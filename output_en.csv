url,title,link,summary,content
https://news.ycombinator.com/rss,I'm Shadow Banned by DuckDuckGo (and Bing),https://daverupert.com/2023/01/shadow-banned-by-duckduckgo-and-bing/,Comments,"




I'm Shadow Banned by DuckDuckGo (and Bing)


January 14, 2023




It came to my attention that my site does not appear on DuckDuckGo search results. Even when searching for ‚Äúdaverupert.com‚Äù directly. After some digging, DuckDuckGo used to get their site index from Yandex, but now gets their site index from Bing and sure enough‚Ä¶ I didn‚Äôt appear on Bing either.
First of all‚Ä¶ rude. I‚Äôm the one person I know who actually uses Bing and I started using DuckDuckGo on my Mac‚Ä¶ and they have the audacity ‚Äînay, the cowardice!‚Äî to shadow ban me and my contributions to the Web!? I ‚Äîa southern gentleman‚Äî take the highest offense at this slighting and misconstruing of my character. I do declare.
SEO isn‚Äôt one of my top objectives with this site, so initially I dismissed it. But that nerdsnipe shot a signal flare up in my brain that spun into mystery I needed to solve. I mean‚Ä¶ there can be money from blogging. Surely I‚Äôve built some clout for my blog over the years‚Ä¶ right?

I have been blogging, almost weekly, for over a decade‚Ä¶
I co-host a somewhat successful web development podcast‚Ä¶
I‚Äôve been back linked from popular blogs like CSS-Tricks‚Ä¶
I‚Äôve been on hacker news a handful of times‚Ä¶
And probably most important‚Ä¶ I show up on Google!

Why on earth would Bing not index my site at all? To solve this, I took the first step and signed up for Bing Webmaster Tools to try to know what Bing knows about my site and sure enough: zero clicks, zero impressions, and zero indexed pages for my site. Awful.

The one clue I have to go off are some ‚ÄúErrors‚Äù according to Bing‚Äôs Crawler. 100% of those errors are ‚Äúmissing meta description‚Äù. That doesn‚Äôt seem like an SEO dealbreaker to me (I get a 91 on Lighthouse SEO), but does Bing super care about meta descriptions? Doesn‚Äôt seem like I should have 0 out of 418 pages in my sitemap.xml though.
One ‚Äúout there‚Äù reason I can think is that I use Amazon Affiliate links on my Bookshelf and my /Uses page and that triggers a shadow ban? I could see how that appears spammy and I question the ethics of Amazon links sometimes myself, but what would I do without those $ones of dollars that I make each year!? I keep it around as a money carrot incentive to motivate me to update the bookshelf, but perhaps it‚Äôs time I retire that monetization avenue.
Anyways, a mystery is afoot‚Ä¶ let the investigation begin! I will post a follow up if I ever solve this.



"
https://news.ycombinator.com/rss,SLT ‚Äì A Common Lisp Language Plugin for Jetbrains IDE Lineup,https://github.com/Enerccio/SLT,Comments,"








Enerccio

/

SLT

Public




 

Notifications



 

Fork
    0




 


          Star
 26
  









        SLT is an IDE Plugin for Itellij/Jetbrains IDE lineup implementing support for Common Lisp via SBCL and Slime/Swank 
      
License





     Apache-2.0 license
    






26
          stars
 



0
          forks
 



 


          Star

  





 

Notifications












Code







Issues
4






Pull requests
0






Actions







Projects
0






Security







Insights



 
 



More


 


                  Code
 


                  Issues
 


                  Pull requests
 


                  Actions
 


                  Projects
 


                  Security
 


                  Insights
 







Enerccio/SLT









This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.











master





Switch branches/tags










Branches
Tags














View all branches















View all tags













Name already in use









      A tag already exists with the provided branch name. Many Git commands accept both tag and branch names, so creating this branch may cause unexpected behavior. Are you sure you want to create this branch?



    Cancel

    Create








3
branches





1
tag







    Code
 







Local



 Codespaces



  










  Clone





            HTTPS
 
            GitHub CLI
 













        Use Git or checkout with SVN using the web URL.
    













      Work fast with our official CLI.
      Learn more.
    








    Open with GitHub Desktop






    Download ZIP



 
Sign In Required

                Please
                sign in
                to use Codespaces.
              



Launching GitHub Desktop

    If nothing happens, download GitHub Desktop and try again.
  




Launching GitHub Desktop

    If nothing happens, download GitHub Desktop and try again.
  




Launching Xcode

    If nothing happens, download Xcode and try again.
  





Launching Visual Studio Code
Your codespace will open once ready.
There was a problem preparing your codespace, please try again.










Latest commit









Peter Vanusanik

fixed wrong import on StringUtils, tested building distributions




        ‚Ä¶
      




        4681185
      

Jan 15, 2023





fixed wrong import on StringUtils, tested building distributions


4681185



Git stats







19

                      commits
                    







Files
Permalink




  
    Failed to load latest commit information.


  
 


Type
Name
Latest commit message
Commit time








.run



fixed wrong import on StringUtils, tested building distributions



Jan 14, 2023









gradle/wrapper



init



Jan 6, 2023









src



fixed wrong import on StringUtils, tested building distributions



Jan 14, 2023









.gitignore



fixed wrong import on StringUtils, tested building distributions



Jan 14, 2023









CodeOfConduct.md



rename file



Jan 14, 2023









LICENSE.txt



readme and such



Jan 14, 2023









README.md



fixed wrong import on StringUtils, tested building distributions



Jan 14, 2023









build-distributions.sh



fixed wrong import on StringUtils, tested building distributions



Jan 14, 2023









build.gradle.kts



fixed wrong import on StringUtils, tested building distributions



Jan 14, 2023









gradle.properties



fixed wrong import on StringUtils, tested building distributions



Jan 14, 2023









gradlew



init



Jan 6, 2023









gradlew.bat



init



Jan 6, 2023









settings.gradle.kts



init



Jan 6, 2023




    View code
 















SLT - A Common Lisp Language Plugin for Jetbrains IDE lineup
Requirements
Getting started
Compiling source
Planned features / goals
License





README.md




SLT - A Common Lisp Language Plugin for Jetbrains IDE lineup



THIS PLUGIN IS EXPERIMENTAL and can crash at any time! Please report all bugs!
This plugin is providing support for Common Lisp for JetBrains IDEs.
Using modified SLIME/Swank protocol to commmunicate with SBCL providing
IDE capabilities for Common Lisp.

Requirements

Intellij based IDE - tested on Intellij Idea Community/Ultimate but should workd on all major IDEs
Steel Bank Common Lisp installed
Quicklisp

Getting started
Download plugin for your IDE from releases and install it via file.
To find out which release applies to you check this table:



Jetbrains IDE Variant
Plugin name pattern




CLion
slt-version-signed-CL.zip


GoLand
slt-version-signed-GO.zip


Intellij Community
slt-version-signed-IC.zip


Intellij Ultimate
slt-version-signed-IU.zip


PyCharm
slt-version-signed-PY.zip


PyCharm Community
slt-version-signed-PC.zip


Rider
slt-version-signed-RD.zip



PhpStorm is coming when I read how to build it correctly since just swapping
the type does not work.
Compiling source
Clone the repository and change gradle.properties for your IDE.
Then use gradle to build the plugin.
You can also open this as a project in Intellij Idea.
Planned features / goals

 Upload to marketplace when it has enough features
 REPL
 Interactive debugging
 Walkable debugger without actions
 Breakpoints
 Documentation
 Macro expand in documentation
 Find function by symbol name
 Search for symbols
 Back references
 Refactoring
 List of quicklisp installed packages / ASDF packages
 List of modified top level forms that are yet to be evaluated

License
This project is licensed under Apache License v2.









About

      SLT is an IDE Plugin for Itellij/Jetbrains IDE lineup implementing support for Common Lisp via SBCL and Slime/Swank 
    
Topics



  lisp


  integrated-development-environment


  jetbrains


  common-lisp


  sbcl


  intellij-plugin


  jetbrains-plugin



Resources





      Readme
 
License





     Apache-2.0 license
    



Stars





26
    stars

Watchers





3
    watching

Forks





0
    forks







    Releases





1
tags







    Packages 0


        No packages published 











Languages













Java
91.4%







Common Lisp
4.4%







Lex
3.3%







Other
0.9%











"
https://news.ycombinator.com/rss,Ask HN: How do you trust that your personal machine is not compromised?,https://news.ycombinator.com/item?id=34388866,Comments,"

Ask HN: How do you trust that your personal machine is not compromised? | Hacker News

Hacker News
new | past | comments | ask | show | jobs | submit 
login




 Ask HN: How do you trust that your personal machine is not compromised?
44 points by coderatlarge 1 hour ago  | hide | past | favorite | 29¬†comments 

""Compromised"" meaning that malware hasn't been installed or that it's not being accessed by malicious third parties.  This could be at the BIOS, firmware, OS, app or any other other level. 
 
  
 
gnfargbl 31 minutes ago  
             | next [‚Äì] 

Here's a short, fairly practical guide that you might find helpful: https://www.ncsc.gov.uk/files/Cyber-Essentials-Requirements-.... It is aimed mostly at small businesses, but I find a lot of the guidance to be pretty relevant to my personal IT.My even shorter (and incomplete) summary of the document would be: configure your router and firewall; remove default passwords and crapware from your devices; use a lock screen; don't run as root; use a password manager and decent passwords; enable 2FA everywhere you can; enable anti-malware if your OS has it built it; don't run software from untrusted sources; patch regularly.There are also other controls that you can choose to impose on yourself. For example, I require full-disk encryption, and I will only use mobile devices which get regular updates. Would be interested in hearing other things that HN'ers do to limit risk.
 
reply



  
 
amelius 16 minutes ago  
             | parent | next [‚Äì] 

Do you lock your computer every time you leave your desk?And do you always check for keylogger thumbdrives and such?
 
reply



  
 
Semaphor 5 minutes ago  
             | root | parent | next [‚Äì] 

For me: No, and no. But as that would require someone breaking into my apartment, I don‚Äôt worry too much.
 
reply



  
 
k3liutZu 5 minutes ago  
             | root | parent | prev | next [‚Äì] 

Yes (I don't bother when I'm working from home)I haven't used a use usb stick in +10 years.
 
reply



  
 
greggyb 14 minutes ago  
             | root | parent | prev | next [‚Äì] 

Yes. Why wouldn't you?
 
reply



  
 
NikolaNovak 22 minutes ago  
             | prev | next [‚Äì] 

Great question. I don't anymore. Decades ago when I had a 286 and knew what each file did and what all the software was, and threats were limited and crude, I had good confidence of controlling my machine. Today, when my laptop has millions of files and each website - even hacker news - could inject something malicious and my surface is so broad (browsers applications extensions libraries everything) and virtually anything I do involves network connections... I just don't have the confidence.FWIW, I try to segregate my machines for different categories of behaviour - this laptop is for work, this one is for photos and personal documents, this one is for porn, this one is if I want to try something. But even still my trust in e. G. software vlan on my router and access controls on my NAS etc are limited in this day and age.I feel today it's not about striving for zero risk (for 99.99 of people) , but picking the ratio of overhead and risk you're ok with. And backups. (bonus question - how to make backups safe in age of encrypting ransom ware).
 
reply



  
 
jl6 9 minutes ago  
             | parent | next [‚Äì] 

On the backup question, this is one reason why I have a set of backups that are physically disconnected and not automated.
 
reply



  
 
h2odragon 42 minutes ago  
             | prev | next [‚Äì] 

You really can't, anymore. You can watch traffic and hope that anything nasty isn't communicating with the outside world, but then there's all sorts of side channels that you may not know to watch.At some point you just have to admit there's limits to privacy and work with them. You paper journal could be stolen and read / rewritten too, yaknow? It's not a new problem, its just in a new context.
 
reply



  
 
ramraj07 3 minutes ago  
             | prev | next [‚Äì] 

There are two levels here: compromised by some national agency vs. compromised by anyone else.For the former, I don‚Äôt assume anything especially since I‚Äôm not an American citizen. I still believe with some certainty that my iPhone is safe from the government but not 100%
 
reply



  
 
adriancr 25 minutes ago  
             | prev | next [‚Äì] 

Just some generic things that should help avoid or clean up after a compromise.- clean reinstall every month, just pick a new flavor of Linux to try out. (also helps ensure I have proper backups and scripts for setting up environment)- Dev work I usually do in docker containers, easy to set up/nuke environments.- Open source router with open source bios (apu2), firewall on it, usually reinstall once in a while.- Spin up VMs via scripts for anything else. (games - windows VM with passthrough GPU for example)- automatic updates everywhere.
 
reply



  
 
867-5309 22 minutes ago  
             | parent | next [‚Äì] 

>Spin up VMs via scripts for .. gamesthis is not sustainable. you do this once and then pray nothing breaks!
 
reply



  
 
adriancr 20 minutes ago  
             | root | parent | next [‚Äì] 

I just have a clone of a clean windows VM.If something breaks or I get bored, nuke the active one and start clone, update it and make another backup, then reinstall games again.On the other hand, gpu pass-through breaks once in a while and is annoying to fix.
 
reply



  
 
albntomat0 6 minutes ago  
             | prev | next [‚Äì] 

The biggest thing is being deliberate about your threat model.  Who would want to get onto your systems, and how much do they care about you in particular?From there, take appropriate actions.  For the vast, vast majority of us, that means using good passwords, updating software, and not running weird things from the internet.If you‚Äôre worried about 0 click RCE in Chrome/Windows/iOS, you either should be getting better advice from folks outside of HN, or are being unrealistic about who is coming after you.
 
reply



  
 
lifthrasiir 36 minutes ago  
             | prev | next [‚Äì] 

I'm reasonably sure that my personal machine is less compromised than the average, but I can't and will never be able to ensure that it is not compromised because I have no way to know everything the machine trying to do. This remains true even when you have an entirely free and directly inspectable hardware; you simply have no knowledge and time to verify everything. Just keep a reasonable amount of precaution and skepticism.
 
reply



  
 
jl6 30 minutes ago  
             | prev | next [‚Äì] 

I don‚Äôt have ultimate trust in any software or hardware, but I get to ‚Äúgood enough‚Äù by deciding which providers I trust:* Software: Canonical, Google, Microsoft, Valve, Oracle, Dropbox. I install software from their official repos. Anything 3rd-party/unofficial/experimental/GitHub goes in a VM.* Hardware: I built my main PC from mainstream commodity components. I have no way of knowing if there are secret backdoors but I consider it unlikely.I‚Äôm also privileged enough to not be a ‚Äúperson of interest‚Äù so don‚Äôt feel the need to take any extraordinary precautions.Yes, I‚Äôm aware of VM escapes. Yes, I‚Äôve read Reflections on Trusting Trust. I choose to trust regardless because life‚Äôs too short for paranoia. As Frank Drebin said:‚ÄúYou take a chance getting up in the morning, crossing the street, or sticking your face in a fan.‚Äù
 
reply



  
 
rhn_mk1 17 minutes ago  
             | parent | next [‚Äì] 

What about publicly known backdoors in your hardware?https://www.techrepublic.com/article/is-the-intel-management...There is hardware that doesn't contain those at least, but it doesn't break power records.
 
reply



  
 
codetrotter 38 minutes ago  
             | prev | next [‚Äì] 

Noone has drained my crypto from my wallets yet.So either my personal machine is not compromised, or they think the amount of crypto in the wallets is too low.Jokes on them though, cause I am moving my crypto to a hardware wallet eventually
 
reply



  
 
progval 14 minutes ago  
             | parent | next [‚Äì] 

Joke's on you, you just told them they should hurry up before you do ;)
 
reply



  
 
tluyben2 31 minutes ago  
             | parent | prev | next [‚Äì] 

Quite an interesting honeypot really.
 
reply



  
 
mimimi31 23 minutes ago  
             | root | parent | next [‚Äì] 

More like a canary I think.
 
reply



  
 
adg001 25 minutes ago  
             | prev | next [‚Äì] 

The reality is that you cannot trust that your machines are not compromised.The only option we are left with is to operate under the assumption that, indeed, our machines are permanently compromised.
 
reply



  
 
rekrsiv 4 minutes ago  
             | prev | next [‚Äì] 

You don't. Treat your personal machine(s) as compromised by default and take it from there.
 
reply



  
 
PaulHoule 35 minutes ago  
             | prev | next [‚Äì] 

Reminds me of the time I was watching a creepypasta horror movie about some guy who gets strange phone calls and my phone rang.I think this guy had gotten my phone number from my HN profile and he thought I might be able to help him.  He thought his android phone was infected by malware and he knew who did it.  I told him the people who repair cell phones at the mall could do a system reset on his phone‚Ä¶. Unless he was dealing with state-level actors in which case it might be an advanced persistent threat and it might be permanent.
 
reply



  
 
treebeard901 43 minutes ago  
             | prev | next [‚Äì] 

You should assume all devices are compromised
 
reply



  
 
wadayano 34 minutes ago  
             | parent | next [‚Äì] 

*compromisable
 
reply



  
 
baobabKoodaa 40 minutes ago  
             | parent | prev | next [‚Äì] 

Not helpful
 
reply



  
 
twaw 14 minutes ago  
             | root | parent | next [‚Äì] 

Why not? It still possible to communicate securely using compromised devices and networks.
 
reply



  
 
cube2222 11 minutes ago  
             | prev | next [‚Äì] 

I try to follow what others already mentioned, but still, for any personal high-security stuff I use a device whose OS  puts strong limits on apps, like an iPad.
 
reply



  
 
crims0n 22 minutes ago  
             | prev [‚Äì] 

Keep it air gapped, only way to be sure!Only half kidding, unfortunately.
 
reply







Guidelines | FAQ | Lists | API | Security | Legal | Apply to YC | Contact
Search:  


"
https://news.ycombinator.com/rss,Ubuntu 22.04 LTS servers and phased apt updates,https://utcc.utoronto.ca/~cks/space/blog/linux/Ubuntu2204ServerPhasedUpdates,Comments,"
 
 Chris's Wiki :: blog/linux/Ubuntu2204ServerPhasedUpdates 






Chris Siebenmann ::
CSpace ¬ª
       blog ¬ª
       linux ¬ª
       Ubuntu2204ServerPhasedUpdates
Welcome, guest.




Ubuntu 22.04 LTS servers and phased apt updates
January 13, 2023

I was working on getting one of our 22.04 LTS servers up to date,
even for packages we normally hold, when I hit a mystery and
posted about it on the Fediverse:
Why does apt on this 22.04 Ubuntu machine want to hold back a bunch of
package updates even with '--with-new-pkgs --ignore-hold'? Who knows,
it won't tell me why it doesn't like any or all of:
open-vm-tools openssh-client openssh-server openssh-sftp-server
osinfo-db python3-software-properties software-properties-common
(Apt is not my favorite package manager for many reasons, this among
them.)

Steve suggested that it was Ubuntu's ""Phased Update"" system, which is what it turned
out to be. This set me off to do some investigations, and it turns
out that phased (apt) updates explain some other anomalies we've
seen with package updates on our Ubuntu 22.04 machines.
The basic idea of phased updates is explained in the ""Phasing""
section of Ubuntu's page on Stable Release Updates (SRUs); it's a
progressive rollout of the package to more and more of the system
base. Ubuntu introduced phased updates in 2013 (cf) but initially they weren't
directly supported by apt, only by the desktop upgrade programs.
Ubuntu 21.04 added apt support for phased updates and
Ubuntu 22.04 LTS is thus the first LTS version to subject servers
to phased updates. More explanations of phased updates are in this
askubuntu answer, which includes
one way to work around them.
(Note that as far as I know and have seen, security updates are not
released as phased updates; if it's a security update, everyone
gets it right away. Phased updates are only used for regular,
non-security updates.)
Unfortunately apt (or apt-get) won't tell you if an update is being
held back because of phasing. This user-hostile apt issue is tracked
in Ubuntu bug #1988819 and
you should add yourself as someone it affects if this is relevant
to you. Ubuntu has a web page on what updates are currently in
phased release,
although packages are removed from this page once they reach 100%.
Having reached 100%, such a package is no longer a phased update,
which will become relevant soon. If you can't see a reason for a
package to be held back, it's probably a phased update but you can
check the page
to be sure.
(As covered in the ""Phasing"" section, packages
normally move forward through the phased rollout every six hours,
so you can have a package held back on some server in the morning
and then be not-held in the afternoon. This is great fun for
troubleshooting why a given server didn't get a particular update.)
Your place in a phased update is randomized across both different
servers and different packages. If you have a fleet of servers,
they will get each phased update at different times, and the order
won't be consistent from package to package. This explains an anomaly
we've been seeing in our package updates for some time, where
different 22.04 servers would get updates at different times without
any consistent pattern.
The phased update related apt settings available and some of the
technical details are mostly explained in this askubuntu answer. If you want to opt out of phased
updates entirely, you have two options; you can have your servers
install all phased updates right away (basically putting you at the
0% start line), or you can skip all phased updates and only install
such packages when they reach 100% and stop being considered phased
updates at all. Unfortunately, as of 22.04 there's no explicit
option to set your servers to have a particular order within all
updates (so that you can have, for example, a 'canary' server that
always installs updates at 0% or 10%, ahead of the rest of the
fleet).
For any given package update, machines are randomized based on the
contents of /etc/machine-id, which
can be overridden for apt by setting APT::Machine-ID to a 32 hex
digit value of your choice (the current version of apt appears to
only use the machine ID for phased updates).  If you set this to
the same value across your fleet, your fleet will update in sync
(although not at a predictable point in the phase process); you can
also set subsets of your fleet to different shared values so that
the groups will update at different times.  The assignment of a
particular machine to a point in the phased rollout is done through
a relatively straightforward approach; the package name, version,
and machine ID are all combined into a seed for a random number
generator, and then the random number generator is used to produce
a 0 to 100 value, which is your position in the phased rollout. The
inclusion of the package name and version means that a given machine
ID will be at different positions in the phased update for different
packages. All of this turns out to be officially documented in the
""Phased Updates"" section of apt_preferences(5),
although not in much detail.
(There is a somewhat different mechanism for desktop updates, covered
in the previously mentioned askubuntu answer.)
As far as I can see from looking at the current apt source code, apt doesn't log anything
at any verbosity if it holds a package back because the package is
a phased update and your machine doesn't qualify for it yet. The
fact that a package was a phased update the last time apt looked
may possibly be recorded in /var/log/apt/eipp.log.xz, but documentation
on this file is sparse.
Now that I've looked at all of this and read about APT::Machine-ID,
we'll probably set it to a single value across all of our fleet
because we find different machines getting updates at different
times to be confusing and annoying (and it potentially complicates
troubleshooting problems that are reported to us, since we normally
assume that all 22.04 machines have the same version of things like
OpenSSH). If we could directly control the position within a phased
rollout we'd probably set up some canary machines, but since we
can't I don't think there's a strong reason to have more than one
machine-id group of machines.
(We could set some very important machines to only get updates when
packages reach 100% and stop being phased updates, but Ubuntu has
a good record of not blowing things up with eg OpenSSH updates.)

(4 comments.)
Written on 13 January 2023. 

     ¬´   A browser tweak for system administrators doing (web) network debugging    
    Your server BMCs can need to be rebooted every so often   ¬ª     



 These are my WanderingThoughts 
(About the blog)
Full index of entries 
Recent comments
This is part of CSpace, and is written by ChrisSiebenmann. 
Mastodon: @cks 
Twitter: @thatcks
* * *
Categories: links, linux, programming, python, snark, solaris, spam, sysadmin, tech, unix, web 
Also: (Sub)topics
This is a DWiki. 
GettingAround 
(Help)
 
 Search:  



 Page tools: View Source, Add Comment. 

Search: 

Login: 
Password: 


 

Atom Syndication: Recent Comments.
 Last modified: Fri Jan 13 22:56:18 2023 
This dinky wiki is brought to you by the Insane Hackers
Guild, Python sub-branch.


"
https://news.ycombinator.com/rss,Single-file scripts that download their dependencies,https://dbohdan.com/scripts-with-dependencies,Comments,"



Single-file scripts that download their dependencies ¬∑ DBohdan.com











Toggle navigation




dbohdan



Home





 




Homescripts-with-dependencies





Single-file scripts that download their dependencies
An ideal distributable script is fully contained in a single file. It runs on any compatible operating system with an appropriate language runtime. It is plain text, and you can copy and paste it. It does not require mucking about with a package manager, or several, to run. It does not conflict with other scripts‚Äô packages or require managing a project environment to avoid such conflicts.
The classic way to get around all of these issues with scripts is to limit yourself to using the scripting language‚Äôs standard library. However, programmers writing scripts don‚Äôt want to; they want to use libraries that do not come with the language by default. Some scripting languages, runtimes, and environments resolve this conflict by offering a means to download and cache a script‚Äôs dependencies with just declarations in the script itself. This page lists such languages, runtimes, and environments. If you know more, drop me a line.
Contents



Anything with a Nix package


D


Groovy


JavaScript (Deno)


Kotlin (kscript)


Racket (Scripty)


Scala (Ammonite)



Anything with a Nix package
The Nix package manager can act as a #! interpreter and start another program with a list of dependencies available to it.
#! /usr/bin/env nix-shell
#! nix-shell -i python3 -p python3
print(""Hello, world!"".rjust(20, ""-""))
D
D‚Äôs official package manager DUB supports single-file packages.
#! /usr/bin/env dub
/+ dub.sdl:
name ""foo""
+/
import std.range : padLeft;
import std.stdio : writeln;
void main() {
    writeln(padLeft(""Hello, world!"", '-', 20));
}
Groovy
Groovy comes with an embedded JAR dependency manager.
#! /usr/bin/env groovy
@Grab(group='org.apache.commons', module='commons-lang3', version='3.12.0')
import org.apache.commons.lang3.StringUtils
println StringUtils.leftPad('Hello, world!', 20, '-')
JavaScript (Deno)
Deno downloads dependencies like a browser. Deno 1.28 and later can also import from NPM packages. Current versions of Deno require you to pass a run argument to deno. One way to accomplish this from a script is with a form of ‚Äúexec magic‚Äù. Here the magic is modified from a comment by Rafa≈Ç Pocztarski.
#! /bin/sh
"":"" //#; exec /usr/bin/env deno run ""$0"" ""$@""
import leftPad from ""npm:left-pad"";
console.log(leftPad(""Hello, world!"", 20, ""-""));
On Linux systems with recent GNU env(1) and on FreeBSD you can replace the magic with env -S.
#! /usr/bin/env -S deno run
import leftPad from ""npm:left-pad"";
console.log(leftPad(""Hello, world!"", 20, ""-""));
Kotlin (kscript)
kscript is an unofficial scripting tool for Kotlin that understands several comment-based directives, including one for dependencies.
#! /usr/bin/env kscript
//DEPS org.apache.commons:commons-lang3:3.12.0
import org.apache.commons.lang3.StringUtils
println(StringUtils.leftPad(""Hello, world!"", 20, ""-""))
Racket (Scripty)
Scripty interactively prompts you to install the missing dependencies for a script in any Racket language.
#! /usr/bin/env racket
#lang scripty
#:dependencies '(""base"" ""typed-racket-lib"" ""left-pad"")
------------------------------------------
#lang typed/racket/base
(require left-pad/typed)
(displayln (left-pad ""Hello, world!"" 20 ""-""))
Scala (Ammonite)
The scripting environment in Ammonite lets you import Ivy dependencies.
#! /usr/bin/env amm
import $ivy.`org.apache.commons:commons-lang3:3.12.0`,
  org.apache.commons.lang3.StringUtils
println(StringUtils.leftPad(""Hello, world!"", 20, ""-""))

Tags: list, programming.
 
 
 
 


Copyright 2013‚Äì2022 D. Bohdan.




 


"
https://news.ycombinator.com/rss,"The Fourier Transform, explained in one sentence",https://blog.revolutionanalytics.com/2014/01/the-fourier-transform-explained-in-one-sentence.html,Comments,"


































The Fourier Transform, explained in one sentence (Revolutions)













Revolutions

			Milestones in AI, Machine Learning, Data Science, and visualization with R and Python since 2008
		









¬´ Forecasting By Combining Expert Opinion |
	Main
	| Predictive Models in R Clustered By Tag Similarity ¬ª



January 03, 2014


The Fourier Transform, explained in one sentence


If, like me, you struggled to understand the Fourier Transformation when you first learned about it, this succinct one-sentence colour-coded explanation from Stuart Riffle probably comes several years too late:

Stuart provides a more detailed explanation here. This is the formula for the Discrete Fourier Transform, which converts sampled signals (like a digital sound recording) into the frequency domain (what tones are represented in the sound, and at what energies?). It's the mathematical engine behind a lot of the technology you use today, including mp3 files, file compression, and even how your old AM radio stays in tune.
The daunting formula involves imaginary numbers and complex summations, but Stuart's idea is simple. Imagine an enormous speaker, mounted on a pole, playing a repeating sound. The speaker is so large, you can see the cone move back and forth with the sound. Mark a point on the cone, and now rotate the pole. Trace the point from an above-ground view, if the resulting squiggly curve is off-center, then there is frequency corresponding the pole's rotational frequency is represented in the sound. This animated illustration (click to see it in action) illustrates the process:

The upper signal is make up of three frequencies (""notes""), but only the bottom-right squiggle is generated by a rotational frequency matching one of the component frequencies of the signal.
By the way, no-one uses that formula to actually calculate the Discrete Fourier Transform ‚Äî use the Fast Fourier Transform instead, as implemented by the fft function in R. As the name suggests, it's much faster.
AltDevBlog: Understanding the Fourier Transform¬†(note: updated link 20 Oct 2015 with active mirror)





Posted by David Smith at 13:30 in R, random  | Permalink











Comments

 You can follow this conversation by subscribing to the comment feed for this post.





Very interesting article, thank you. Please take a moment to rephrase the following key statement, if you would: ""...then there is frequency corresponding the pole's rotational frequency is represented in the sound.""


		Posted by:
		C. Griffith |
		January 04, 2014 at 10:09




polar form e^iŒ∏ is equal to the rectangular form cosŒ∏+isinŒ∏ and corresponds to the coordinates (cosŒ∏,sinŒ∏) such that 
e^i0    =  1 = (1,0)
e^iœÑ/4  =  i = (0,1)
e^iœÑ/2  = -1 = (-1,0)
e^iœÑ3/4 = -i = (0,-1)
e^iœÑ    =  1 = (1,0)


		Posted by:
		MasterG |
		January 04, 2014 at 16:33




May I suggest a  minor exception to your claim about FFT: most modern languages, R included, use some variation of the ""pure"" 2^N Cooley-Tukey FFT algorithm as appropriate to support factors of 3, 5, etc. in the length of the dataset, and even default to the ""raw"" DFT for other data lengths (unless specifically suppressed by the user).   
And, of course, the FFT is in fact that equation, just with gobs of like terms grouped together. :-)


		Posted by:
		Carl Witthoft |
		January 06, 2014 at 08:40











	The comments to this entry are closed.







Information


About this blog
Comments Policy
About Categories
About the Authors
Local R User Group Directory
Tips on Starting an R User Group





Search Revolutions Blog






















Got comments or suggestions for the blog editor? 
Email David Smith.
    




 Follow David on Twitter: @revodavid





Get this blog via email with 




Categories


academia (41)
advanced tips (218)
AI (62)
airoundups (20)
announcements (201)
applications (288)
beginner tips (106)
big data (272)
courses (60)
current events (126)
data science (227)
developer tips (90)
events (280)
finance (126)
government (25)
graphics (378)
high-performance computing (115)
life sciences (35)
Microsoft (314)
mlops (4)
open source (78)
other industry (58)
packages (388)
popularity (54)
predictive analytics (163)
profiles (15)
python (69)
R (2442)
R is Hot (8)
random (464)
reviews (22)
Revolution (422)
Rmedia (136)
roundups (121)
sports (55)
statistics (297)
user groups (127)


See More




R links


R on AzureDeveloper's guide and documentation
Find R packagesCRAN package directory at MRAN
Download Microsoft R OpenFree, high-performance R
R Project siteInformation about the R project






Recommended Sites


@RLangTipDaily tips on using R
FlowingDataModern data visualization
Probability and statistics blogMonte Carlo simulations in R
R BloggersDaily news and tutorials about R, contributed by R bloggers worldwide.
R Project group on analyticbridge.comCommunity and discussion forum
Statistical Modeling, Causal Inference, and Social ScienceAndrew Gelman's statistics blog






Archives


January 2023
August 2022
September 2021
July 2021
June 2021
April 2021
March 2021
February 2021
January 2021
December 2020





 Subscribe to this blog's feed




‚Äã
    













 








"
https://news.ycombinator.com/rss,Go FOSS: Information is power,https://gofoss.net/,Comments,"          gofoss.net      Home      Get started      Get started     Protect your digital freedom         Browse privately      Browse privately     Free your browser     Firefox     Tor Browser     VPN         Speak freely      Speak freely     Keep conversations private     Encrypted messages     Encrypted emails         Store safely      Store safely     Secure your data     Safe passwords     Backups     Encrypted files         Stay mobile & free      Stay mobile & free     Free your phone     FOSS apps     CalyxOS     LineageOS for microG         Unlock your computer      Unlock your computer     Free your computer     Ubuntu     Ubuntu apps         Own your cloud      Own your cloud     Free your cloud     Fediverse     Alternative cloud providers     Server hosting     Basic server security     Advanced server security     Secure access     Cloud storage     Photo gallery     Contacts, calendars & tasks     Media streaming     Server backups         About      About     Big Tech threatens privacy     The project     The team     Thanks     Contributing     Roadmap     Disclaimer         Origins      Origins     Hackers, 1984     The GNU Manifesto, 1985     The Techno-Revolution, 1986     The Conscience of a Hacker, 1986     The Crypto Anarchist Manifesto, 1988     A Cypherpunk's Manifesto, 1993     A Declaration of the Independence of Cyberspace, 1996     A Cyberpunk Manifesto, 1997     The Cathedral & The Bazaar, 1999     The dotCommunist Manifesto, 2003     A Hacker Manifesto, 2004     The Maker's Bill of Rights, 2006     Guerilla Open Access Manifesto, 2008     The Apache Way, 2009     Repair Manifesto, 2009     The Cult of Done Manifesto, 2009     Self-Repair Manifesto, 2010     The Hardware Hacker Manifesto, 2010     An Anonymous Manifesto, 2011     The Declaration of the Independence of the people of the Internet, 2012                          Back to top  "
https://news.ycombinator.com/rss,Constrain ‚Äì Interactive figures using declarative constraint solving,https://github.com/andrewcmyers/constrain,Comments,"








andrewcmyers

/

constrain

Public




 

Notifications



 

Fork
    2




 


          Star
 50
  









        Responsive, animated figures in JavaScript/HTML canvases
      





andrewcmyers.github.io/constrain







50
          stars
 



2
          forks
 



 


          Star

  





 

Notifications












Code







Issues
18






Pull requests
0






Discussions







Actions







Projects
0






Security







Insights



 
 



More


 


                  Code
 


                  Issues
 


                  Pull requests
 


                  Discussions
 


                  Actions
 


                  Projects
 


                  Security
 


                  Insights
 







andrewcmyers/constrain









This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.











master





Switch branches/tags










Branches
Tags














View all branches















View all tags













Name already in use









      A tag already exists with the provided branch name. Many Git commands accept both tag and branch names, so creating this branch may cause unexpected behavior. Are you sure you want to create this branch?



    Cancel

    Create








7
branches





6
tags







    Code
 







Local



 Codespaces



  










  Clone





            HTTPS
 
            GitHub CLI
 













        Use Git or checkout with SVN using the web URL.
    













      Work fast with our official CLI.
      Learn more.
    








    Open with GitHub Desktop






    Download ZIP



 
Sign In Required

                Please
                sign in
                to use Codespaces.
              



Launching GitHub Desktop

    If nothing happens, download GitHub Desktop and try again.
  




Launching GitHub Desktop

    If nothing happens, download GitHub Desktop and try again.
  




Launching Xcode

    If nothing happens, download Xcode and try again.
  





Launching Visual Studio Code
Your codespace will open once ready.
There was a problem preparing your codespace, please try again.










Latest commit






 




andrewcmyers

Fix backprop for Smooth/Linear.




        ‚Ä¶
      




        130cac8
      

Jan 15, 2023





Fix backprop for Smooth/Linear.

Remove unnecessary tree constraints.
Add necessary constraints to example.

130cac8



Git stats







516

                      commits
                    







Files
Permalink




  
    Failed to load latest commit information.


  
 


Type
Name
Latest commit message
Commit time








doc



doc improvement



Jan 13, 2023









examples



Fix backprop for Smooth/Linear.



Jan 15, 2023









images



Update image



Jun 27, 2022









reveal.js @ 9430a98



latest



Jul 25, 2019









tests



un/refix test



Jan 15, 2023









.gitignore



Reorg/clean up repo



Dec 25, 2020









.gitmodules



change to my version of Reveal



Jul 18, 2019









README.md



tree example



Jan 13, 2023









constrain-graph.js



argument checking



May 11, 2022









constrain-mathjax.js



formatting



Jul 27, 2022









constrain-pdf.js



Monkey-patch broken jsPDF calls



Apr 9, 2022









constrain-ps.js



Implement missing methods for PS rendering



Apr 9, 2022









constrain-reveal.js



Clean up comment



Apr 19, 2021









constrain-slide.css



More refactoring of Reveal mods



Aug 21, 2019









constrain-trees.js



Fix backprop for Smooth/Linear.



Jan 15, 2023









constrain.js



Fix backprop for Smooth/Linear.



Jan 15, 2023









numeric-1.2.6.js



execute bit should not be on



Jul 22, 2019




    View code
 















Constrain - a JS (ES6) library for animated, interactive figures, based on declarative constraint solving
Demos
Requirements





README.md




Constrain - a JS (ES6) library for animated, interactive figures, based on declarative constraint solving


Responsive, animated figures embedded in web pages
Figures implemented declaratively with time-dependent constraints on graphical objects
Integrates with Reveal.js presentations
GitHub repository
Reference manual
A short talk about Constrain

Demos
Using constraints to compute the Golden Ratio (Drag the diamond!)
A short talk about Constrain, using Reveal
Cornell University course notes using Constrain for embedded figures: CS 2112,
CS 4120/lexer generation,
CS 4120/bottom-up parsing
Interactive Pythagorean Theorem
Interactively computing centers of a triangle
TeX-style text formatting
Simple template page for using Constrain
Animated trees
Requirements

ES6-capable web browser

Tested on Chrome, Opera, Brave, Firefox, Safari (runs best on the first three)
Does not work on Internet Explorer or Opera Mini


Numeric.js version 1.2.6 (included)










About

      Responsive, animated figures in JavaScript/HTML canvases
    





andrewcmyers.github.io/constrain


Topics



  constraints


  web-pages


  animated-figures


  embedded-figures



Resources





      Readme
 


Stars





50
    stars

Watchers





4
    watching

Forks





2
    forks







    Releases
      5







Release 0.3.0

          Latest
 
Apr 21, 2021

 

        + 4 releases







    Packages 0


        No packages published 





Languages












JavaScript
95.1%







HTML
4.8%







CSS
0.1%











"
https://news.ycombinator.com/rss,Flightcontrol (YC W22) is hiring Developer Advocate (remote/fulltime),https://jobs.flightcontrol.dev/developer-advocate,Comments,"üõ´Developer Advocate at a Calm, Ambitious DevTools Startup¬†https://www.flightcontrol.dev¬†Flightcontrol is a 4 person devtool startup cofounded by the creator of Blitz.js. We‚Äôre not the macho, overworked team that ‚Äústartup‚Äù might bring to mind. We‚Äôre intentionally building the most life-giving and fulfilling company possible, and we want you to join us! :)¬†Photos from our last retreat in Italy ‚Äî¬†contrary to appearances, we also did real work :)Flightcontrol is transforming the app deployment landscapeFlightcontrol provides the deployment experience of a Platform-as-a-Service but without the limitations.Traditionally, users had to choose between a PaaS like Heroku, which is easy to use but is a closed-box with limitations and restrictions, or AWS which gives you full power and control but is a royal pain to set up. But with Flightcontrol they get the best of both worlds: great developer experience and full control and scalabilityOur product is so compelling that most of our users are migrating existing applications from Heroku, Render, Railway, Vercel and from custom AWS setups.Before you cringe at our current design, know that we are currently working with Overnice to completely overhaul our brand design, marketing site, and UI/UX. So rest assured, you‚Äôll soon have world-class brand materials to work with :)Since launching in January, over 350 users have deployed 30,000+ timesUsers of all sizes love the product, from solo indie hackers to enterprisesWe went through Y Combinator in W22 and have raised $3.5M.We‚Äôre default alive ‚Äî on track to become profitable this yearIntrigued? Read more about our company here.Deployments Per Month¬†Meet Our Team of 4Brandon Bayer, Cofounder and CEO. Dayton, Ohio. You might know me as the creator of Blitz.js. Although highly technical, my strengths are product design and marketing. My superpower is simplicity. My top values that define everything I do are excellence, equality, inclusion, and freedom. Outside of work I love traveling, flying airplanes and helicopters, and rock climbing. My intention is to build the best company to work for in the world. I‚Äôm here to support you and help make your dreams come true.Mina Abadir, Cofounder and CTO. Toronto, Canada. Mina is the technical genius that brings our core product features to life. He‚Äôs deeply authentic and caring, loves to laugh, and greatly enjoys a good video game. His superpower is empathy.Blake Bayer, Junior Software Engineer. Dayton, Ohio. Formerly a nurse, Blake joined at the end of April. This is his first job in tech, and he continually impresses everyone on the team with his ability to learn and implement complex things quickly. He loves rock climbing and learning new things.Camila Rondinini, Senior Backend Software Engineer. Spain. Since joining this past June, she is already an extremely foundational part of our team, having designed and shipped some of our most important features. She‚Äôs an incredible engineer and has made a massive impact on our engineering culture.You? üòâ¬†We need you to help us grow through awareness & educationAs our first devrel hire, this is your chance to really shine and help propel Flightcontrol into one of the most loved developer companies of this decade. This is a critical role in shaping FlightcontrolYour high level goal is to grow ‚Äútop of funnel‚Äù traffic through awareness and education, with written content as the foundation.We are building a product-led growth flywheel. Your primary role is feeding the flywheel via new top of funnel users. Your secondary role is improving the flywheel through education and documentation.So far Brandon has been doing all the devrel related tasks. You‚Äôll work closely with him to figure out where and how to invest your efforts. We don‚Äôt yet have the perfect content strategy. So we‚Äôll be experimenting to see what works and what doesn‚Äôt.In time, we want to be known as the cloud education company. The place where all devs turn to become maestros of the cloud. We believe that most engineers would love working with native cloud providers like AWS if only it was more approachable and more easily understood. Our vision is to empower an entirely new generation of engineers through our product and through our educational content.Essential Responsibilities Deeply understand our product, its strengths and weaknessesCreate and distribute compelling technical content, including documentation, documentation, guides, demos, and videosWe care about quality over quantityIdentify and work on collaborations and integrations with other companies and projectsExample: how to use Flightcontrol preview environments to run isolated Cypress e2e testsSecondary ResponsibilitiesHelp with customer success. As a small team, we all share this responsibility. Helping with this is one of the best ways to understand nitty-gritty details of our product, product improvement ideas, and documentation ideas.A customer recently said that we ‚Äúhave amazing support and developer success‚Äù and that it provides a tremendous amount of value to themPossibly, but not required: represent Flightcontrol at eventsIdentifying relevant events for Flightcontrol and organizing our participation (meetups, conferences, hackathons, workshops, etc.),Ideally participating in 4-8 of these events per year, as a speaker or sponsorRequirements1 year full-time devrel experience2 years full-time software engineering experience and are comfortable with fullstackSome working knowledge of some basic AWS services like EC2, S3, RDS, LambdaTeacher ‚Äî can explain complex things in as simple a manner as possibleWriter ‚Äî great at writing technical content, ideally for 1+ yearsGrit ‚Äî can ship content consistently over time through thick and thinEmpathy ‚Äî can learn and understand what‚Äôs important to developers and engineering organizationsCredible ‚Äî produces content that acknowledges the trade-offs and complexities of the real worldCan overlap with 10a-noon US Eastern time (EST) . You can work from anywhere in the world, but we have our company wide meetings in the 10a-12p EST time range.Nice to haveExperience in the AWS or cloud spaceGreat at creating videosConference speaking experienceGreat knowledge of the application hosting/deployment ecosystemAble to work with basic demos in several programming languagesExperience with our stack: Typescript, React, Next.js¬†You Are Someone WhoIs Kind. We are a team that seeks to work really well together by building deep relationships. We have each other‚Äôs backs. We care about and check in on each other, and we enjoy being together. We have company retreats 2-3 times per year for a week at a time.Is Collaborative. We all work closely together to design and develop the best product possible. We want someone who is humble but will bring your own ideas on how to be more excellent.Takes Ownership. We offer significant equity because we want you to think at a higher level than just your daily tasks. We want you to help us shape the business. We need someone who loves to dig in and do what it takes to figure things out. And we want someone who is good at turning vague ideas into magnificence. Has a Growth Mindset. It matters more where you are going than where you are today. We‚Äôre looking for someone who loves to grow, improve, and learn new things.¬†Your Typical Week at FlightcontrolOn Monday, depending on your timezone, you‚Äôll start your morning or afternoon with a coffee chat where everyone is together for causal conversation. After that, you‚Äôll join our Flightcontrol planning session with the entire Flightcontrol product team.Tuesday is usually meeting free, so you‚Äôll be focused on your work.On Wednesday you‚Äôll have your weekly 1 on 1 with Brandon, the CEO. This is your time to ask for what you want, bring up issues, ask hard questions, and give and receive feedback. Brandon takes feedback very seriously and is quick to make needed changes. Thursday and Friday are your time for deep work.Aside from being available 9a-12p EST, your work hours are flexible and up to you. Some of us work a standard 9-5 type of deal while others have varying schedules.You‚Äôll collaborate with Brandon as much as is needed.Since we‚Äôre a startup, the journey from idea to building to shipping to growing is certainly a bit of a roller coaster. But we're all on the roller coaster together, learning and iterating as quickly as we can. As long as we stick to our values and show up for each other with curiosity, compassion, and collaboration, we can likely overcome just about anything together.Every month we have a tech-debt cleanup day. Every other month we have a company hackathon.¬†You Can Grow With UsWe want you to grow with us as much as you desire. As we scale, you‚Äôll be able to grow into almost any role you can imagine. Want to become a team lead? We‚Äôll help train you. Want to become a manager? We‚Äôll make it happen. Want to be an executive? Let‚Äôs figure that out. We want you to be with us as long as you are extremely happy. If we get to place were you aren‚Äôt happy, we‚Äôll do everything we can to help you find a place where you are.¬†Our Code of ExcellenceGo above and beyond. We‚Äôre not here to half-way do anything. If we‚Äôre going to do something, we‚Äôre going to do a stellar job.Tell the truth even when it hurts. We don‚Äôt tell white lies, and we don‚Äôt deceive. Even when it costs.Take care of you and yours first, work second. Nothing matters more than family and close relationships. We never sacrifice them for work.Treat people better than they deserve. Kindness and generosity guides how we treat everyone, including teammates and customers.Give and receive feedback. Feedback is essential for growth. We highly value giving and receiving informal, constructive feedback between all members of the team, and then taking prompt action on that feedback.Have a life outside work. It can be anything, hobbies, side projects, reading, etc. As long as you have something and work isn‚Äôt all you live for.Eradicate stress. Stress is a killer, and we work to eliminate it through any means, including systems, exercise, and meditation.Nothing is impossible. We believe we can create any future we imagine, and we lean into solving the things that seem impossible.Build a legacy. We are here to do our very best work. Work that will inspire generations for years to come.¬†Salary & Benefits32 Hour Work Week - More and more companies are finding that people accomplish the same amount of work in 32 hours as in 40 hours.Salary: $110k ‚Äî $145k USD (same as our engineering roles)0.75% ‚Äî 1% Equity Stock Options. You‚Äôll be a $20+ millionaire if our growth continues like it isMinimum 4 Weeks PTO - It's critical to have good work life balance, so you must take at least 4 weeks PTO each year.Fully RemoteHealth Insurance Fully Paid For401k - We‚Äôre still working out the details on this, but will get it nailed down asap if it‚Äôs important to youMenstrual Leave - There's no use trying to be productive when you are suffering. Take the day(s) off as PTO, no explanation needed.Unlimited Sick Leave - If you are feeling crappy, you aren't going to be doing your best work. So rest, get better, then come back energized.2+ In-Person Company Retreats Per YearOpen Source - We are passionate about open-source and encourage you to contribute on company time to anything that will benefit the company.Equipment - We'll make sure you have all the equipment you need to have an ergonomic, productive environment, including a standing desk and external monitors.Conferences - We're a big fan of in-person conference experiences, and encourage you to speak at and attend them. We'll fully pay for you to attend 2 conferences per year.Education - Budget for books or courses that are at least tangentially related to your work.¬†¬†üî•Please apply here üëâ https://airtable.com/shrPet5euUinQ0uP4 üëà
Our process:You submit the application45 minute zoom with Brandon, CEO45 minute technical interview with Mina, CTONo LeetCode garbage ‚Äî we‚Äôll offer you a range of options so you can choose a style that you‚Äôll do best at45 minute technical interview with Camila1 hour zoom with Brandon, CEO ‚Äî a deep dive on your experience, devrel strategy, tactics, and information architectureAnother short call with Brandon for both of us to ask and answer questions in preparation for making an offer¬†üì£If you‚Äôd like to hear about future job openings, sign up here.¬†"
https://news.ycombinator.com/rss,"Porth, It's Like Forth but in Python",https://gitlab.com/tsoding/porth,Comments,"






P



porth






Project ID: 30419193








Star
250






1,189 Commits

1 Branch

0 Tags

16.1 MB Project Storage








Concatenative Programming Language for Computers


Read more
























Find file




Select Archive Format




Download source code


zip
tar.gz
tar.bz2
tar









Clone






Clone with SSH










Clone with HTTPS











Open in your IDE



Visual Studio Code (SSH)




Visual Studio Code (HTTPS)




IntelliJ IDEA (SSH)




IntelliJ IDEA (HTTPS)







Copy HTTPS clone URL





Copy SSH clone URLgit@gitlab.com:tsoding/porth.git


Copy HTTPS clone URLhttps://gitlab.com/tsoding/porth.git








README

MIT License

CONTRIBUTING





"
https://news.ycombinator.com/rss,I analyzed shuffling in a million games of MtG Arena (2020),https://old.reddit.com/r/MagicArena/comments/b21u3n/i_analyzed_shuffling_in_a_million_games/,Comments,"



Too Many Requests



whoa there, pardner!
we're sorry, but you appear to be a bot and we've seen too many requests
from you lately. we enforce a hard speed limit on requests that appear to come
from bots to prevent abuse.
if you are not a bot but are spoofing one via your browser's user agent
string: please change your user agent string to avoid seeing this message
again.
please wait 1 second(s) and try again.
as a reminder to developers, we recommend that clients make no
    more than one
    request every two seconds to avoid seeing this message.


"
https://news.ycombinator.com/rss,Faster than the filesystem (2021),https://www.sqlite.org/fasterthanfs.html,Comments,"




35% Faster Than The Filesystem









Small. Fast. Reliable.Choose any three.



Home
Menu
About
Documentation
Download
License
Support
Purchase

Search




About
Documentation
Download
Support
Purchase





Search Documentation
Search Changelog










35% Faster Than The Filesystem



‚ñ∫
Table Of Contents

1. Summary
1.1. Caveats
1.2. Related Studies
2. How These Measurements Are Made
2.1. Read Performance Measurements
2.2. Write Performance Measurements
2.3. Variations
3. General Findings
4. Additional Notes
4.1. Compiling And Testing on Android




1. Summary
SQLite reads and writes small blobs (for example, thumbnail images)
35% faster¬π than the same blobs
can be read from or written to individual files on disk using
fread() or fwrite().

Furthermore, a single SQLite database holding
10-kilobyte blobs uses about 20% less disk space than
storing the blobs in individual files.

The performance difference arises (we believe) because when
working from an SQLite database, the open() and close() system calls
are invoked only once, whereas
open() and close() are invoked once for each blob
when using blobs stored in individual files.  It appears that the
overhead of calling open() and close() is greater than the overhead
of using the database.  The size reduction arises from the fact that
individual files are padded out to the next multiple of the filesystem
block size, whereas the blobs are packed more tightly into an SQLite
database.


The measurements in this article were made during the week of 2017-06-05
using a version of SQLite in between 3.19.2 and 3.20.0.  You may expect
future versions of SQLite to perform even better.

1.1. Caveats


¬πThe 35% figure above is approximate.  Actual timings vary
depending on hardware, operating system, and the
details of the experiment, and due to random performance fluctuations
on real-world hardware.  See the text below for more detail.
Try the experiments yourself.  Report significant deviations on
the SQLite forum.


The 35% figure is based on running tests on every machine
that the author has easily at hand.
Some reviewers of this article report that SQLite has higher 
latency than direct I/O on their systems.  We do not yet understand
the difference.  We also see indications that SQLite does not
perform as well as direct I/O when experiments are run using
a cold filesystem cache.


So let your take-away be this: read/write latency for
SQLite is competitive with read/write latency of individual files on
disk.  Often SQLite is faster.  Sometimes SQLite is almost
as fast.  Either way, this article disproves the common
assumption that a relational database must be slower than direct
filesystem I/O.

1.2. Related Studies

Jim Gray
and others studied the read performance of BLOBs
versus file I/O for Microsoft SQL Server and found that reading BLOBs 
out of the 
database was faster for BLOB sizes less than between 250KiB and 1MiB.
(Paper).
In that study, the database still stores the filename of the content even
if the content is held in a separate file.  So the database is consulted
for every BLOB, even if it is only to extract the filename.  In this
article, the key for the BLOB is the filename, so no preliminary database
access is required.  Because the database is never used at all when
reading content from individual files in this article, the threshold
at which direct file I/O becomes faster is smaller than it is in Gray's
paper.


The Internal Versus External BLOBs article on this website is an
earlier investigation (circa 2011) that uses the same approach as the
Jim Gray paper ‚Äî storing the blob filenames as entries in the
database ‚Äî but for SQLite instead of SQL Server.



2. How These Measurements Are Made
I/O performance is measured using the
kvtest.c program
from the SQLite source tree.
To compile this test program, first gather the kvtest.c source file
into a directory with the SQLite amalgamation source
files ""sqlite3.c"" and ""sqlite3.h"".  Then on unix, run a command like
the following:

gcc -Os -I. -DSQLITE_DIRECT_OVERFLOW_READ \
  kvtest.c sqlite3.c -o kvtest -ldl -lpthread

Or on Windows with MSVC:

cl -I. -DSQLITE_DIRECT_OVERFLOW_READ kvtest.c sqlite3.c

Instructions for compiling for Android
are shown below.


Use the resulting ""kvtest"" program to
generate a test database with 100,000 random uncompressible
blobs, each with a random
size between 8,000 and 12,000 bytes
using a command like this:

./kvtest init test1.db --count 100k --size 10k --variance 2k


If desired, you can verify the new database by running this command:

./kvtest stat test1.db


Next, make copies of all the blobs into individual files in a directory
using a command like this:

./kvtest export test1.db test1.dir


At this point, you can measure the amount of disk space used by
the test1.db database and the space used by the test1.dir directory
and all of its content.  On a standard Ubuntu Linux desktop, the
database file will be 1,024,512,000 bytes in size and the test1.dir
directory will use 1,228,800,000 bytes of space (according to ""du -k""),
about 20% more than the database.


The ""test1.dir"" directory created above puts all the blobs into a single
folder.  It was conjectured that some operating systems would perform 
poorly when a single directory contains 100,000 objects.  To test this,
the kvtest program can also store the blobs in a hierarchy of folders with no
more than 100 files and/or subdirectories per folder.  The alternative
on-disk representation of the blobs can be created using the --tree
command-line option to the ""export"" command, like this:

./kvtest export test1.db test1.tree --tree


The test1.dir directory will contain 100,000 files
with names like ""000000"", ""000001"", ""000002"" and so forth but the
test1.tree directory will contain the same files in subdirectories like
""00/00/00"", ""00/00/01"", and so on.  The test1.dir and test1.test
directories take up approximately the same amount of space, though
test1.test is very slightly larger due to the extra directory entries.


All of the experiments that follow operate the same with either 
""test1.dir"" or ""test1.tree"".  Very little performance difference is
measured in either case, regardless of operating system.


Measure the performance for reading blobs from the database and from
individual files using these commands:

./kvtest run test1.db --count 100k --blob-api
./kvtest run test1.dir --count 100k --blob-api
./kvtest run test1.tree --count 100k --blob-api


Depending on your hardware and operating system, you should see that reads 
from the test1.db database file are about 35% faster than reads from 
individual files in the test1.dir or test1.tree folders.  Results can vary
significantly from one run to the next due to caching, so it is advisable
to run tests multiple times and take an average or a worst case or a best
case, depending on your requirements.

The --blob-api option on the database read test causes kvtest to use
the sqlite3_blob_read() feature of SQLite to load the content of the
blobs, rather than running pure SQL statements.  This helps SQLite to run
a little faster on read tests.  You can omit that option to compare the
performance of SQLite running SQL statements.
In that case, the SQLite still out-performs direct reads, though
by not as much as when using sqlite3_blob_read().
The --blob-api option is ignored for tests that read from individual disk
files.


Measure write performance by adding the --update option.  This causes
the blobs are overwritten in place with another random blob of
exactly the same size.

./kvtest run test1.db --count 100k --update
./kvtest run test1.dir --count 100k --update
./kvtest run test1.tree --count 100k --update


The writing test above is not completely fair, since SQLite is doing
power-safe transactions whereas the direct-to-disk writing is not.
To put the tests on a more equal footing, add either the --nosync
option to the SQLite writes to disable calling fsync() or
FlushFileBuffers() to force content to disk, or using the --fsync option
for the direct-to-disk tests to force them to invoke fsync() or
FlushFileBuffers() when updating disk files.


By default, kvtest runs the database I/O measurements all within
a single transaction.  Use the --multitrans option to run each blob
read or write in a separate transaction.  The --multitrans option makes
SQLite much slower, and uncompetitive with direct disk I/O.  This
option proves, yet again, that to get the most performance out of
SQLite, you should group as much database interaction as possible within
a single transaction.


There are many other testing options, which can be seen by running
the command:

./kvtest help

2.1. Read Performance Measurements
The chart below shows data collected using 
kvtest.c on five different
systems:


Win7: A circa-2009 Dell Inspiron laptop, Pentium dual-core
    at 2.30GHz, 4GiB RAM, Windows7.
Win10: A 2016 Lenovo YOGA 910, Intel i7-7500 at 2.70GHz,
    16GiB RAM, Windows10.
Mac: A 2015 MacBook Pro, 3.1GHz intel Core i7, 16GiB RAM,
    MacOS 10.12.5
Ubuntu: Desktop built from Intel i7-4770K at 3.50GHz, 32GiB RAM,
    Ubuntu 16.04.2 LTS
Android: Galaxy S3, ARMv7, 2GiB RAM

All machines use SSD except Win7 which has a
hard-drive. The test database is 100K blobs with sizes uniformly
distributed between 8K and 12K, for a total of about 1 gigabyte
of content.  The database page size
is 4KiB.  The -DSQLITE_DIRECT_OVERFLOW_READ compile-time option was
used for all of these tests.
Tests were run multiple times.
The first run was used to warm up the cache and its timings were discarded.


The chart below shows average time to read a blob directly from the
filesystem versus the time needed to read the same blob from the SQLite 
database.
The actual timings vary considerably from one system to another 
(the Ubuntu desktop is much
faster than the Galaxy S3 phone, for example).  
This chart shows the ratio of the
times needed to read blobs from a file divided by the time needed to
from the database.  The left-most column in the chart is the normalized
time to read from the database, for reference.


In this chart, an SQL statement (""SELECT v FROM kv WHERE k=?1"") 
is prepared once.  Then for each blob, the blob key value is bound 
to the ?1 parameter and the statement is evaluated to extract the
blob content.


The chart shows that on Windows10, content can be read from the SQLite
database about 5 times faster than it can be read directly from disk.
On Android, SQLite is only about 35% faster than reading from disk.






Chart 1:  SQLite read latency relative to direct filesystem reads.
100K blobs, avg 10KB each, random order using SQL


The performance can be improved slightly by bypassing the SQL layer
and reading the blob content directly using the
sqlite3_blob_read() interface, as shown in the next chart:






Chart 2:  SQLite read latency relative to direct filesystem reads.
100K blobs, avg size 10KB, random order
using sqlite3_blob_read().


Further performance improves can be made by using the
memory-mapped I/O feature of SQLite.  In the next chart, the
entire 1GB database file is memory mapped and blobs are read
(in random order) using the sqlite3_blob_read() interface.
With these optimizations, SQLite is twice as fast as Android
or MacOS-X and over 10 times faster than Windows.






Chart 3:  SQLite read latency relative to direct filesystem reads.
100K blobs, avg size 10KB, random order
using sqlite3_blob_read() from a memory-mapped database.


The third chart shows that reading blob content out of SQLite can be
twice as fast as reading from individual files on disk for Mac and
Android, and an amazing ten times faster for Windows.

2.2. Write Performance Measurements

Writes are slower.
On all systems, using both direct I/O and SQLite, write performance is
between 5 and 15 times slower than reads.


Write performance measurements were made by replacing (overwriting)
an entire blob with a different blob.  All of the blobs in these
experiment are random and incompressible.  Because writes are so much
slower than reads, only 10,000 of the 100,000 blobs in the database
are replaced.  The blobs to be replaced are selected at random and
are in no particular order.


The direct-to-disk writes are accomplished using fopen()/fwrite()/fclose().
By default, and in all the results shown below, the OS filesystem buffers are
never flushed to persistent storage using fsync() or
FlushFileBuffers().  In other words, there is no attempt to make the
direct-to-disk writes transactional or power-safe.
We found that invoking fsync() or FlushFileBuffers() on each file
written causes direct-to-disk storage
to be about 10 times or more slower than writes to SQLite.


The next chart compares SQLite database updates in WAL mode
against raw direct-to-disk overwrites of separate files on disk.
The PRAGMA synchronous setting is NORMAL.
All database writes are in a single transaction.
The timer for the database writes is stopped after the transaction
commits, but before a checkpoint is run.
Note that the SQLite writes, unlike the direct-to-disk writes,
are transactional and power-safe, though because the synchronous
setting is NORMAL instead of FULL, the transactions are not durable.






Chart 4:  SQLite write latency relative to direct filesystem writes.
10K blobs, avg size 10KB, random order,
WAL mode with synchronous NORMAL,
exclusive of checkpoint time


The android performance numbers for the write experiments are omitted
because the performance tests on the Galaxy S3 are so random.  Two
consecutive runs of the exact same experiment would give wildly different
times.  And, to be fair, the performance of SQLite on android is slightly
slower than writing directly to disk.


The next chart shows the performance of SQLite versus direct-to-disk
when transactions are disabled (PRAGMA journal_mode=OFF)
and PRAGMA synchronous is set to OFF.  These settings put SQLite on an
equal footing with direct-to-disk writes, which is to say they make the
data prone to corruption due to system crashes and power failures.






Chart 5:  SQLite write latency relative to direct filesystem writes.
10K blobs, avg size 10KB, random order,
journaling disabled, synchronous OFF.


In all of the write tests, it is important to disable anti-virus software
prior to running the direct-to-disk performance tests.  We found that
anti-virus software slows down direct-to-disk by an order of magnitude
whereas it impacts SQLite writes very little.  This is probably due to the
fact that direct-to-disk changes thousands of separate files which all need
to be checked by anti-virus, whereas SQLite writes only changes the single
database file.

2.3. Variations
The -DSQLITE_DIRECT_OVERFLOW_READ compile-time option causes SQLite
to bypass its page cache when reading content from overflow pages.  This
helps database reads of 10K blobs run a little faster, but not all that much
faster.  SQLite still holds a speed advantage over direct filesystem reads
without the SQLITE_DIRECT_OVERFLOW_READ compile-time option.

Other compile-time options such as using -O3 instead of -Os or
using -DSQLITE_THREADSAFE=0 and/or some of the other
recommended compile-time options might help SQLite to run even faster
relative to direct filesystem reads.

The size of the blobs in the test data affects performance.
The filesystem will generally be faster for larger blobs, since
the overhead of open() and close() is amortized over more bytes of I/O,
whereas the database will be more efficient in both speed and space
as the average blob size decreases.


3. General Findings


SQLite is competitive with, and usually faster than, blobs stored in
separate files on disk, for both reading and writing.


SQLite is much faster than direct writes to disk on Windows
when anti-virus protection is turned on.  Since anti-virus software
is and should be on by default in Windows, that means that SQLite
is generally much faster than direct disk writes on Windows.


Reading is about an order of magnitude faster than writing, for all
systems and for both SQLite and direct-to-disk I/O.


I/O performance varies widely depending on operating system and hardware.
Make your own measurements before drawing conclusions.


Some other SQL database engines advise developers to store blobs in separate
files and then store the filename in the database.  In that case, where
the database must first be consulted to find the filename before opening
and reading the file, simply storing the entire blob in the database
gives much faster read and write performance with SQLite.
See the Internal Versus External BLOBs article for more information.

4. Additional Notes

4.1. Compiling And Testing on Android

The kvtest program is compiled and run on Android as follows.
First install the Android SDK and NDK.  Then prepare a script
named ""android-gcc"" that looks approximately like this:

#!/bin/sh
#
NDK=/home/drh/Android/Sdk/ndk-bundle
SYSROOT=$NDK/platforms/android-16/arch-arm
ABIN=$NDK/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin
GCC=$ABIN/arm-linux-androideabi-gcc
$GCC --sysroot=$SYSROOT -fPIC -pie $*

Make that script executable and put it on your $PATH.  Then
compile the kvtest program as follows:

android-gcc -Os -I. kvtest.c sqlite3.c -o kvtest-android

Next, move the resulting kvtest-android executable to the Android
device:

adb push kvtest-android /data/local/tmp

Finally use ""adb shell"" to get a shell prompt on the Android device,
cd into the /data/local/tmp directory, and begin running the tests
as with any other unix host.
This page last modified on  2021-03-01 12:55:48 UTC 
"
https://news.ycombinator.com/rss,The Inner Beauty of Basic Electronics,https://spectrum.ieee.org/open-circuits,Comments,"The Inner Beauty of Basic Electronics - IEEE SpectrumIEEE.orgIEEE Xplore Digital LibraryIEEE StandardsMore SitesSign InJoin IEEEThe Inner Beauty of Basic ElectronicsShareFOR THE TECHNOLOGY INSIDERSearch: Explore by topicAerospaceArtificial IntelligenceBiomedicalComputingConsumer ElectronicsEnergyHistory of TechnologyRoboticsSemiconductorsSensorsTelecommunicationsTransportationIEEE SpectrumFOR THE TECHNOLOGY INSIDERTopicsAerospaceArtificial IntelligenceBiomedicalComputingConsumer ElectronicsEnergyHistory of TechnologyRoboticsSemiconductorsSensorsTelecommunicationsTransportationSectionsFeaturesNewsOpinionCareersDIYThe Big PictureEngineering ResourcesMoreSpecial ReportsCollectionsExplainersPodcastsVideosNewslettersTop Programming LanguagesRobots GuideFor IEEE MembersCurrent IssueMagazine ArchiveThe InstituteTI ArchiveFor IEEE MembersCurrent IssueMagazine ArchiveThe InstituteTI ArchiveIEEE SpectrumAbout UsContact UsReprints & PermissionsAdvertisingFollow IEEE SpectrumSupport IEEE SpectrumIEEE Spectrum is the flagship publication of the IEEE ‚Äî the world‚Äôs largest professional organization devoted to engineering and applied sciences. Our articles, podcasts, and infographics inform our readers about developments in technology, engineering, and science.Join IEEESubscribeAbout IEEEContact & SupportAccessibilityNondiscrimination PolicyTermsIEEE Privacy Policy¬© Copyright 2023 IEEE ‚Äî All rights reserved. A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.IEEE websites place cookies on your device to give you the best user experience. By using our websites, you agree to the placement of these cookies. To learn more, read our Privacy Policy.
                        view privacy policy
                    
                    accept & close
                Enjoy more free content and benefits by creating an accountSaving articles to read later requires an IEEE Spectrum accountThe Institute content is only available for membersDownloading full PDF issues is exclusive for IEEE MembersAccess to Spectrum's Digital Edition is exclusive for IEEE MembersFollowing topics is a feature exclusive for IEEE MembersAdding your response to an article requires an IEEE Spectrum accountCreate an account to access more content and features on IEEE Spectrum, including the ability to save articles to read later, download Spectrum Collections, and participate in conversations with readers and editors. For more exclusive content and features, consider Joining IEEE.Join the world‚Äôs largest professional organization devoted to engineering and applied sciences and get access to all of Spectrum‚Äôs articles, archives, PDF downloads, and other benefits. Learn more ‚ÜíCREATE AN ACCOUNTSIGN INJOIN IEEESIGN INCloseAccess Thousands of Articles ‚Äî Completely FreeCreate an account and get exclusive content and features: Save articles, download collections, and talk to tech insiders ‚Äî all free! For full access and benefits, join IEEE as a paying member.CREATE AN ACCOUNTSIGN INConsumer ElectronicsTopicMagazineTypeFeature
        The Inner Beauty of Basic Electronics
    Open Circuits showcases the surprising complexity of passive componentsEric SchlaepferWindell H. Oskay20h5 min readBlueEric Schlaepfer was trying to fix a broken piece of test equipment when he came across the cause of the problem‚Äîa troubled tantalum capacitor. The component had somehow shorted out, and he wanted to know why. So he polished it down for a look inside. He never found the source of the short, but he and his collaborator, Windell H. Oskay, discovered something even better: a breathtaking hidden world inside electronics. What followed were hours and hours of polishing, cleaning, and photography that resulted in Open Circuits: The Inner Beauty of Electronic Components (No Starch Press, 2022), an excerpt of which follows. As the authors write, everything about these components is deliberately designed to meet specific technical needs, but that design leads to ‚Äúaccidental beauty: the emergent aesthetics of things you were never expected to see.‚Äù

	From a book that spans the wide world of electronics, what we at 
	IEEE Spectrum found surprisingly compelling were the insides of things we don‚Äôt spend much time thinking about, passive components. Transistors, LEDs, and other semiconductors may be where the action is, but the simple physics of resistors, capacitors, and inductors have their own sort of splendor. 
            
                High-Stability Film Resistor
            
            
        All photos by Eric Schlaepfer & Windell H. OskayThis high-stability film resistor, about 4 millimeters in diameter, is made in much the same way as its inexpensive carbon-film cousin, but with exacting precision. A ceramic rod is coated with a fine layer of resistive film (thin metal, metal oxide, or carbon) and then a perfectly uniform helical groove is machined into the film.Instead of coating the resistor with an epoxy, it‚Äôs hermetically sealed in a lustrous little glass envelope. This makes the resistor more robust, ideal for specialized cases such as precision reference instrumentation, where long-term stability of the resistor is critical. The glass envelope provides better isolation against moisture and other environmental changes than standard coatings like epoxy.
            
                15-Turn Trimmer Potentiometer
            
            
        It takes 15 rotations of an adjustment screw to move a 15-turn trimmer potentiometer from one end of its resistive range to the other. Circuits that need to be adjusted with fine resolution control use this type of trimmer pot instead of the single-turn variety.The resistive element in this trimmer is a strip of cermet‚Äîa composite of ceramic and metal‚Äîsilk-screened on a white ceramic substrate. Screen-printed metal links each end of the strip to the connecting wires. It‚Äôs a flattened, linear version of the horseshoe-shaped resistive element in single-turn trimmers.Turning the adjustment screw moves a plastic slider along a track. The wiper is a spring finger, a spring-loaded metal contact, attached to the slider. It makes contact between a metal strip and the selected point on the strip of resistive film.
            
                Ceramic Disc Capacitor
            
            
        Capacitors are fundamental electronic components that store energy in the form of static electricity. They‚Äôre used in countless ways, including for bulk energy storage, to smooth out electronic signals, and as computer memory cells. The simplest capacitor consists of two parallel metal plates with a gap between them, but capacitors can take many forms so long as there are two conductive surfaces, called electrodes, separated by an insulator.A ceramic disc capacitor is a low-cost capacitor that is frequently found in appliances and toys. Its insulator is a ceramic disc, and its two parallel plates are extremely thin metal coatings that are evaporated or sputtered onto the disc‚Äôs outer surfaces. Connecting wires are attached using solder, and the whole assembly is dipped into a porous coating material that dries hard and protects the capacitor from damage.
            
                Film Capacitor
            
            
        Film capacitors are frequently found in high-quality audio equipment, such as headphone amplifiers, record players, graphic equalizers, and radio tuners. Their key feature is that the dielectric material is a plastic film, such as polyester or polypropylene.The metal electrodes of this film capacitor are vacuum-deposited on the surfaces of long strips of plastic film. After the leads are attached, the films are rolled up and dipped into an epoxy that binds the assembly together. Then the completed assembly is dipped in a tough outer coating and marked with its value.Other types of film capacitors are made by stacking flat layers of metallized plastic film, rather than rolling up layers of film.
            
                Dipped Tantalum Capacitor
            
            
        At the core of this capacitor is a porous pellet of tantalum metal. The pellet is made from tantalum powder and sintered, or compressed at a high temperature, into a dense, spongelike solid.Just like a kitchen sponge, the resulting pellet has a high surface area per unit volume. The pellet is then anodized, creating an insulating oxide layer with an equally high surface area. This process packs a lot of capacitance into a compact device, using spongelike geometry rather than the stacked or rolled layers that most other capacitors use.The device‚Äôs positive terminal, or anode, is connected directly to the tantalum metal. The negative terminal, or cathode, is formed by a thin layer of conductive manganese dioxide coating the pellet.
            
                Axial Inductor
            
            
        Inductors are fundamental electronic components that store energy in the form of a magnetic field. They‚Äôre used, for example, in some types of power supplies to convert between voltages by alternately storing and releasing energy. This energy-efficient design helps maximize the battery life of cellphones and other portable electronics.Inductors typically consist of a coil of insulated wire wrapped around a core of magnetic material like iron or ferrite, a ceramic filled with iron oxide. Current flowing around the core produces a magnetic field that acts as a sort of flywheel for current, smoothing out changes in the current as it flows through the inductor.This axial inductor has a number of turns of varnished copper wire wrapped around a ferrite form and soldered to copper leads on its two ends. It has several layers of protection: a clear varnish over the windings, a light-green coating around the solder joints, and a striking green outer coating to protect the whole component and provide a surface for the colorful stripes that indicate its inductance value.
            
                Power Supply Transformer
            
            
        This transformer has multiple sets of windings and is used in a power supply to create multiple output AC voltages from a single AC input such as a wall outlet.The small wires nearer the center are ‚Äúhigh impedance‚Äù turns of magnet wire. These windings carry a higher voltage but a lower current. They‚Äôre protected by several layers of tape, a copper-foil electrostatic shield, and more tape.The outer ‚Äúlow impedance‚Äù windings are made with thicker insulated wire and fewer turns. They handle a lower voltage but a higher current.All of the windings are wrapped around a black plastic bobbin. Two pieces of ferrite ceramic are bonded together to form the magnetic core at the heart of the transformer.From Your Site ArticlesDell Tried to Hide Bad Capacitors Problem 2003-2005 ‚Ä∫Hands On - IEEE Spectrum ‚Ä∫Watch: Laser Origami Makes Inductors ‚Ä∫Related Articles Around the WebOpen Circuits: The Inner Beauty of Electronic Components: Oskay ... ‚Ä∫Open Circuits | No Starch Press ‚Ä∫Open Circuits ‚Ä∫passive componentsArt of Electronicsresistorscapacitorsinductorsbooks{""imageShortcodeIds"":[]}Eric SchlaepferEric Schlaepfer runs the popular engineering Twitter account @TubeTimeUS, where he posts cross-section photos, shares his retrocomputing and reverse engineering projects, investigates engineering accidents, and even features the occasional vacuum tube or two. He is coauthor of Open Circuits: The Inner Beauty of Electronic Components (No Starch Press, 2022).Windell H. OskayWindell H. Oskay is the cofounder of Evil Mad Scientist Laboratories, where he designs robots for a living. He is coauthor of¬†Open Circuits: The Inner Beauty of Electronic Components¬†(No Starch Press, 2022).The Conversation (0)
        Video Friday: Robots at Night
    13 Jan 20233 min readAerospaceTopicTypeRoboticsNews
        Relativity Space Aims for Orbit
    13 Jan 20234 min readConsumer ElectronicsTopicTypeNews
        Paper Batteries, Blue Quantum Dots, and Other Enabling Technologies from CES 2023
    12 Jan 20233 min readThe InstituteTopicArticleTypeHistory of Technology
        How This Record Company Engineer Invented the CT Scanner
    The machine, made to image the human brain, won him a Nobel PrizeJoanna GoodrichJoanna Goodrich is the associate editor of The Institute, covering the work and accomplishments of IEEE members and IEEE and technology-related events. She has a master's degree in health communications from Rutgers University, in New Brunswick, N.J.12 Jan 20234 min readResearch engineer Godfrey Hounsfield invented the CT scanner to create three-dimensional brain images.
        PA Images/Getty Images
    ieee historyieee tech historyhistory of technologyct scannermedical devicesieee milestonetype:tiThe inspiration for computed tomography (CT) came from a chance conversation that research engineer Godfrey Hounsfield had with a doctor while on vacation in the 1960s. The physician complained that X-ray images of the brain were too grainy and only two-dimensional.Hounsfield worked at Electrical and Musical Industry in Hayes, England. Best known for producing and selling Beatles records, EMI also developed electronic equipment. Keep Reading ‚ÜìShow lessConsumer ElectronicsTopicTypeComputingSponsored Article
        Building the Future of Smart Home Security
    Engineers must invent new technology to enhance security products‚Äô abilitiesNate WilfertNate Wilfert is Vice President of Software Engineering at SimpliSafe.22 Mar 20224 min readIn this article, SimpliSafe‚Äôs VP of Software Engineering discusses his team‚Äôs focus on creating a safer future through enhanced technology.
        SimpliSafe
    smart homeiotconnected homesecuritysimplisafeThis is a sponsored article brought to you by SimpliSafe.It‚Äôs nearly impossible to find a household today that doesn‚Äôt have at least one connected smart home device installed. From video doorbells to robot vacuums, automated lighting, and voice assistants, smart home technology has invaded consumers‚Äô homes and shows no sign of disappearing anytime soon. Indeed, according to a study conducted by consulting firm Parks Associates, smart home device adoption has increased by more than 64 percent in the past two years, with 23 percent of households owning three or more smart home devices. This is particularly true for devices that provide security with 38 percent of Americans owning a home security product. This percentage is likely to increase as 7 in 10 homebuyers claimed that safety and security was the primary reason, after convenience, that they would be seeking out smart homes, according to a report published by Security.org last year.As the demand for smart home security grows, it‚Äôs pertinent that the engineers who build the products and services that keep millions of customers safe continue to experiment with new technologies that could enhance overall security and accessibility. At SimpliSafe, an award-winning home security company based in Boston, Mass., it is the pursuit of industry-leading protection that drives the entire organization to continue innovating.In this article, Nate Wilfert, VP of Software Engineering at SimpliSafe, discusses the complex puzzles his team is solving on a daily basis‚Äîsuch as applying artificial intelligence (AI) technology into cameras and building load-balancing solutions to handle server traffic‚Äîto push forward the company‚Äôs mission to make every home secure and advance the home security industry as a whole.Keep Reading ‚ÜìShow less
        Trending Stories
    The most-read stories on IEEE Spectrum right nowThe InstituteTopicArticleTypeHistory of Technology
        How This Record Company Engineer Invented the CT Scanner
    12 Jan 20234 min readAerospaceTopicTypeRoboticsNews
        Relativity Space Aims for Orbit
    13 Jan 20234 min readConsumer ElectronicsTopicTypeNews
        Paper Batteries, Blue Quantum Dots, and Other Enabling Technologies from CES 2023
    12 Jan 20233 min readConsumer ElectronicsTopicTypeNews
        CES 2023‚Äôs Four Wildest‚Äîand Catchiest‚ÄîGadgets
    11 Jan 20233 min readThe InstituteTopicTypeOpinionTelecommunications
        Examining the Impact of 6G Telecommunications on Society
    10 Jan 20233 min readSensorsTopicArtificial IntelligenceTypeNews
        Spray-on Smart Skin Reads Typing and Hand Gestures
    11 Jan 20233 min readTelecommunicationsTopicMagazineTypeFeature
        How Police Exploited the Capitol Riot‚Äôs Digital Records
    06 Jan 202311 min readConsumer ElectronicsTopicTypeNewsTransportation
        The Best Tech of CES 2023
    09 Jan 20236 min read"
https://news.ycombinator.com/rss,Running KDE Plasma on RISC-V VisionFive-2,https://cordlandwehr.wordpress.com/2023/01/14/running-plasma-on-visionfive-2/,Comments,"


Running Plasma on¬†VisionFive-2 

New year, new RISC-V Yocto blog post \o/ When I wrote my last post, I did really not expect my brand new VisionFive-2 board to find its way to me so soon‚Ä¶ But well, a week ago it was suddenly there. While unpacking I shortly pondered over my made plans to prepare a Plasma Bigscreen RaspberryPi 4 demo board for this year‚Äôs FOSDEM.
Obvious conclusion: ‚ÄúScrew it! Let‚Äôs do the demo on the VisionFive-2!‚Äù ‚Äî And there we are:
After some initial bumpy steps to boot up a first self-compiled U-boot and Kernel (If you unbox a new board, you need to do a bootloader and firmware update first! Otherwise it will not boot the latest VisionFive Kernel) it was surprisingly easy to prepare Yocto to build a core-image-minimal that really boots the whole way up.
Unfortunately after these first happy hours, the last week was full of handling the horrors of closed-source binary drivers for the GPU. Even though Imagination promised to provide an open source driver at some time, right now there is only the solution to use the closed source PVR driver. After quite a lot of trying, guessing and and comparing the boot and init sequences of the reference image to the dark screen in front of me, I came up with:

a new visionfive2-graphics Yocto package for the closed source driver blobs
a fork of Mesa that uses a very heavy patch set for the PVR driver adaptions; all patches are taken from the VisionFive 2 buildroot configurations
and a couple of configs for making the system start with doing an initial modeset

The result right now:

VisionFive-2 device with Plasma-Bigscreen (KWin running via Wayland), SD card image built via Yocto, KDE software via KDE‚Äôs Yocto layers, Kernel and U-Boot being the latest fork versions from StarFive
Actually, the full UI even feels much smoother than on my RPi4, which is quite cool. I am not sure where I will end in about 3 weeks with some more debugging and patching. But I am very confident that you can see a working RISC-V board with onboard GPU and running Plasma Shell, when you visit the KDE stall at FOSDEM in February üòâ
For people who are interested in Yocto, here is the WIP patch set: https://github.com/riscv/meta-riscv/pull/382
Share this:TwitterFacebookLike this:Like Loading...

Related
 

Posted on January 14, 2023January 14, 2023Author cordlandwehrCategories KDE, YoctoTags KDE 



Leave a Reply Cancel reply


Enter your comment here...




Fill in your details below or click an icon to log in:







 



 



 






 
 


Email (required) (Address never made public)



Name (required)



Website
















			You are commenting using your WordPress.com account.			
				(¬†Log¬†Out¬†/¬†
				Change¬†)
			
















			You are commenting using your Twitter account.			
				(¬†Log¬†Out¬†/¬†
				Change¬†)
			
















			You are commenting using your Facebook account.			
				(¬†Log¬†Out¬†/¬†
				Change¬†)
			






Cancel
Connecting to %s




 Notify me of new comments via email. Notify me of new posts via email.
 



Œî 



Post navigation
Previous Previous post: Getting a First Picture on my Nezha RISC-V¬†Board

"
https://news.ycombinator.com/rss,The Bibites: Artificial Life Simulation,https://leocaussan.itch.io/the-bibites,Comments,"The Bibites by The BibitesFollow The BibitesFollowFollowing The BibitesFollowingAdd To CollectionCollectionCommentsDevlogRelated gamesRelatedThe BibitesA downloadable project for Windows, macOS, and LinuxDownload NowName your own priceWelcome everyone!¬†
This is The Bibites ¬†
A simulation where you are able to watch evolution happen before your very eyes!¬†
Each¬†bibite (the small critters you see on the screen) starts off with an empty brain (they do nothing) and pretty basic genes (they all look alike).¬†
Through random mutations, one can be spawned with a brain connection that will link two neurons and might trigger a behavior, like going forward, which will allow them to eat food, and then reproduce with the energy gained.
You have reproduction, mutations, and natural selection, which leads to ...¬†

With time, this develops into complex behaviors, like following¬†pheromone trails to hunt other bibites, or stockpiling food in a specific area of the map.¬†

Present Features
VisionProcedural Sprites (generating a custom sprite for each bibite from their genes)
Self-awareness (state, health, energy, etc.)Pheromones (producing and sensing)Grabbing and Throwing stuff (pellets and other bibites)Materials and Digestion SimulationRealistic Energy System
The simulation is also interactive, allowing you to YEET bibites and pellets around. You can selectively kill bibites, feed them, force the laying of eggs, and so much more.
It's also highly customizable, allowing you to test a nearly infinite number of scenarios. How will they evolve if there is no drag (no friction)? What about if moving is extremely energy-costly? It's your job to test it all, I sure can't do it¬†by myself.
I'LL STATE CLEARLY THAT THIS IS THE REGULAR VERSION. I TRIED TO DISABLE ""name your own price"" AND SET IT TO¬†0.00$ BUT IT DON'T SEEM TO WORK...I ENCOURAGE YOU TO DOWNLOAD THIS FOR FREE, ONLY PAY SOMETHING IF YOU WANT TO THROW MONEY AT ME FOR NO OTHER REASON THAN TO SUPPORT THIS PROJECT. The best way to do so is to subscribe to my Patreon to provide me with reliable support and have access to the alpha updates as I develop them:¬†
Become a Patron to get alpha updates!¬†

Follow the development and see additional content on Youtube

Follow me on Twitter to see... whatever I do there

Join the subreddit community

Upcoming features¬†
Module-based systems for unbounded evolution and incredible performancesBiomes (environmental simulation)Evolving ecosystems (the plants/food evolves too)Rocks (Movable objects)And much more!

After trying it out, please give me some feedback

Or report bugs
More informationUpdated 28 days agoStatusIn developmentPlatformsWindows, macOS, LinuxRatingRated 4.6 out of 5 stars(69 total ratings)AuthorThe BibitesGenreSimulationMade withUnityTags2D, artificial-intelligence, evolution, interactive, Life Simulation, Pixel Art, Procedural Generation, Sandbox, UnityAverage sessionA few hoursLanguagesEnglishInputsKeyboard, MouseMultiplayerLocal multiplayerPlayer countSingleplayerLinksYouTube, Patreon, Twitter, CommunityDownloadDownload NowName your own priceClick download now to get access to the following files:The Bibites 0.4.2 - Windows 64x.zip 30 MB  The Bibites 0.4.2 - Linux.zip 41 MB  The Bibites 0.4.2 - Mac Universal.zip 36 MB  The Bibites 0.4.2 - Windows 32x.zip 27 MB  The Bibites 0.5.0 - Linux.zip 84 MB  The Bibites 0.5.0 - Windows 32x.zip 70 MB  The Bibites 0.5.0 - Mac Universal.zip 98 MB  The Bibites 0.5.0 - Windows 64x.zip 73 MB  Development logThe Bibites 0.5.0: Modernity and Progress 28 days agoThe Bibites  v0.4.2: Balance and stability Jun 19, 2022The Bibites  v0.4.1 Mar 28, 2022The Bibites 0.3.0 : Artificial Life With Herding and Viruses Jun 25, 2021It's official, this is launch üöÄüöÄüöÄ! Full-time on The Bibites May 20, 2021Roadmap for the future of the project Ep.3 Procedural Sprites! Jan 24, 2021Roadmap for the future of the project Ep.2 Modules! Jan 11, 2021Roadmap of the future of the Project Ep.1 Dec 28, 2020View all postsCommentsLog in with itch.io to leave a comment.Viewing most recent comments 1 to 40 of 112 ¬∑ Next page ¬∑ Last page Waterloo057 hours agoso dowload the game... from where do i enter to it?Reply Davket00520 hours ago!!!Reply Davket00520 hours agohow the hell do I download itReply Victoria_the_cool4 days agoi cant figure out how to save my progressReply Victoria_the_cool4 days agoyou should probably implement in-game save filesReply Riptides_storm2 days agohit settings top right, save gameleads to a menu where u can name the save file¬†for 0.5 btwReply JoeKing295 days agoWill you add android version? (if it is possible)Reply TheSmartBanana5 days agoIs there an opotion that allows you to paint or upload your own bit parts like texture packs in minecraft?Reply Filipcucumer18 days agoIf i have a problem how do i report it?Reply R0fael25 days ago(+1)It's the best simulator of lifeReply The Bibites25 days ago(+1)Thanks!Reply R0fael23 days ago (1 edit) Can you fix 0 fps when you have more than 100 bibitesReply johnnysmith10 days agoprobably a hardware issue (bad computer)Reply R0fael7 days agono, it can run windows 11Reply Riptides_storm2 days agothat dosn't really determine how good you computer is.Reply coryedora28 days ago(+1)(-3)how I download the game?Reply Crknite!26 days ago(+10)By completing elementary school.Reply Nikki_Devil31 days ago(+2)I wanted to know, will the Linux version also be compiled to Arm64 processors ? I'd really like to use this on my server but as of now I can't and am stuck with my 15yo 32bit pc :,)Reply EKKN38 days ago(+5)Great game, recommended.Even though there are bugs and uncompleted features, it is a decent and very interesting¬†game.Good luck on developing the game!Reply tosety56 days ago(+5)(-1)running on Ubuntu 20 I get a grey screen and cursor, but nothing elseReply Methisa53 days ago (1 edit) (+4)(-1)same for me on steamdeck running steam os. Happened on v 3.0 and 4.2Reply geomagas27 days ago(+1)Same here!Reply Friday_13th56 days ago(+1)I think we rly need some multi core optimizations. Program struggles a lot when there is a high birth rate bibite developedReply baulerbonduc63 days ago(+2)(-1)hey this don't¬†work on linux.please fix if you canReply raktul89 days ago(+1)I like the o & g binding to find oldest and highest generation respectfully, but would love to add more search features/ toggles between multiple bit bits of the same generation. Not sure how to support the development(as in offering my own time/skills to learn and implement)Reply Garyizcool103 days ago(+2)I got to play it once but now its not letting me go on. not sure if its my computer or some sort of glitch but I'm getting a new computer today so we will see if it works then :). if this has happened to anyone else and they know how to solve it could you please help?Reply ThemonstousBibiteengineer111 days ago(-2)how download simReply Skyper111 days ago(+1)Is there a way to save the simulation?Reply Victoria_the_cool2 days agoi hope he adds in-game save filesReply Magnet Boi117 days ago(+5)When will neural netork editor be available?Reply bloodytomb122 days ago(-1)my own thing is how do i use neural network editorReply Phoenix_185128 days ago(+2)How do you download this on linux/chromebook? It will be very helpful if someone can tell me.Reply sssemil130 days ago(+4)To fix the blue screen on Linux, run with the following parameter:¬†-force-vulkan. Cheers.Reply HotNoob130 days ago(+3)
./'The Bibites.x86_64' -force-vulkanWorks! thx.Reply jinnturtle130 days ago (1 edit) (+5)Stuck on a dark blue screen immediately after running the executable, nothing seems to change even if I let it sit there for a while.OS: distro is ArchLinux running on kernell v5.18.15GPU:¬†Nvidia GeForce 1060s ; driver version¬†515.57CPU: Intel i5-9400FGame version in question:¬†The Bibites 0.4.2The game/sim looks quite interesting from what I've seen and read of it, well done!Reply juega331131 days ago(+1)Is this going to be on Android at some point?Reply Fiddeou131 days ago(+4)I'm on mac Mojave. I open the game, and when loading it just stops at 50%Reply damiantyler8a58 days ago(+2)same, why does this happen?Reply ViyWolf56 days ago(+3)You need to put the file into the applications folder.Reply IIDisruptII133 days ago (1 edit) (+4)(-1)Linux version is broken.
After the unity flash screen goes away it get's stuck on a dark blue screen.
Nothing at all, gotta alt f4 or tab out to close.I'm on Ubuntu¬†22.04.1 LTS x86_64, I hope this get's fixed the game looks super dope.Reply TeDe3152 days ago (1 edit) (+2)Add bodyplans and abylity to change them!!!!!!!! PLSReply Morado161 days ago(+3)I'm having difficulties on macOS, the game hangs on 50%; any suggestion?Reply sunusl157 days ago(+1)I am having the same issueReply RottenLynx165 days ago(+3)The game does not work on linux. There's just a dark blue screen after the unity splash screen.Reply someguyplaysitchgames132 days ago(+1)yeah same hereReply R333999174 days ago(+2)make an android version pleaseReply lilyhavok179 days ago(+1)As a fan of Framsticks, Artificial LIfe ENvironment, and AL:RE this is definitely on my watchlist. I love everything so far, and it runs quite well.¬†Do you plan to allow creating Bibites through genetic programming?Reply String Studios184 days agoWhere source code?Reply helsy185 days ago(+1)wont load :( stuck on 50% permanentlyReply neccarus180 days ago(+1)Had this happen. Moved it to another folder location and it worked. Seems like it was a permissions errorReply helsy180 days ago(+1)i'll try it out! :D thanks for the replyReply Daevan189 days ago(+1)I tried to download it, sadly my Mac says it can't search for malware and the software needs to be updated to do that.¬†Reply Robotex4193 days ago (2 edits) (+4)some of my bibites evolved to ""herd"" with individual prey, chasing it to eat its meat once it dies. I kind of think that the herding node is too advanced and powerful (it seems to completely overpower things like ""pellet concentration angle""), it could have an internal neural network which can also evolve and change, or a better option would be to make it an input¬†node like pellet concentration angle¬†which would simply cause the bibite to accelerate towards its herd (but only when moving slower)¬†if connected to the accelerate node,¬†or turn towards its herd, if connected to the rotate node, this option could also come with making all input/output nodes also being able to be modifier nodes, allowing for strands like """"pellet concentration angle""-""herding""-""rotate"""" which would cause the bibite to turn towards pellets by a value altered by how close/far said pellet¬†is from the herdReply Robotex4193 days ago(+3)Here's my idea to make bibites able to be just a bit better: memory, for example,¬†¬†if they see a pellet somewhere but pass by it (and no longer see it). They could, with this adaptation, remember where it is anyway, acting as though they can see it even if it's out of view. A memorized thing would no longer need to be sensed to trigger something like ""pellet concentration angle"". This would all work through a ""commit to memory"" node, which would save the bibites location, direction, and everything it senses to a single memory slot, a ""bite"" if you will, but it would not need any extra nodes to call this info, instead, it would be called by the normal sensing nodes if nothing else is found. there would be a ""memory"" stat, which by default would be 0, and would control the number of ""bites"" a bibite can remember, and once a bibite fills its memory older memories are deleted. There could also be a node that would update/replace a memory slot, and another that would delete a memory slot. This memory system would save many splendid¬†bibites from a lonely fate in the void.Reply Jognh199 days ago(+1)I have a glitch with the latest windows version where no matter how much energy my bibites are getting they have a minimum energy loss. If they end up deep in the negative of energy consumption they still lose energy faster, but there seems to be a point (around 0.1 e/s) where it just doesnt lose less or gain any and all my bibites just dieReply EnchantedAxolotl204 days ago (1 edit) (+1)my strong bibites keep throwing themselves into the void :( they are kinda dumb, but i love this game!Reply Kammcorder205 days ago(+3)i am having the hardest time modding the game, can you please make the guide more easy to understand?Reply Lrapava205 days ago(+2)Fix Linux version plzReplyViewing most recent comments 1 to 40 of 112 ¬∑ Next page ¬∑ Last pageitch.io¬∑View all by The Bibites¬∑Report¬∑Embed¬∑Updated  28 days agoGames ‚Ä∫ Simulation ‚Ä∫ Free"
https://news.ycombinator.com/rss,VToonify: Controllable high-resolution portrait video style transfer,https://github.com/williamyang1991/VToonify,Comments,"








williamyang1991

/

VToonify

Public




 

Notifications



 

Fork
    238




 


          Star
 2.2k
  









        [SIGGRAPH Asia 2022] VToonify: Controllable High-Resolution Portrait Video Style Transfer
      
License





     View license
    






2.2k
          stars
 



238
          forks
 



 


          Star

  





 

Notifications












Code







Issues
7






Pull requests
1






Actions







Projects
0






Security







Insights



 
 



More


 


                  Code
 


                  Issues
 


                  Pull requests
 


                  Actions
 


                  Projects
 


                  Security
 


                  Insights
 







williamyang1991/VToonify









This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.











main





Switch branches/tags










Branches
Tags














View all branches















View all tags













Name already in use









      A tag already exists with the provided branch name. Many Git commands accept both tag and branch names, so creating this branch may cause unexpected behavior. Are you sure you want to create this branch?



    Cancel

    Create








1
branch





0
tags







    Code
 







Local



 Codespaces



  










  Clone





            HTTPS
 
            GitHub CLI
 













        Use Git or checkout with SVN using the web URL.
    













      Work fast with our official CLI.
      Learn more.
    








    Open with GitHub Desktop






    Download ZIP



 
Sign In Required

                Please
                sign in
                to use Codespaces.
              



Launching GitHub Desktop

    If nothing happens, download GitHub Desktop and try again.
  




Launching GitHub Desktop

    If nothing happens, download GitHub Desktop and try again.
  




Launching Xcode

    If nothing happens, download Xcode and try again.
  





Launching Visual Studio Code
Your codespace will open once ready.
There was a problem preparing your codespace, please try again.










Latest commit






 




williamyang1991

Update train_vtoonify_d.py




        ‚Ä¶
      




        cf993aa
      

Nov 15, 2022





Update train_vtoonify_d.py


cf993aa



Git stats







166

                      commits
                    







Files
Permalink




  
    Failed to load latest commit information.


  
 


Type
Name
Latest commit message
Commit time








checkpoint



Update README.md



Sep 12, 2022









data



Add files via upload



Oct 3, 2022









environment



Add files via upload



Sep 14, 2022









model



Update align_all_parallel.py



Oct 2, 2022









notebooks



‰ΩøÁî® Colaboratory ÂàõÂª∫



Oct 7, 2022









output



Update readme.md



Sep 12, 2022









LICENSE.md



Update LICENSE.md



Sep 14, 2022









README.md



Update README.md



Oct 13, 2022









smooth_parsing_map.py



Add files via upload



Sep 12, 2022









style_transfer.py



Add files via upload



Sep 12, 2022









train_vtoonify_d.py



Update train_vtoonify_d.py



Nov 15, 2022









train_vtoonify_t.py



Update train_vtoonify_t.py



Sep 16, 2022









util.py



Update util.py



Oct 1, 2022









vtoonify_model.py



Update vtoonify_model.py



Oct 4, 2022




    View code
 


















VToonify - Official PyTorch Implementation
Updates
Web Demo
Installation
(1) Inference for Image/Video Toonification
Inference Notebook
Pre-trained Models
Style Transfer with VToonify-D
Style Transfer with VToonify-T
(2) Training VToonify
Train VToonify-D
Train VToonify-T
(3) Results
Citation
Acknowledgments





README.md




VToonify - Official PyTorch Implementation





overview.mp4





This repository provides the official PyTorch implementation for the following paper:
VToonify: Controllable High-Resolution Portrait Video Style Transfer
Shuai Yang, Liming Jiang, Ziwei Liu and Chen Change Loy
In ACM TOG (Proceedings of SIGGRAPH Asia), 2022.
Project Page | Paper | Supplementary Video | Input Data and Video Results 




Abstract: Generating high-quality artistic portrait videos is an important and desirable task in computer graphics and vision.
Although a series of successful portrait image toonification models built upon the powerful StyleGAN have been proposed,
these image-oriented methods have obvious limitations when applied to videos, such as the fixed frame size, the requirement of face alignment, missing non-facial details and temporal inconsistency.
In this work, we investigate the challenging controllable high-resolution portrait video style transfer by introducing a novel VToonify framework.
Specifically, VToonify leverages the mid- and high-resolution layers of StyleGAN to render high-quality artistic portraits based on the multi-scale content features extracted by an encoder to better preserve the frame details. The resulting fully convolutional architecture accepts non-aligned faces in videos of variable size as input, contributing to complete face regions with natural motions in the output.
Our framework is compatible with existing StyleGAN-based image toonification models to extend them to video toonification, and inherits appealing features of these models for flexible style control on color and intensity.
This work presents two instantiations of VToonify built upon Toonify and DualStyleGAN for collection-based and exemplar-based portrait video style transfer, respectively.
Extensive experimental results demonstrate the effectiveness of our proposed VToonify framework over existing methods in generating high-quality and temporally-coherent artistic portrait videos with flexible style controls.

Features:
High-Resolution Video (>1024, support unaligned faces) | Data-Friendly (no real training data) | Style Control

Updates

[10/2022] Integrate Gradio interface into Colab notebook. Enjoy the web demo!
[10/2022] Integrated to ü§ó Hugging Face. Enjoy the web demo!
[09/2022] Input videos and video results are released.
[09/2022] Paper is released.
[09/2022] Code is released.
[09/2022] This website is created.

Web Demo
Integrated into Huggingface Spaces ü§ó using Gradio. Try out the Web Demo 
Installation
Clone this repo:
git clone https://github.com/williamyang1991/VToonify.git
cd VToonify
Dependencies:
We have tested on:

CUDA 10.1
PyTorch 1.7.0
Pillow 8.3.1; Matplotlib 3.3.4; opencv-python 4.5.3; Faiss 1.7.1; tqdm 4.61.2; Ninja 1.10.2

All dependencies for defining the environment are provided in environment/vtoonify_env.yaml.
We recommend running this repository using Anaconda (you may need to modify vtoonify_env.yaml to install PyTorch that matches your own CUDA version following https://pytorch.org/):
conda env create -f ./environment/vtoonify_env.yaml
If you have a problem regarding the cpp extention (fused and upfirdn2d), or no GPU is available, you may refer to CPU compatible version.

(1) Inference for Image/Video Toonification
Inference Notebook

To help users get started, we provide a Jupyter notebook found in ./notebooks/inference_playground.ipynb that allows one to visualize the performance of VToonify.
The notebook will download the necessary pretrained models and run inference on the images found in ./data/.
Pre-trained Models
Pre-trained models can be downloaded from Google Drive, Baidu Cloud (access code: sigg) or Hugging Face:


BackboneModelDescription


DualStyleGANcartoonpre-trained VToonify-D models and 317 cartoon style codes


caricaturepre-trained VToonify-D models and 199 caricature style codes


arcanepre-trained VToonify-D models and 100 arcane style codes


comicpre-trained VToonify-D models and 101 comic style codes


pixarpre-trained VToonify-D models and 122 pixar style codes


illustrationpre-trained VToonify-D models and 156 illustration style codes


Toonifycartoonpre-trained VToonify-T model


caricaturepre-trained VToonify-T model


arcanepre-trained VToonify-T model


comicpre-trained VToonify-T model


pixarpre-trained VToonify-T model


Supporting model 


encoder.ptPixel2style2pixel encoder to map real faces into Z+ space of StyleGAN


faceparsing.pthBiSeNet for face parsing from face-parsing.PyTorch


The downloaded models are suggested to be arranged in this folder structure.
The VToonify-D models are named with suffixes to indicate the settings, where

_sXXX: supports only one fixed style with XXX the index of this style.

_s without XXX means the model supports examplar-based style transfer


_dXXX: supports only a fixed style degree of XXX.

_d without XXX means the model supports style degrees ranging from 0 to 1


_c: supports color transfer.

Style Transfer with VToonify-D
‚úî A quick start HERE
Transfer a default cartoon style onto a default face image ./data/077436.jpg:
python style_transfer.py --scale_image
The results are saved in the folder ./output/, where 077436_input.jpg is the rescaled input image to fit VToonify (this image can serve as the input without --scale_image) and 077436_vtoonify_d.jpg is the result.

Specify the content image and the model, control the style with the following options:

--content: path to the target face image or video
--style_id: the index of the style image (find the mapping between index and the style image here).
--style_degree (default: 0.5): adjust the degree of style.
--color_transfer(default: False): perform color transfer if loading a VToonify-Dsdc model.
--ckpt: path of the VToonify-D model. By default, a VToonify-Dsd trained on cartoon style is loaded.
--exstyle_path: path of the extrinsic style code. By default, codes in the same directory as --ckpt are loaded.
--scale_image: rescale the input image/video to fit VToonify (highly recommend).
--padding (default: 200, 200, 200, 200): left, right, top, bottom paddings to the eye center.

Here is an example of arcane style transfer:
python style_transfer.py --content ./data/038648.jpg \
       --scale_image --style_id 77 --style_degree 0.5 \
       --ckpt ./checkpoint/vtoonify_d_arcane/vtoonify_s_d.pt \
       --padding 600 600 600 600     # use large padding to avoid cropping the image

Specify --video to perform video toonification:
python style_transfer.py --scale_image --content ./data/YOUR_VIDEO.mp4 --video
The above style control options (--style_id, --style_degree, --color_transfer) also work for videos.
Style Transfer with VToonify-T
Specify --backbone as ''toonify'' to load and use a VToonify-T model.
python style_transfer.py --content ./data/038648.jpg \
       --scale_image --backbone toonify \
       --ckpt ./checkpoint/vtoonify_t_arcane/vtoonify.pt \
       --padding 600 600 600 600     # use large padding to avoid cropping the image

In VToonify-T, --style_id, --style_degree, --color_transfer, --exstyle_path are not used.
As with VToonify-D, specify --video to perform video toonification.

(2) Training VToonify
Download the supporting models to the ./checkpoint/ folder and arrange them in this folder structure:



Model
Description




stylegan2-ffhq-config-f.pt
StyleGAN model trained on FFHQ taken from rosinality


encoder.pt
Pixel2style2pixel encoder that embeds FFHQ images into StyleGAN2 Z+ latent code


faceparsing.pth
BiSeNet for face parsing from face-parsing.PyTorch


directions.npy
Editing vectors taken from LowRankGAN for editing face attributes


Toonify | DualStyleGAN
pre-trained stylegan-based toonification models



To customize your own style, you may need to train a new Toonify/DualStyleGAN model following here.
Train VToonify-D
Given the supporting models arranged in the default folder structure, we can simply pre-train the encoder and train the whole VToonify-D by running
# for pre-training the encoder
python -m torch.distributed.launch --nproc_per_node=N_GPU --master_port=PORT train_vtoonify_d.py \
       --iter ITERATIONS --stylegan_path DUALSTYLEGAN_PATH --exstyle_path EXSTYLE_CODE_PATH \
       --batch BATCH_SIZE --name SAVE_NAME --pretrain
# for training VToonify-D given the pre-trained encoder
python -m torch.distributed.launch --nproc_per_node=N_GPU --master_port=PORT train_vtoonify_d.py \
       --iter ITERATIONS --stylegan_path DUALSTYLEGAN_PATH --exstyle_path EXSTYLE_CODE_PATH \
       --batch BATCH_SIZE --name SAVE_NAME                  # + ADDITIONAL STYLE CONTROL OPTIONS
The models and the intermediate results are saved in ./checkpoint/SAVE_NAME/ and ./log/SAVE_NAME/, respectively.
VToonify-D provides the following STYLE CONTROL OPTIONS:

--fix_degree: if specified, model is trained with a fixed style degree (no degree adjustment)
--fix_style: if specified, model is trained with a fixed style image (no examplar-based style transfer)
--fix_color: if specified, model is trained with color preservation (no color transfer)
--style_id: the index of the style image (find the mapping between index and the style image here).
--style_degree (default: 0.5): the degree of style.

Here is an example to reproduce the VToonify-Dsd on Cartoon style and the VToonify-D specialized for a mild toonification on the 26th cartoon style:
python -m torch.distributed.launch --nproc_per_node=8 --master_port=8765 train_vtoonify_d.py \
       --iter 30000 --stylegan_path ./checkpoint/cartoon/generator.pt --exstyle_path ./checkpoint/cartoon/refined_exstyle_code.npy \
       --batch 1 --name vtoonify_d_cartoon --pretrain      
python -m torch.distributed.launch --nproc_per_node=8 --master_port=8765 train_vtoonify_d.py \
       --iter 2000 --stylegan_path ./checkpoint/cartoon/generator.pt --exstyle_path ./checkpoint/cartoon/refined_exstyle_code.npy \
       --batch 4 --name vtoonify_d_cartoon --fix_color 
python -m torch.distributed.launch --nproc_per_node=8 --master_port=8765 train_vtoonify_d.py \
       --iter 2000 --stylegan_path ./checkpoint/cartoon/generator.pt --exstyle_path ./checkpoint/cartoon/refined_exstyle_code.npy \
       --batch 4 --name vtoonify_d_cartoon --fix_color --fix_degree --style_degree 0.5 --fix_style --style_id 26
Note that the pre-trained encoder is shared by different STYLE CONTROL OPTIONS. VToonify-D only needs to pre-train the encoder once for each DualStyleGAN model.
Eight GPUs are not necessary, one can train the model with a single GPU with larger --iter.
Tips: [how to find an ideal model] we can first train a versatile model VToonify-Dsd,
and navigate around different styles and degrees. After finding the ideal setting, we can then train the model specialized in that setting for high-quality stylization.
Train VToonify-T
The training of VToonify-T is similar to VToonify-D,
# for pre-training the encoder
python -m torch.distributed.launch --nproc_per_node=N_GPU --master_port=PORT train_vtoonify_t.py \
       --iter ITERATIONS --finetunegan_path FINETUNED_MODEL_PATH \
       --batch BATCH_SIZE --name SAVE_NAME --pretrain       # + ADDITIONAL STYLE CONTROL OPTION
# for training VToonify-T given the pre-trained encoder
python -m torch.distributed.launch --nproc_per_node=N_GPU --master_port=PORT train_vtoonify_t.py \
       --iter ITERATIONS --finetunegan_path FINETUNED_MODEL_PATH \
       --batch BATCH_SIZE --name SAVE_NAME                  # + ADDITIONAL STYLE CONTROL OPTION
VToonify-T only has one STYLE CONTROL OPTION:

--weight (default: 1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0): 18 numbers indicate how the 18 layers of the ffhq stylegan model and the finetuned model are blended to obtain the final Toonify model. Here is the --weight we use in the paper for different styles. Please refer to toonify for the details.

Here is an example to reproduce the VToonify-T model on Arcane style:
python -m torch.distributed.launch --nproc_per_node=8 --master_port=8765 train_vtoonify_t.py \
       --iter 30000 --finetunegan_path ./checkpoint/arcane/finetune-000600.pt \
       --batch 1 --name vtoonify_t_arcane --pretrain --weight 0.5 0.5 0.5 0.5 0.5 0.5 0.5 1 1 1 1 1 1 1 1 1 1 1
python -m torch.distributed.launch --nproc_per_node=8 --master_port=8765 train_vtoonify_t.py \
       --iter 2000 --finetunegan_path ./checkpoint/arcane/finetune-000600.pt \
       --batch 4 --name vtoonify_t_arcane --weight 0.5 0.5 0.5 0.5 0.5 0.5 0.5 1 1 1 1 1 1 1 1 1 1 1

(3) Results
Our framework is compatible with existing StyleGAN-based image toonification models to extend them to video toonification, and inherits their appealing features for flexible style control. With DualStyleGAN as the backbone, our VToonify is able to transfer the style of various reference images and adjust the style degree in one model.





joint.style.and.degree.control.mp4





Here are the color interpolated results of VToonify-D and VToonify-Dc on Arcane, Pixar and Comic styles.





styles.mp4





Citation
If you find this work useful for your research, please consider citing our paper:
@article{yang2022Vtoonify,
  title={VToonify: Controllable High-Resolution Portrait Video Style Transfer},
  author={Yang, Shuai and Jiang, Liming and Liu, Ziwei and Loy, Chen Change},
  journal={ACM Transactions on Graphics (TOG)},
  volume={41},
  number={6},
  articleno={203},
  pages={1--15},
  year={2022},
  publisher={ACM New York, NY, USA},
  doi={10.1145/3550454.3555437},
}
Acknowledgments
The code is mainly developed based on stylegan2-pytorch, pixel2style2pixel and DualStyleGAN.









About

      [SIGGRAPH Asia 2022] VToonify: Controllable High-Resolution Portrait Video Style Transfer
    
Topics



  style-transfer


  face


  siggraph-asia


  stylegan2


  toonify


  video-style-transfer



Resources





      Readme
 
License





     View license
    



Stars





2.2k
    stars

Watchers





54
    watching

Forks





238
    forks







    Releases

No releases published






    Packages 0


        No packages published 







    Contributors 4





¬†



¬†



¬†



¬†







Languages












Jupyter Notebook
91.0%







Python
8.3%







Other
0.7%











"
https://news.ycombinator.com/rss,ZSWatch ‚Äì Open-source Zephyr-based smartwatch,https://github.com/jakkra/ZSWatch,Comments,"








jakkra

/

ZSWatch

Public




 

Notifications



 

Fork
    5




 


          Star
 204
  









        ZSWatch - the Open Source Zephyr‚Ñ¢ based Smartwatch, including both HW and FW.
      
License





     MIT license
    






204
          stars
 



5
          forks
 



 


          Star

  





 

Notifications












Code







Issues
1






Pull requests
1






Actions







Projects
0






Security







Insights



 
 



More


 


                  Code
 


                  Issues
 


                  Pull requests
 


                  Actions
 


                  Projects
 


                  Security
 


                  Insights
 







jakkra/ZSWatch









This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.











main





Switch branches/tags










Branches
Tags














View all branches















View all tags













Name already in use









      A tag already exists with the provided branch name. Many Git commands accept both tag and branch names, so creating this branch may cause unexpected behavior. Are you sure you want to create this branch?



    Cancel

    Create








1
branch





0
tags







    Code
 







Local



 Codespaces



  










  Clone





            HTTPS
 
            GitHub CLI
 













        Use Git or checkout with SVN using the web URL.
    













      Work fast with our official CLI.
      Learn more.
    








    Open with GitHub Desktop






    Download ZIP



 
Sign In Required

                Please
                sign in
                to use Codespaces.
              



Launching GitHub Desktop

    If nothing happens, download GitHub Desktop and try again.
  




Launching GitHub Desktop

    If nothing happens, download GitHub Desktop and try again.
  




Launching Xcode

    If nothing happens, download Xcode and try again.
  





Launching Visual Studio Code
Your codespace will open once ready.
There was a problem preparing your codespace, please try again.










Latest commit






 




jakkra

Merge remote-tracking branch 'origin/main' into main




        ‚Ä¶
      




        b0bbf79
      

Jan 14, 2023





Merge remote-tracking branch 'origin/main' into main


b0bbf79



Git stats







123

                      commits
                    







Files

Permalink




  
    Failed to load latest commit information.


  
 


Type
Name
Latest commit message
Commit time








.github


¬†


¬†









CAD


¬†


¬†









ZSWatch-kicad


¬†


¬†









app


¬†


¬†









schematic


¬†


¬†









.gitignore


¬†


¬†









LICENCE


¬†


¬†









README.md


¬†


¬†




    View code
 



















ZSWatch
Hardware Features in ZSWatch v1
Upcoming Hardware features in ZSWatch v2
Charger/Dock
Enclosure/Casing
Software Features
Larger not yet implemented SW Features and TODOs
Android phone communication
PCB
ZSWatch in action
Writing apps for the Application Manager
Dock





README.md





ZSWatch


  The ZSWatch v1



Smartwatch built from scratch, both hardware and software. Built on the Zephyr‚Ñ¢ Project RTOS, hence the name ZSWatch - Zephyr Smartwatch.

Hardware Features in ZSWatch v1

nRF52833 BLE chip (u-blox ANNA-B402 module).
1.28"" 240x240 IPS TFT Circular Display with GC9A01 driver.
Accelerometer for step counting etc. (LIS2DS12TR).
Pulse oximetry and heartrate using (MAX30101EFD)).
Vibration motor with haptics driver to give better vibration control (DRV2603RUNT).
External 8MB flash (MX25R6435FZNIL0).
Battery charger and battery supervisor (MAX1811ESA+ datasheet, TLV840MAPL3).
3 buttons for navigation (prev/next/enter)
220 mAh Li-Po battery.
Sapphire Crystal Glass to protect the display.

Upcoming Hardware features in ZSWatch v2

nRF5340 BLE chip (u-blox NORA-B10 module)
Touch screen with same size and features as v1
8MB external flash will probably be removed due to larger size of u-blox NORA-B10 vs. ANNA-B402.
Find another way to dock the clock for charging and programming, maybe can find some connector similar to what smartwatches normally have.

Charger/Dock
Basic pogo-pin dock that connects the power and SWD pins to the bottom of the watch.
Enclosure/Casing
3D printed casing with 3D printed buttons. Does it's job, but for revision v2 of the watch I'll probably do something CNC'd for nicer looks.
Software Features

Bluetooth LE communications with GadgetBridge Android app.
Also support Bluetooth Direction Finding so the watch can act as a tag and is trackable using any u-blox AoA antenna board
Watchface that shows:

Standard stuff as time, date, battery
Weather
Step count
Number unread notifications
Heart rate (not implemented yet however)


Pop-up notifications
Setting menu system, with easy extendability
Application picker and app concept

Music control app
Settings app
etc.


Step counting

Larger not yet implemented SW Features and TODOs

Heart rate, right now only samples the raw data, but no heart rate is calculated from it.
Proper BLE pairing, currently removed due to flash constraints (fixed by nRF5340 upgrade).
Watchface should also be an application.
Refactoring of main.c, should have way less logic, utlize Zephyr architecture more.

Android phone communication
Fortunately there is a great Android app called GadgetBridge which handles everything needed on the phone side, such as notifications management, music control and so much more... The ZSWatch right now pretends to be one of the supported Smart Watches in Gadgetbridge, following the same API as it does. In future there may be a point adding native support, we'll see.
PCB
A 4 layer board which measures 36mm in diameter designed in KiCad.








ZSWatch in action



Music control
Accelerometer for step count and tap detection




 object-fit=""cover""



Notifications from phone (Gmail here)
Settings







Writing apps for the Application Manager
Check out the sample application for the general app design. The main idea is each app have an <app_name>_app.c file which registers the app, chooses icon and drives the logic for the app. Then there should be one or more files named for example <app_name>_ui.c containing pure LVGL code with no dependencies to Zephyr or the watch software. The idea is that this UI code should be runnable in a LVGL simulator to speed up development of UI, however right now that's not set up yet. The <app_name>_app.c will do all logic and call functions in <app_name>_ui.c to update the UI accordingly.
Each application needs to have a way to close itself, for example a button, and then through callback tell the application_manager.c to close the app:
When user clicks an app in the app picker:

application_manager.c deletes it's UI elements and calls the application_start_fn.
<app_name>_app.c will do necessary init and then call the <app_name>_ui.c to draw the app UI.
User can now navigate arund and the application and do whatever.

When user for example presses a close button in the application:

Typically a callback from the UI code in <app_name>_ui.c will call <app_name>_app.c to tell that user requested to close the app. <app_name>_app.c will notify application_manager.c that it want to close itself. application_manager.c will then call <app_name>_app.c application_stop_fn and <app_name>_app.c will tell UI to close then do necessary de-init and return.
application_manager.c will now draw the app picker again.

The application manager can also at any time close a running application by calling it's application_stop_fn.
Dock
Very basic, will be re-worked for next watch revision v2.












About

      ZSWatch - the Open Source Zephyr‚Ñ¢ based Smartwatch, including both HW and FW.
    
Topics



  bluetooth


  ble


  smartwatch


  zephyr


  nrf52


  lvgl


  angle-of-arrival


  nrf-connect


  nordic-semiconductor


  nrf53


  nrf-connect-sdk


  zswatch



Resources





      Readme
 
License





     MIT license
    



Stars





204
    stars

Watchers





5
    watching

Forks





5
    forks







    Releases

No releases published




Languages











C
99.9%







Other
0.1%











"
https://news.ycombinator.com/rss,Four thousand weeks,https://leebyron.com/4000/,Comments,"



















Four Thousand Weeks










FourThousandWeeks


          A tribute to
          the book by
          Oliver Burkeman, an exploration of time management in the
          face of human finitude, and addressing the anxiety of ‚Äúgetting
          everything done.‚Äù
        

          To begin, enter when were you born
          This site uses no cookies nor saves your information




Scroll on...




We live our livesweek by week

















Yet a week feels frustratingly limited

        The pressure to be more productive and fit ever-increasing quantities of
        activity into a stubbornly non-increasing quantity of time leads to
        productivity anxiety, shriveled attention spans, and burn-out.
      


And there are alarmingly few of¬†them

        You would feel less anxious about wasting an evening doom-scrolling if
        you had an infinite amount of them. Somehow either doing too much or too
        little can create the sense of wasting time.
      

        Despite all this activity we sense there are important and fulfilling
        ways we could be spending our time, even if we can‚Äôt say exactly what
        they are. Yet, we systematically spend our time doing other things to
        get by instead.
      


          I (like many others) felt a wrongness in the world. Life, I knew, was
          supposed to be more joyful than this, more real, more meaningful. We
          were not supposed to hate Mondays and live for the weekends and
          holidays. We were not supposed to have to raise our hands to be
          allowed to pee.
        
Charles Eisenstien




The average human life is only four thousand weeks


        Scientists estimate that life, in some form, will persist for another
        1.5 billion years or more, until the intensifying heat of the sun
        condemns the last organism to death.
      

        But you? Assuming you live to be eighty, you‚Äôll have had about four
        thousand weeks. The rare few lucky enough to become a centenarian will
        see only five thousand.
      
That‚Äôs absurdly, terrifyingly, insultingly short.




          You have lived  of them so¬†far
        


        You likely have many more weeks ahead of you. The psychologist
        Erik Erikson suggests that at this phase of life you focus
        on the virtues of competence and fidelity. Allow yourself failures in
        the spirit of discovering and developing your personal identity and
        priorities so that your future weeks can be lived well with intention
        and purpose.
      

        That‚Äôs a significant amount of the weeks you‚Äôll see. The psychologist
        Erik Erikson suggests that at this phase of life you focus
        on the virtue of love. Share yourself more intimately with others and
        invest in happy relationships so that your future weeks can be lived
        well with companionship and purpose.
      

        That‚Äôs likely a majority of the weeks you‚Äôll see. The psychologist
        Erik Erikson suggests that at this phase of life you focus
        on the virtue of care. Spend your weeks ‚Äúmaking your mark‚Äù by
        intentionally nurturing things that will outlast you, raising children,
        mentoring others, becoming involved in your community and organizations,
        and creating positive change that benefits others.
      

        You‚Äôre likely well aware of your own finitude having lived the large
        majority of the weeks you‚Äôll see. The psychologist
        Erik Erikson suggests that at this phase of life you focus
        on the virtue of wisdom. Accept and appreciate your accomplishments so
        far as a life well lived. Continue to nurture things that will outlast
        you and mentor others, spend your weeks intentionally on your true
        priorities, and appreciate novelty in the mundane.
      

        You‚Äôre no doubt well aware of your own finitude as one of the lucky ones
        to live well past four thousand weeks. The psychologist
        Erik Erikson suggests that at this phase of life you focus
        on the virtue of wisdom. Accept and appreciate your accomplishments so
        far as a life well lived. Spend every remaining week intentionally on
        your true priorities and appreciate novelty in the mundane.
      


Productivity is a trap

        There are numerous techniques, products, and services to squeeze the
        most productivity from your week. The problem isn‚Äôt that these don‚Äôt
        work, it‚Äôs that they do work. And yet paradoxically you only
        feel busier, more anxious, and somehow emptier as a result.
      

        The day will never arrive when you finally have everything under
        control‚Äîwhen the flood of emails has been contained; when your to-do
        lists have stopped getting longer; when you‚Äôre meeting all your
        obligations at work and in your home life; when nobody‚Äôs angry with you
        for missing a deadline or dropping the ball; and when the fully
        optimized person you‚Äôve become can turn, at long last, to the things
        life is really supposed to be about.
      

        Let‚Äôs start by admitting defeat: none of this is ever going to happen.
      


          Time feels like an unstoppable conveyer belt, bringing us new tasks as
          fast as we can dispatch the old ones; and becoming ‚Äúmore productive‚Äù
          just seems to cause the belt to speed up.
        
Edward T. Hall



Adopt a limit-embracing attitude

        If you truly don‚Äôt have time for everything you want to do, or feel you
        ought to do, or that others are badgering you to do, then, well, you
        don‚Äôt have time‚Äîno matter how grave the consequences of failing to do it
        all might prove to be. So, technically, it‚Äôs irrational to feel troubled
        by an overwhelming to-do list. You‚Äôll do what you can, you won‚Äôt do what
        you can‚Äôt, and the tyrannical inner voice insisting that you must do
        everything is simply mistaken.
      

        We rarely stop to consider things so rationally, though, because that
        would mean confronting the painful truth of our limitations.
      

        Surrender to the reality that things just take the time they take, and
        that you can‚Äôt quiet your anxieties by working faster, because it isn‚Äôt
        within your power to force reality‚Äôs pace as much as you feel you need
        to, and because the faster you go, the faster you‚Äôll feel you need to
        go.
      


          Which of us truly lives on twenty-four hours a day? Which of us is not
          saying: ‚ÄúI shall alter that when I have a little more time?‚Äù We never
          shall have any more time. We have, and we have always had, all the
          time there is.
        
Arnold Bennett



How you spend your time is a choice

        We are forced to accept that there will always be too much to do; that
        you can‚Äôt make the world run at your preferred speed and so there are
        tough choices to be made: which balls to let drop, which people to
        disappoint, which cherished ambitions to abandon, which roles to fail
        at.
      

        Once you truly understand that you‚Äôre guaranteed to miss out on almost
        every experience the world has to offer, the fact that there are so many
        you still haven‚Äôt experienced stops feeling like a problem. Instead, you
        get to focus on fully enjoying the tiny slice of experiences you
        actually do have time for. Digging in to a challenging project that
        can‚Äôt be hurried becomes not a trigger for stressful emotions but a
        bracing act of choice.
      


The importance of¬†rest

        A real risk of doing too much is finding your work time, in attempt to
        be productive, encroaching on an evening‚Äôs rest. Rest as it turns
        out‚Äîwhether in the evening, over a weekend, or a long vacation‚Äîis
        critical for productive creative work. Its absence can lead to stress,
        burnout, and counterintuitively overall poor performance despite the
        extra hours worked.
      

        Though why should vacations or lazy mornings need defending in terms of
        improved work performance? Enjoying leisure for its own sake‚Äîwhich is
        the whole point of leisure‚Äîshould not feel as though you‚Äôre failing at
        life. Leisure is not merely an opportunity for recovery and
        replenishment for the purposes of further work, but for its intrinsic
        satisfactions.
      


          I have to die. If it is now, well then I die now; if later, then now I
          will take my lunch, since the hour for lunch has arrived - and dying I
          will tend to later.
        
Epictetus



The loneliness of temporal sovereignty

        Other human beings are always impinging on your time in countless
        frustrating ways. In an ideal world the only person making decisions
        about your time is you. However this comes at a cost that‚Äôs not worth
        paying.
      

        It‚Äôs good to have plenty of time, but having all the time in the world
        isn‚Äôt much use if you‚Äôre forced to experience it all on your own. To do
        countless important things with time: to socialize, go on dates, raise
        children, launch businesses, start movements; it has to be synchronized
        with other people. In fact, having large amounts of time but no
        opportunity to use it collaboratively can be actively unpleasant.
      

        We treat our time as something to hoard, when it‚Äôs better approached as
        something to share. Even if that means surrendering some of your power
        to decide exactly what you do with it and when.
      


          However, the two things must be mingled and varied, solitude and
          joining a crowd: the one will make us long for people and the other
          for ourselves, and each will be a remedy for the other; solitude will
          cure our distaste for a crowd, and a crowd will cure our boredom with
          solitude.
        
Seneca




        Ten tools for embracing finitude
      


1.
Adopt a fixed volume approach to productivity

        Tough choices are inevitable; focus on making them consciously and well.
      

        Keep two to-do lists: an ‚Äúopen‚Äù one for everything on your plate,
        doubtlessly nightmarishly long, and ‚Äúclosed‚Äù with a fixed number of
        entries, only moving tasks onto it when previous ones have been
        completed.
      

        You‚Äôll never get through all the tasks on the open list, but you were
        never going to in any case. The choice to leave them there is hard, but
        time spent on them is time not spent on the things you chose to focus
        on.
      

        Establish pre-determined time boundaries on your work, and make
        decisions in light of those limits. If your primary goal is to do what‚Äôs
        required to be finished by 5:30 you‚Äôll be aware of the constraints on
        your time and motivated to use it wisely.
      


2.
Serialize,serialize,serialize

        Focus on one big project at a time, and see it to completion before
        moving onto the next.
      

        It‚Äôs alluring to try to alleviate the anxiety of having too many
        responsibilities or ambitions by getting started on them all at once,
        but you‚Äôll make little progress that way. Instead, train yourself to get
        incrementally better at tolerating that anxiety by consciously
        postponing everything you possibly can except for one thing.
      

        Soon the satisfaction of completing important projects will make that
        anxiety feel worthwhile, and as you complete them you‚Äôll have less to be
        anxious about anyway.
      


3.
Strategic underachievement

        Simply because your time is finite, you‚Äôll inevitably underachieve at
        something. When you can‚Äôt do it all, you can feel ashamed and give up.
        When you decide in advance what to fail at, you remove the sting of
        shame.
      

        Nominate in advance whole areas of life in which you won‚Äôt expect
        excellence from yourself. Instead focus that time more effectively, and
        you won‚Äôt be surprised when you fail at what you planned to fail at all
        along.
      


4.
Celebrate wins

        The to-do list will never be finished. Inbox zero will inevitably
        refill. There‚Äôs an unhelpful assumption that you begin each morning with
        a productivity debt that you must pay off with hard work to achieve a
        zero-balance by evening.
      

        Keep a ‚Äúdone‚Äù list which starts empty and fills up over the day. You
        could have spent the day doing nothing remotely constructive, and look
        what you did instead! Lower the bar for what gets to count as an
        accomplishment; small wins accrue.
      


5.
Consolidate care

        The attention economy demands urgency, bringing a litany of demands for
        your care every day. Consciously choose your battles in industry,
        charity, activism, and politics.
      

        To make a real difference, you must focus your finite capacity for care.
      


6.
Embrace boring & single-purpose technology

        Modern digital devices offer distraction to a place where painful human
        limitations do not apply; you need never feel bored or constrained in
        your freedom of action‚Äîwhich isn‚Äôt the case when it comes to work that
        matters.
      

        Combat this by making your devices boring. Remove apps that distract
        (even consider Slack or Email). Switch your screen to grayscale. Use
        time-limiting reminders.
      

        Choose single-purpose devices like an e-reader where it‚Äôs tedious and
        awkward to do anything but read. If distracting apps are only a swipe
        away they‚Äôll prove impossible to resist when the first twinge of boredom
        or difficulty of focus arises.
      


7.
Seek novelty in the¬†mundane

        The fewer weeks we have left the faster we seem to lose them. The
        likeliest explanation for this phenomenon is that our brains encode the
        passing of time on the basis of how much information we process in any
        given interval.
      

        Cramming your life with novel experiences does work, but can also lead
        to existential overwhelm and is also impractical, especially if you have
        a job or children.
      

        Alternatively pay more attention to every moment no matter how mundane.
        Plunge into the life you already have with twice the intensity and your
        life will feel twice as full and will be remembered as lasting twice as
        long. Meditation, going on unplanned walks, photography, journaling,
        anything that draws your attention more fully to the present.
      


8.
Be a researcher in relationships

        When presented with a challenging or boring moment with another person,
        deliberately adopt an attitude of curiosity in which your goal isn‚Äôt to
        achieve any particular outcome or explain your position but to figure
        out who this human being is who we‚Äôre with.
      

        This curiosity is well suited to the unpredictability of life with
        others because it can be satisfied by their behaving in ways you like or
        dislike whereas the stance of demanding a certain result is frustrated
        each time things fail to go your way.
      


9.
Cultivate instantaneous generosity

        Whenever a generous impulse arises your mind: to give money, to check in
        on a friend, send an email praising someone‚Äôs work, act on that impulse
        right away. If you put it off for whatever reason, you‚Äôll likely not get
        back to it. The only acts of generosity that count are the ones you‚Äôre
        actually making.
      

        People are social creatures, and generous action reliably makes us feel
        much happier.
      


10.
Practice doing nothing

        When it comes to the challenge of using your four thousand weeks well,
        the capacity to do nothing is indispensable. If you can‚Äôt bear the
        discomfort of not acting you‚Äôre far more likely to make poor choices
        with your time simply to feel as if you‚Äôre acting. Calm down, gain
        autonomy over your choices, and make better ones.
      
Do nothing meditation

Set a timer, even for only five minutes.
Sit in a chair and then stop trying to do anything.

          Every time you notice you‚Äôre doing something, including thinking or
          focusing on your breathing, stop doing it.
        

          If you notice you‚Äôre criticizing yourself inwardly for doing things
          well‚Ä¶ that‚Äôs a thought too so stop doing that.
        
Keep on stopping until the timer goes off.





        Thanks for reading this tribute to
        Four Thousand Weeks, by Oliver Burkeman.
      

        This page is comprised of themes and excerpts from the book. If you‚Äôve
        scrolled this far you should absolutely read it in its entirety.
      

        Set in
        Playfair 2.0
        by Claus Eggers


        Made and open-sourced by
        Lee Byron
        with ‚ô• in San Francisco.
      
‚úåÔ∏é



"
https://news.ycombinator.com/rss,Use.GPU Goes Trad,https://acko.net/blog/use-gpu-goes-trad/,Comments,"



Use.GPU Goes Trad ‚Äî Acko.net































Hackery, Math &¬†Design
Steven Wittens i













Home







Home






January 14, 2023
Use.GPU Goes Trad


Old is new again




I've released a new version of Use.GPU, my experimental reactive/declarative WebGPU framework, now at version 0.8.
My goal is to make GPU rendering easier and more sane. I do this by applying the lessons and patterns learned from the React world, and basically turning them all up to 11, sometimes 12. This is done via my own Live run-time, which is like a martian React on steroids.
The previous 0.7 release was themed around compute, where I applied my shader linker to a few challenging use cases. It hopefully made it clear that Use.GPU is very good at things that traditional engines are kinda bad at.
In comparison, 0.8 will seem banal, because the theme was to fill the gaps and bring some traditional conveniences, like:

Scenes and nodes with matrices
Meshes with instancing
Shadow maps for lighting
Visibility culling for geometry






These were absent mostly because I didn't really need them, and they didn't seem like they'd push the architecture in novel directions. That's changed however, because there's one major refactor underpinning it all: the previously standard forward renderer is now entirely swappable. There is a shiny deferred-style renderer to showcase this ability, where lights are rendered separately, using a g-buffer with stenciling.
This new rendering pipeline is entirely component-driven, and fully dogfooded. There is no core renderer per-se: the way draws are realized depends purely on the components being used. It effectively realizes that most elusive of graphics grails, which established engines have had difficulty delivering on: a data-driven, scriptable render pipeline, that mortals can hopefully use.





Root of the App



Deep inside the tree


I've spent countless words on Use.GPU's effect-based architecture in prior posts, which I won't recap. Rather, I'll just summarize the one big trick: it's structured entirely as if it needs to produce only 1 frame. Then in order to be interactive, and animate, it selectively rewinds parts of the program, and reactively re-runs them. If it sounds crazy, that's because it is. And yet it works.
So the key point isn't the feature list above, but rather, how it does so. It continues to prove that this way of coding can pay off big. It has all the benefits of immediate-mode UI, with none of the downsides, and tons of extensibility. And there are some surprises along the way.
Real Reactivity
You might think: isn't this a solved problem? There are plenty of JS 3D engines. Hasn't React-Three-Fiber (R3F) shown how to make that declarative? And aren't these just web versions of what native engines like Unreal and Unity already do well, and better?
My answer is no, but it might not be clear why. Let me give an example from my current job.







My client needs a specialized 3D editing tool. In gaming terms you might think of it as a level design tool, except the levels are real buildings. The details don't really matter, only that they need a custom 3D editing UI. I've been using Three.js and R3F for it, because that's what works today and what other people know.
Three.js might seem like a great choice for the job: it has a 3D scene, editing controls and so on. But, my scene is not the source of truth, it's the output of a process. The actual source of truth being live-edited is another tree that sits before it. So I need to solve a two-way synchronization problem between both. This requires careful reasoning about state changes.





Change handlers in Three.js and R3F


Sadly, the way Three.js responds to changes is ill-defined. As is common, its objects have ""dirty"" flags. They are resolved and cleared when the scene is re-rendered. But this is not an iron rule: many methods do trigger a local refresh on the spot. Worse, certain properties have an invisible setter, which immediately triggers a ""change"" event when you assign a new value to it. This also causes derived state to update and cascade, and will be broadcast to any code that might be listening.
The coding principle applied here is ""better safe than sorry"". Each of these triggers was only added to fix a particular stale data bug, so their effects are incomplete, creating two big problems. Problem 1 is a mix of old and new state... but problem 2 is you can only make it worse, by adding even more pre-emptive partial updates, sprinkled around everywhere.
These ""change"" events are oblivious to the reason for the change, and this is actually key: if a change was caused by a user interaction, the rest of the app needs to respond to it. But if the change was computed from something else, then you explicitly don't want anything earlier to respond to it, because it would just create an endless cycle, which you need to detect and halt.


R3F introduces a declarative model on top, but can't fundamentally fix this. In fact it adds a few new problems of it own in trying to bridge the two worlds. The details are boring and too specific to dig into, but let's just say it took me a while to realize why my objects were moving around whenever I did a hot-reload, because the second render is not at all the same as the first.
Yet this is exactly what one-way data flow in reactive frameworks is meant to address. It creates a fundamental distinction between the two directions: cascading down (derived state) vs cascading up (user interactions). Instead of routing both through the same mutable objects, it creates a one-way reverse-path too, triggered only in specific circumstances, so that cause and effect are always unambigious, and cycles are impossible.
Three.js is good for classic 3D. But if you're trying to build applications with R3F it feels fragile, like there's something fundamentally wrong with it, that they'll never be able to fix. The big lesson is this: for code to be truly declarative, changes must not be allowed to travel backwards. They must also be resolved consistently, in one big pass. Otherwise it leads to endless bug whack-a-mole.
What reactivity really does is take cache invalidation, said to be the hardest problem, and turn the problem itself into the solution. You never invalidate a cache without immediately refreshing it, and you make that the sole way to cause anything to happen at all. Crazy, and yet it works.
When I tell people this, they often say ""well, it might work well for your domain, but it couldn't possibly work for mine."" And then I show them how to do it.


Figuring out which way your cube map points:just gfx programmer things.

And... Scene
One of the cool consequences of this architecture is that even the most traditional of constructs can suddenly bring neat, Lispy surprises.
The new scene system is a great example. Contrary to most other engines, it's actually entirely optional. But that's not the surprising part.
Normally you just have a tree where nodes contain other nodes, which eventually contain meshes, like this:
<Scene>
  <Node matrix={...}>
    <Mesh>
    <Mesh>
  <Node matrix={...}>
    <Mesh>
    <Node matrix={...}>
      <Mesh>
      <Mesh>


It's a way to compose matrices: they cascade and combine from parent to child. The 3D engine is then built to efficiently traverse and render this structure.
But what it ultimately does is define a transform for every mesh: a function vec3 => vec3 that maps one vertex position to another. So if you squint, <Mesh> is really just a marker for a place where you stop composing matrices and pass a composed matrix transform to something else.
Hence Use.GPU's equivalent, <Primitive>, could actually be called <Unscene>. What it does is escape from the scene model, mirroring the Lisp pattern of quote-unquote. A chain of <Node> parents is just a domain-specific-language (DSL) to produce a TransformContext with a shader function, one that applies a single combined matrix transform.
In turn, <Mesh> just becomes a combination of <Primitive> and a <FaceLayer>, i.e. triangle geometry that uses the transform. It all composes cleanly.
So if you just put meshes inside the scene tree, it works exactly like a traditional 3D engine. But if you put, say, a polar coordinate plot in there from the plot package, which is not a matrix transform, inside a primitive, then it will still compose cleanly. It will combine the transforms into a new shader function, and apply it to whatever's inside. You can unscene and scene repeatedly, because it's just exiting and re-entering a DSL.
In 3D this is complicated by the fact that tangents and normals transform differently from vertices. But, this was already addressed in 0.7 by pairing each transform with a differential function, and using shader fu to compose it. So this all just keeps working.
Another neat thing is how this works with instancing. There is now an <Instances> component, which is exactly like <Mesh>, except that it gives you a dynamic <Instance> to copy/paste via a render prop:
<Instances
   mesh={mesh}
   render={(Instance) => (<>
     <Instance position={[1, 2, 3]} />
     <Instance position={[3, 4, 5]} />
   </>)
 />


As you might expect, it will gather the transforms of all instances, stuff all of them into a single buffer, and then render them all with a single draw call. The neat part is this: you can still wrap individual <Instance> components in as many <Node> levels as you like. Because all <Instance> does is pass its matrix transform back up the tree to the parent it belongs to.





This is done using Live captures, which are React context providers in reverse. It doesn't violate one-way data flow, because captures will only run after all the children have finished running. Captures already worked previously, the semantics were just extended and formalized in 0.8 to allow this to compose with other reduction mechanisms.


But there's more. Not only can you wrap <Instance> in <Node>, you can also wrap either of them in <Animate>, which is Use.GPU's keyframe animator, entirely unchanged since 0.7:









<Instances
  mesh={mesh}
  render={(Instance) => (

    <Animate
      prop=""rotation""
      keyframes={ROTATION_KEYFRAMES}
      loop
      ease=""cosine""
    >
      <Node>
        {seq(20).map(i => (
          <Animate
            prop=""position""
            keyframes={POSITION_KEYFRAMES}
            loop
            delay={-i * 2}
            ease=""linear""
          >
            <Instance
              rotation={[
                Math.random()*360,
                Math.random()*360,
                Math.random()*360,
              ]}
              scale={[0.2, 0.2, 0.2]}
            />
          </Animate>
        ))}
      </Node>
    </Animate>

  )}
/>


The scene DSL and the instancing DSL and the animation DSL all compose directly, with nothing up my sleeve. Each of these <Components> are still just ordinary functions. On the inside they look like constructors with all the other code missing. There is zero special casing going on here, and none of them are explicitly walking the tree to reach each other. The only one doing that is the reactive run-time... and all it does is enforce one-way data flow by calling functions, gathering results and busting caches in tree order. Because a capture is a long-distance yeet.
Personally I find this pretty magical. It's not as efficient as a hand-rolled scene graph with instancing and built-in animation, but in terms of coding lift it's literally O(0) instead of OO. I needed to add zero lines of code to any of the 3 sub-systems, in order to combine them into one spinning whole.
The entire scene + instancing package clocks in at about 300 lines and that's including empties and generous formatting. I don't need to architect the rest of the framework around a base Object3D class that everything has to inherit from either, which is a-ok in my book.
This architecture will never reach Unreal or Unity levels of hundreds of thousands of draw calls, but then, it's not meant to do that. It embraces the idea of a unique shader for every draw call, and then walks that back if and when it's useful. The prototype map package for example does this, and can draw a whole 3D vector globe in 2 draw calls: fill and stroke. Adding labels would make it 3. And it's not static: it's doing the usual quad-tree of LOD'd mercator map tiles.










Multi-Pass
Next up, the modular renderer passes. Architecturally and reactively-speaking, there isn't much here. This was mainly an exercise in slicing apart the existing glue.
The key thing to grok is that in Use.GPU, the <Pass> component does not correspond to a literal GPU render pass. Rather, it's a virtual, logical render pass. It represents all the work needed to draw some geometry to a screen or off-screen buffer, in its fully shaded form. This seems like a useful abstraction, because it cleanly separates the nitty gritty rendering from later compositing (e.g. overlays).
For the forward renderer, this means first rendering a few shadow maps, and possibly rendering a picking buffer for interaction. For the deferred renderer, this involves rendering the g-buffer, stencils, lights, and so on.
My goal was for the toggle between the two to be as simple as replacing a <ForwardRenderer> with a <DeferredRenderer>... but also to have both of those be flexible enough that you could potentially add on, say, SSAO, or bloom, or a Space Engine-style black hole, as an afterthought. And each <Pass> can have its own renderer, rather than shoehorning everything into one big engine.
Neatly, that's mostly what it is now. The basic principle rests on three pillars.



Deferred rendering


First, there are a few different rendering modes, by default solid vs shaded vs ui. These define what kind of information is needed at every pixel, i.e. the classic varying attributes. But they have no opinion on where the data comes from or what it's used for: that's defined by the geometry layer being rendered. It renders a <Virtual> draw call, which it gives e.g. a getVertex and getFragment shader function with a particular signature for that mode. These functions are not complete shaders, just the core functions, which are linked into a stub. There are a few standard 'tropes' used here, not just these two.
Second, there are a few different rendering buckets, like opaque, transparent, shadow, picking and debug. These are used to group draws into. Different GPU render passes then pick and choose from that. opaque and transparent are drawn to the screen, while shadow is drawn repeatedly into all the shadow maps. This includes sorting front-to-back and back-to-front, as well as culling.
Finally, there's the renderer itself (forward vs deferred), and its associated pass components (e.g. <ColorPass>, <ShadowPass>, <PickingPass>, and so on). The renderer decides how to translate a particular ""mode + bucket"" combination into a concrete draw call, by lowering it into render components (e.g. <ShadedRender>). The pass components decide which buffer to actually render stuff to, and how. So the renderer itself doesn't actually render, it merely spawns and delegates to other components that do.


The forward path works mostly the same as before, only the culling and shadow maps are new... but it's now split up into all its logical parts. And I verified this design by adding the deferred renderer, which is a lot more convoluted, but still needs to do some forward rendering.
It works like a treat, and they use all the same lighting shaders. You can extend any of the 3 pillars just by replacing or injecting a new component. And you don't need to fork either renderer to do so: you can just pick and choose √† la carte by selectively overriding or extending its ""mode + bucket"" mapping table, or injecting a new actual render pass.










To really put a bow on top, I upgraded the Use.GPU inspector so that you can directly view any render target in a RenderDoc-like way. This will auto-apply useful colorization shaders, e.g. to visualize depth. This is itself implemented as a Use.GPU Live canvas, sitting inside the HTML-based inspector, sitting on top of Live, which makes this a Live-in-React-in-Live scenario.
For shits and giggles, you can also inspect the inspector's canvas, recursively, ad infinitum. Useful for debugging the debugger:







There are still of course some limitations. If, for example, you wanted to add a new light type, or add support for volumetric lights, you'd have to reach in more deeply to make that happen: the resulting code needs to be tightly optimized, because it runs per pixel and per light. But if you do, you're still going to be able to reuse 90% of the existing components as-is.
I do want a more comprehensive set of light types (e.g. line and area), I just didn't get around to it. Same goes for motion vectors and TXAA. However, with WebGPU finally nearing public release, maybe people will actually help out. Hint hint.







Port of a Reaction Diffusion system by Felix Woitzel.



A Clusterfuck of Textures
A final thing to talk about is 2D image effects and how they work. Or rather, the way they don't work. It seems simple, but in practice it's kind of ludicrous.
If you'd asked me a year ago, I'd have thought a very clean, composable post-effects pipeline was entirely within reach, with a unified API that mostly papered over the difference between compute and render. Given that I can link together all sorts of crazy shaders, this ought to be doable.
Well, I did upgrade the built-in fullscreen conveniences a bit, so that it's now easier to make e.g. a reaction diffusion sim like this (full code):



The devil here is in the details. If you want to process 2D images on a GPU, you basically have several choices:

Use a compute shader or render shader?
Which pixel format do you use?
Are you sampling one flat image or a MIP pyramid of pre-scaled copies?
Are you sampling color images, or depth/stencil images?
Use hardware filtering or emulate filtering in software?

The big problem is that there is no single approach that can handle all cases. Each has its own quirks. To give you a concrete example: if you wrote a float16 reaction-diffusion sim, and then decided you actually needed float32, you'd probably have to rewrite all your shaders, because float16 is always renderable and hardware filterable, but float32 is not.
Use.GPU has a pretty nice set of Compute/Stage/Kernel components, which are elegant on the outside; but they require you to write pretty gnarly shader code to actually use them. On the other side are the RenderToTexture/Pass/FullScreen components which conceptually do the same thing, and have much nicer shader code, but which don't work for a lot of scenarios. All of them can be broken by doing something seemingly obvious, that just isn't natively supported and difficult to check ahead of time.
Even just producing universal code to display any possible texture type on screen becomes a careful exercise in code-generation. If you're familiar with the history of these features, it's understandable how it got to this point, but nevertheless, the resulting API is abysmal to use, and is a never-ending show of surprise pitfalls.
Here's a non-exhaustive list of quirks:

Render shaders are the simplest, but can only be used to write those pixel formats that are ""renderable"".
Compute shaders must be dispatched in groups of N, even if the image size is not a multiple of N. You have to manually trim off the excess threads.
Hardware filtering only works on some formats, and some filtering functions only work in render shaders.
Hardware filtering (fast) uses [0..1] UV float coordinates, software emulation in a shader (slow) uses [0..N] XY uint coordinates.
Reading and writing from/to the same render texture is not allowed, you have to bounce between a read and write buffer.
Depth+stencil images have their own types and have an additional notion of ""aspect"" to select one or both.
Certain texture functions cannot be called conditionally, i.e. inside an if.
Copying from one texture to another doesn't work between certain formats and aspects.

My strategy so far has been to try and stick to native WGSL semantics as much as possible, meaning the shader code you do write gets inserted pretty much verbatim. But if you wanted to paper over all these differences, you'd have to invent a whole new shader dialect. This is a huge effort which I have not bothered with. As a result, compute vs render pretty much have to remain separate universes, even when they're doing 95% the same thing. There is also no easy way to explain to users which one they ought to use.
While it's unrealistic to expect GPU makers to support every possible format and feature on a fast path, there is little reason why they can't just pretend a little bit more. If a texture format isn't hardware filterable, somebody will have to emulate that in a shader, so it may as well be done once, properly, instead of in hundreds of other hand-rolled implementations.
If there is one overarching theme in this space, it's that limitations and quirks continue to be offloaded directly onto application developers, often with barely a shrug. To make matters worse, the ""next gen"" APIs like Metal and Vulkan, which WebGPU inherits from, do not improve this. They want you to become an expert at their own kind of busywork, instead of getting on with your own.
I can understand if the WebGPU designers have looked at the resulting venn-diagram of poorly supported features, and have had to pick their battles. But there's a few absurdities hidden in the API, and many non-obvious limitations, where the API spec suggests you can do a lot more than you actually can. It's a very mixed bag all things considered, and in certain parts, plain retarded. Ask me about minimum binding size. No wait, don't.
* * *
Most promising is that as Use.GPU grows to do more, I'm not touching extremely large parts of it. This to me is the sign of good architecture. I also continue to focus on specific use cases to validate it all, because that's the only way I know how to do it well.
There are some very interesting goodies lurking inside too. To give you an example... that R3F client app I mentioned at the start. It leverages Use.GPU's state package to implement a universal undo/redo system in 130 lines. A JS patcher is very handy to wrangle the WebGPU API's deep argument style, but it can do a lot more.
One more thing. As a side project to get away from the core architecting, I made a viewer for levels for Dark Engine games, i.e. Thief 1 (1998), System Shock 2 (1999) and Thief 2 (2000). I want to answer a question I've had for ages: how would those light-driven games have looked, if we'd had better lighting tech back then? So it actually relights the levels. It's still a work in progress, and so far I've only done slow-ass offline CPU bakes with it, using a BSP-tree based raytracer. But it works like a treat.









I basically don't have to do any heavy lifting if I want to draw something, be it normal geometry, in-place data/debug viz, or zoomable overlays. Integrating old-school lightmaps takes about 10 lines of shader code and 10 lines of JS, and the rest is off-the-shelf Use.GPU. I can spend my cycles working on the problem I actually want to be working on. That to me is the real value proposition here.
I've noticed that when you present people with refined code that is extremely simple, they often just do not believe you, or even themselves. They assume that the only way you're able to juggle many different concerns is through galaxy brain integration gymnastics. It's really quite funny. They go looking for the complexity, and they can't find it, so they assume they're missing something really vital. The realization that it's simply not there can take a very long time to sink in.
Visit usegpu.live for more and to view demos in a WebGPU capable browser.






Compute ¬†Data Flow ¬†GPU ¬†Latest ¬†Use.GPU

January 14, 2023











Home







Home









Subscribe










About
¬© 2003‚Äì2023







This article contains graphics made with WebGL, which your browser does not seem to support.
  Try Google Chrome or Mozilla Firefox.
  
  √ó



"
https://news.ycombinator.com/rss,DragonFlyBSD's HAMMER2 File-System Being Ported to NetBSD,https://www.phoronix.com/news/NetBSD-HAMMER2-Port,Comments,"







DragonFlyBSD's HAMMER2 File-System Being Ported To NetBSD - Phoronix






































 













Articles & Reviews
News Archive
Forums
Premium  Categories
Computers Display Drivers Graphics Cards Linux Gaming Memory Motherboards Processors Software Storage Operating Systems Peripherals Close








Articles & Reviews


News Archive


Forums


Premium
 
Contact


 Categories


Computers Display Drivers Graphics Cards Linux Gaming Memory Motherboards Processors Software Storage Operating Systems Peripherals 






























Show Your Support:  This site is primarily supported by advertisements. Ads are what have allowed this site to be maintained on a daily basis for the past 18+ years. We do our best to ensure only clean, relevant ads are shown, when any nasty ads are detected, we work to remove them ASAP. If you would like to view the site without ads while still supporting our work, please consider our ad-free Phoronix Premium.
DragonFlyBSD's HAMMER2 File-System Being Ported To NetBSD
Written by Michael Larabel in BSD on 11 January 2023 at 06:26 AM EST. 21 Comments


NetBSD continues using the FFS file-system by default while it's offered ZFS support that has been slowly improving -- in NetBSD-CURRENT is the ability to use ZFS as the root file-system if first booting to FFS, for example.  There may be another modern file-system option soon with an effort underway to port DragonFlyBSD's HAMMER2 over to NetBSD. HAMMER2 has been built-up over the past decade by Matthew Dillon and other DragonFlyBSD developers. HAMMER2 has been the default and working rather well with recent releases of DragonFlyBSD while now there is a port underway to try to get the file-system working good for NetBSD.HAMMER2 on DragonFlyBSD. NetBSD developer  Tomohiro Kusumi has started working on a HAMMER2 port to NetBSD, who had also worked on porting HAMMER2 to FreeBSD as another exercise. This port is intended to be built against recent NetBSD code, initially is only read-only support but write support will be tackled once the read support has stabilized.  More details on this still very early stage port of HAMMER2 to NetBSD can be found via this GitHub repository. It will be interesting to see how the HAMMER2 port to NetBSD goes and if eventually could become a viable file-system option for NetBSD installations.









21 Comments 




Tweet







Related News
DragonFlyBSD 6.4 Released With Many FixesNetBSD 10 Beta Brings Much Improved Performance, Long Overdue Hardware SupportFreeBSD 12.4 Released With Various Fixes & ImprovementsTrying Out The BSDs On The Intel Core i9 13900K ""Raptor Lake""FreeBSD Re-Introduces WireGuard Support Into Its KernelFreeBSD 12.4-BETA1 Released, Q3-2022 Status Report Issued
 






About The Author

Michael Larabel is the principal author of Phoronix.com and founded the site in 2004 with a focus on enriching the Linux hardware experience. Michael has written more than 20,000 articles covering the state of Linux hardware support, Linux performance, graphics drivers, and other topics. Michael is also the lead developer of the Phoronix Test Suite, Phoromatic, and OpenBenchmarking.org automated benchmarking software. He can be followed via Twitter, LinkedIn, or contacted via MichaelLarabel.com.


Popular News This Week
DragonFlyBSD's HAMMER2 File-System Being Ported To NetBSDOpenZFS Lands A Very Nice Performance OptimizationA Developer Hopes To Restore GCC's Java Front-EndOBS Studio 29 Released With AV1 Encode Additions, Upward Compression FilterUbuntu's Real-Time Kernel Approaching GA StatusLinux Preparing To Disable Drivers For Microsoft's RNDIS ProtocolLinux 4.9.337 Released To End Out The 2016 LTS SeriesWine 8.0-rc3 Released With 28 Known Bug Fixes
 













Latest Linux News
Removing Some Old Arm Drivers & Board/Machine Code To Lighten The Kernel By 154k Lines


Linux 6.3 To Support Making Use Of Intel's New LKGS Instruction (Part Of FRED)


Linux 6.3 Will Better Handle Missing AMD Radeon Firmware / Unsupported Hardware


Basic OpenGL ES Compute Shader Support Begins Working For The Apple GPU Linux Driver


GNU Binutils 2.40 Released With AMD Zen 4 & Upcoming Intel Instructions, Zstd Support


MSI PRO Z690-A WiFi DDR5 Support Upstreamed To Coreboot


Intel Posts Linux Patches For Linear Address Space Separation (LASS)


AMD ROCm 5.4.2 Released As Another Small Update To The Compute Stack


KDE This Week: ""Pretty Juicy In The Eye Candy Department""


Linux Developers Eye Orphaning The JFS File-System










Show Your Support, Go Premium
Phoronix Premium allows ad-free access to the site, multi-page articles on a single page, and other features while supporting this site's continued operations.


Latest Featured Articles
Setting Up Intel 4th Gen Xeon Scalable ""Sapphire Rapids"" For Accelerator Use


AMD Radeon vs. Intel Arc Graphics With Linux 6.2 + Mesa 23.0


Intel Xeon Platinum 8490H ""Sapphire Rapids"" Performance Benchmarks


Intel Launches 4th Gen Xeon Scalable ""Sapphire Rapids"", Xeon CPU Max Series


AMD Ryzen 5 7600 / Ryzen 7 7700 / Ryzen 9 7900 Linux Performance







 


Support Phoronix
The mission at Phoronix since 2004 has centered around enriching the Linux hardware experience. In addition to supporting our site through advertisements, you can help by subscribing to Phoronix Premium. You can also contribute to Phoronix through a PayPal tip or tip via Stripe.











Phoronix Media


Contact
Michael Larabel
OpenBenchmarking.org



Phoronix Premium


Support Phoronix
While Having Ad-Free Browsing,
Single-Page Article Viewing



Share


Facebook
Twitter







Legal Disclaimer, Privacy Policy, Cookies | Contact
Copyright ¬© 2004 - 2023 by Phoronix Media.
All trademarks used are properties of their respective owners. All rights reserved.







"
https://news.ycombinator.com/rss,The joy of sets,https://www.prospectmagazine.co.uk/arts-and-books/the-joy-of-sets,Comments,"
403 Forbidden

403 Forbidden


"
https://news.ycombinator.com/rss,Server BMCs can need to be rebooted every so often,https://utcc.utoronto.ca/~cks/space/blog/sysadmin/BMCsCanNeedRebooting,Comments,"
 
 Chris's Wiki :: blog/sysadmin/BMCsCanNeedRebooting 






Chris Siebenmann ::
CSpace ¬ª
       blog ¬ª
       sysadmin ¬ª
       BMCsCanNeedRebooting
Welcome, guest.




Your server BMCs can need to be rebooted every so often
January 14, 2023

Over on the Fediverse I said:
A sysadmin tip: if your BMC/IPMI
is doing weird things, restart (reboot) it. Server BMCs are little
computers running ancient versions of Linux with software that's
probably terribly written and they stay running forever, which means
all sorts of opportunities for slow bugs. Reboot away!
This is brought to you by the BMC with a KVM-over-IP that wouldn't
accept '2' entered on the (virtual) keyboard in any way or form. Until
I rebooted the BMC. 
PS: Our IP addresses have 2s in them.

(This probably isn't the only weird BMC glitch we've experienced,
but it's the first one where I tried rebooting the BMC and that
fixed it.)
A number of people shared additional stories in the replies, and I
especially 'liked' @frederic@chaos.social's:
Same for IPMI hardware sensors: Thought the motherboard was damaged
because half the sensors were reported as ""n/a"".  Rebooting magically
fixed this. √∞≈∏‚Ñ¢ÀÜ

This happens for more or less the reasons I mentioned above. BMCs
naturally accumulate very large uptimes because they don't normally
reboot when your server reboots; if you don't do anything special,
your BMC will normally stay up for as long as the server has power.
In many places this can amount to years of uptime, and it's a rare
set of software that can stand up to that even if you don't use
them much. Server vendors typically don't want you to think about
this, and I don't believe 'BMC uptime' is generally exposed anywhere.
(Routinely querying the BMC's sensor readings via IPMI may actually
make this worse, since then the BMC's software is active to answer
those queries. I should probably make our metrics system notice when a server decreases the
number of IPMI metrics it exposes without a reboot.)
Modern BMCs can generally reboot themselves without rebooting their
host (the actual server), although you may want to test this to be
sure since apparently some vendors can do that differently.
PS: How I encountered this is that I was reinstalling a server using
KVM-over-IP, and I hit the portion of the base Ubuntu 22.04 install
when I had to enter the subnet and various associated IP addresses.
Our network has a '2' in it, so all of that failed. Helpfully, the
KVM-over-IP software had a virtual keyboard so I could see it wasn't
just some browser weirdness intercepting a '2' from my real keyboard;
even the virtual keyboard's '2' key wouldn't get through to the
Ubuntu 22.04 installer running on the server being reinstalled. Since
rebooting the BMC didn't reboot the host, I could verify that rebooting
the BMC alone fixed the problem; when the BMC rebooted, my KVM-over-IP
session could now enter all digits.
(I'm glad that it occurred to me to reboot the BMC, instead of just
grumble and go down to the machine room to do the install with the
physical console.)

(One comment.)
Written on 14 January 2023. 

     ¬´   Ubuntu 22.04 LTS servers and phased apt updates    
  



 These are my WanderingThoughts 
(About the blog)
Full index of entries 
Recent comments
This is part of CSpace, and is written by ChrisSiebenmann. 
Mastodon: @cks 
Twitter: @thatcks
* * *
Categories: links, linux, programming, python, snark, solaris, spam, sysadmin, tech, unix, web 
Also: (Sub)topics
This is a DWiki. 
GettingAround 
(Help)
 
 Search:  



 Page tools: View Source, Add Comment. 

Search: 

Login: 
Password: 


 

Atom Syndication: Recent Comments.
 Last modified: Sat Jan 14 22:02:49 2023 
This dinky wiki is brought to you by the Insane Hackers
Guild, Python sub-branch.


"
https://news.ycombinator.com/rss,Bayesian statistics and machine learning: How do they differ?,https://statmodeling.stat.columbia.edu/2023/01/14/bayesian-statistics-and-machine-learning-how-do-they-differ/,Comments,"
403 Forbidden

403 Forbidden
nginx


"
https://news.ycombinator.com/rss,Money creation in the modern economy (2014) [pdf],https://www.bankofengland.co.uk/-/media/boe/files/quarterly-bulletin/2014/money-creation-in-the-modern-economy.pdf?la=en&hash=9A8788FD44A62D8BB927123544205CE476E01654,Comments,"14  Quarterly Bulletin  2014 Q1  Money creation in the modern economy  By Michael McLeay, Amar Radia and Ryland Thomas of the Bank‚Äôs Monetary Analysis Directorate.(1)  ¬Å  This article explains how the majority of money in the modern economy is created by commercial  banks making loans.  ¬Å  Money creation in practice differs from some popular misconceptions ‚Äî banks do not act simply as intermediaries, lending out deposits that savers place with them, and nor do they ‚Äòmultiply up‚Äô central bank money to create new loans and deposits.  ¬Å  The amount of money created in the economy ultimately depends on the monetary policy of the central bank.  In normal times, this is carried out by setting interest rates.  The central bank can also affect the amount of money directly through purchasing assets or ‚Äòquantitative easing‚Äô.  Overview  In the modern economy, most money takes the form of bank deposits.  But how those bank deposits are created is often misunderstood:  the principal way is through commercial banks making loans.  Whenever a bank makes a loan, it simultaneously creates a matching deposit in the borrower‚Äôs bank account, thereby creating new money.  The reality of how money is created today differs from the description found in some economics textbooks:  ¬Å  Rather than banks receiving deposits when households save and then lending them out, bank lending creates deposits.  ¬Å  In normal times, the central bank does not fix the amount  of money in circulation, nor is central bank money ‚Äòmultiplied up‚Äô into more loans and deposits.  Although commercial banks create money through lending, they cannot do so freely without limit.  Banks are limited in how much they can lend if they are to remain profitable in a competitive banking system.  Prudential regulation also acts as a constraint on banks‚Äô activities in order to maintain the resilience of the financial system.  And the households and companies who receive the money created by new lending may take actions that affect the stock of money ‚Äî they could quickly ‚Äòdestroy‚Äô money by using it to repay their existing debt, for instance.  Monetary policy acts as the ultimate limit on money creation.  The Bank of England aims to make sure the amount of money creation in the economy is consistent with  low and stable inflation.  In normal times, the Bank of England implements monetary policy by setting the interest rate on central bank reserves.  This then influences a range of interest rates in the economy, including those on bank loans.  In exceptional circumstances, when interest rates are at theireffective lower bound, money creation and spending in the economy may still be too low to be consistent with the central bank‚Äôs monetary policy objectives.  One possible response is to undertake a series of asset purchases, or‚Äòquantitative easing‚Äô (QE).  QE is intended to boost theamount of money in the economy directly by purchasingassets, mainly from non-bank financial companies. QE initially increases the amount of bank deposits those companies hold (in place of the assets they sell).  Those companies will then wish to rebalance their portfolios ofassets by buying higher-yielding assets, raising the price ofthose assets and stimulating spending in the economy. As a by-product of QE, new central bank reserves arecreated.  But these are not an important part of thetransmission mechanism.  This article explains how, just as innormal times, these reserves cannot be multiplied into moreloans and deposits and how these reserves do not represent‚Äòfree money‚Äô for banks. Click here for a short video filmed in the Bank‚Äôs gold vaults that discusses some of the key topics from this article.  (1)  The authors would like to thank Lewis Kirkham for his help in producing this article.  Topical articles  Money creation in the modern economy  15  Introduction  ‚ÄòMoney in the modern economy:  an introduction‚Äô, a companion piece to this article, provides an overview of what is meant by money and the different types of money that exist in a modern economy, briefly touching upon how each type of money is created.  This article explores money creation in the modern economy in more detail.  The article begins by outlining two common misconceptions about money creation, and explaining how, in the modern economy, money is largely created by commercial banks making loans.(1)  The article then discusses the limits to the banking system‚Äôs ability to create money and the important role for central bank policies in ensuring that credit and money growth are consistent with monetary and financial stability in the economy.  The final section discusses the role of money in the monetary transmission mechanism during periods of quantitative easing (QE), and dispels some myths surrounding money creation and QE.  A short video explains some of the key topics covered in this article.(2)  Two misconceptions about money creation  The vast majority of money held by the public takes the form of bank deposits.  But where the stock of bank deposits comes from is often misunderstood.  One common misconception is that banks act simply as intermediaries, lending out the deposits that savers place with them.  In this view deposits are typically ‚Äòcreated‚Äô by the saving decisions of households, and banks then ‚Äòlend out‚Äô those existing deposits to borrowers, for example to companies looking to finance investment or individuals wanting to purchase houses.  In fact, when households choose to save more money in bank accounts, those deposits come simply at the expense of deposits that would have otherwise gone to companies in payment for goods and services.  Saving does not by itself increase the deposits or ‚Äòfunds available‚Äô for banks to lend. Indeed, viewing banks simply as intermediaries ignores the fact that, in reality in the modern economy, commercial banks are the creators of deposit money.  This article explains how, rather than banks lending out deposits that are placed with them, the act of lending creates deposits ‚Äî the reverse of the sequence typically described in textbooks.(3)  Another common misconception is that the central bank determines the quantity of loans and deposits in the economy by controlling the quantity of central bank money ‚Äî the so-called ‚Äòmoney multiplier‚Äô approach.  In that view, central banks implement monetary policy by choosing a quantity of reserves.  And, because there is assumed to be a constant ratio of broad money to base money, these reserves are then ‚Äòmultiplied up‚Äô to a much greater change in bank  loans and deposits.  For the theory to hold, the amount of reserves must be a binding constraint on lending, and the central bank must directly determine the amount of reserves. While the money multiplier theory can be a useful way of introducing money and banking in economic textbooks, it is not an accurate description of how money is created in reality. Rather than controlling the quantity of reserves, central banks today typically implement monetary policy by setting the price of reserves ‚Äî that is, interest rates.  In reality, neither are reserves a binding constraint on lending, nor does the central bank fix the amount of reserves that are available.  As with the relationship between deposits and loans, the relationship between reserves and loans typically operates in the reverse way to that described in some economics textbooks.  Banks first decide how much to lend depending on the profitable lending opportunities available to them ‚Äî which will, crucially, depend on the interest rate set by the Bank of England.  It is these lending decisions that determine how many bank deposits are created by the banking system.  The amount of bank deposits in turn influences how much central bank money banks want to hold in reserve (to meet withdrawals by the public, make payments to other banks, or meet regulatory liquidity requirements), which is then, in normal times, supplied on demand by the Bank of England.  The rest of this article discusses these practices in more detail.  Money creation in reality  Lending creates deposits ‚Äî broad money determination at the aggregate level As explained in ‚ÄòMoney in the modern economy:  an introduction‚Äô, broad money is a measure of the total amount of money held by households and companies in the economy. Broad money is made up of bank deposits ‚Äî which are essentially IOUs from commercial banks to households and companies ‚Äî and currency ‚Äî mostly IOUs from the central bank.(4)(5)  Of the two types of broad money, bank deposits make up the vast majority ‚Äî 97% of the amount currently in circulation.(6)  And in the modern economy, those bank deposits are mostly created by commercial banks themselves.  (1)  Throughout this article, ‚Äòbanks‚Äô and ‚Äòcommercial banks‚Äô are used to refer to banks and  building societies together.  (2)  See www.youtube.com/watch?v=CvRAqR2pAgw. (3)  There is a long literature that does recognise the ‚Äòendogenous‚Äô nature of money  creation in practice.  See, for example, Moore (1988), Howells (1995) and Palley (1996).  (4)  The definition of broad money used by the Bank of England, M4ex, also includes a  wider range of bank liabilities than regular deposits;  see Burgess and Janssen (2007) for more details.  For simplicity, this article describes all of these liabilities as deposits. A box later in this article provides details about a range of popular monetary aggregates in the United Kingdom.  (5)  Around 6% of the currency in circulation is made up of coins, which are produced by The Royal Mint.  Of the banknotes that circulate in the UK economy, some are issued by some Scottish and Northern Irish commercial banks, although these are fully matched by Bank of England money held at the Bank.  (6)  As of December 2013.  16  Quarterly Bulletin  2014 Q1  Commercial banks create money, in the form of bank deposits, by making new loans.  When a bank makes a loan, for example to someone taking out a mortgage to buy a house, it does not typically do so by giving them thousands of pounds worth of banknotes.  Instead, it credits their bank account with a bank deposit of the size of the mortgage.  At that moment, new money is created.  For this reason, some economists have referred to bank deposits as ‚Äòfountain pen money‚Äô, created at the stroke of bankers‚Äô pens when they approve loans.(1)  This process is illustrated in Figure 1, which shows how new lending affects the balance sheets of different sectors of the economy (similar balance sheet diagrams are introduced in ‚ÄòMoney in the modern economy:  an introduction‚Äô).  As shown in the third row of Figure 1, the new deposits increase the assets of the consumer (here taken to represent households and companies) ‚Äî the extra red bars ‚Äî and the new loan increases their liabilities ‚Äî the extra white bars.  New broad money has been created.  Similarly, both sides of the commercial banking sector‚Äôs balance sheet increase as new money and loans are created.  It is important to note that although the simplified diagram of Figure 1 shows the amount of new money created as being identical to the amount of new lending, in practice there will be several factors that may subsequently cause the amount of deposits to be different from the amount of lending.  These are discussed in detail in the next section.  While new broad money has been created on the consumer‚Äôs balance sheet, the first row of Figure 1 shows that this is without ‚Äî in the first instance, at least ‚Äî any change in the amount of central bank money or ‚Äòbase money‚Äô.  As discussed earlier, the higher stock of deposits may mean that banks want, or are required, to hold more central bank money in order to meet withdrawals by the public or make payments to other banks.  And reserves are, in normal times, supplied ‚Äòon demand‚Äô by the Bank of England to commercial banks in exchange for other assets on their balance sheets.  In no way does the aggregate quantity of reserves directly constrain the amount of bank lending or deposit creation.  This description of money creation contrasts with the notion that banks can only lend out pre-existing money, outlined in the previous section.  Bank deposits are simply a record of how much the bank itself owes its customers.  So they are a liability of the bank, not an asset that could be lent out.  A related misconception is that banks can lend out their reserves. Reserves can only be lent between banks, since consumers do not have access to reserves accounts at the Bank of England.(2)  Other ways of creating and destroying deposits Just as taking out a new loan creates money, the repayment of bank loans destroys money.(3)  For example, suppose a consumer has spent money in the supermarket throughout the month by using a credit card.  Each purchase made using the  Figure 1  Money creation by the aggregate banking sector making additional loans(a)  Before loans are made  After loans are made  Assets  Liabilities  Assets  Liabilities  Central bank(b)  Non-money  Reserves  Currency  Base money  Non-money  Reserves  Currency  Base money  Commercial banks(c)  Assets  Liabilities  New loans  New deposits  Assets  Liabilities  Reserves  Deposits  Reserves  Deposits  Currency  Currency  Consumers(d)  Assets  Liabilities  New deposits  New loans  Assets  Liabilities  Broad money  Broad money  Deposits  Non-money  Deposits  Non-money  Currency  Currency  (a)  Balance sheets are highly stylised for ease of exposition:  the quantities of each type of  money shown do not correspond to the quantities actually held on each sector‚Äôs balance sheet.  (b)  Central bank balance sheet only shows base money liabilities and the corresponding assets. In practice the central bank holds other non-money liabilities.  Its non-monetary assets are mostly made up of government debt.  Although that government debt is actually held by the Bank of England Asset Purchase Facility, so does not appear directly on the balance sheet. (c)  Commercial banks‚Äô balance sheets only show money assets and liabilities before any loans  are made.  (d)  Consumers represent the private sector of households and companies.  Balance sheet only shows broad money assets and corresponding liabilities ‚Äî real assets such as the house being transacted are not shown.  Consumers‚Äô non-money liabilities include existing secured and unsecured loans.  credit card will have increased the outstanding loans on the consumer‚Äôs balance sheet and the deposits on the supermarket‚Äôs balance sheet (in a similar way to that shown in Figure 1).  If the consumer were then to pay their credit card  (1)  Fountain pen money is discussed in Tobin (1963), who mentions it in the context of making an argument that banks cannot create unlimited amounts of money in practice.  (2)  Part of the confusion may stem from some economists‚Äô use of the term ‚Äòreserves‚Äô when referring to ‚Äòexcess reserves‚Äô ‚Äî balances held above those required by regulatory reserve requirements.  In this context, ‚Äòlending out reserves‚Äô could be a shorthand way of describing the process of increasing lending and deposits until the bank reaches its maximum ratio.  As there are no reserve requirements in the United Kingdom the process is less relevant for UK banks.  (3)  The fall in bank lending in the United Kingdom since 2008 is an important reason why  the growth of money in the economy has been so much lower than in the years leading up to the crisis, as discussed in Bridges, Rossiter and Thomas (2011) and Butt et al (2012).  Topical articles  Money creation in the modern economy  17  bill in full at the end of the month, its bank would reduce the amount of deposits in the consumer‚Äôs account by the value of the credit card bill, thus destroying all of the newly created money.  Banks making loans and consumers repaying them are the most significant ways in which bank deposits are created and destroyed in the modern economy.  But they are far from the only ways.  Deposit creation or destruction will also occur any time the banking sector (including the central bank) buys or sells existing assets from or to consumers, or, more often, from companies or the government.  Banks buying and selling government bonds is one particularly important way in which the purchase or sale of existing assets by banks creates and destroys money.  Banks often buy and hold government bonds as part of their portfolio of liquid assets that can be sold on quickly for central bank money if, for example, depositors want to withdraw currency in large amounts.(1)  When banks purchase government bonds from the non-bank private sector they credit the sellers with bank deposits.(2)  And, as discussed later in this article, central bank asset purchases, known as quantitative easing (QE), have similar implications for money creation.  Money can also be destroyed through the issuance of long-term debt and equity instruments by banks.  In addition to deposits, banks hold other liabilities on their balance sheets. Banks manage their liabilities to ensure that they have at least some capital and longer-term debt liabilities to mitigate certain risks and meet regulatory requirements.  Because these ‚Äònon-deposit‚Äô liabilities represent longer-term investments in the banking system by households and companies, they cannot be exchanged for currency as easily as bank deposits, and therefore increase the resilience of the bank.  When banks issue these longer-term debt and equity instruments to non-bank financial companies, those companies pay for them with bank deposits.  That reduces the amount of deposit, or money, liabilities on the banking sector‚Äôs balance sheet and increases their non-deposit liabilities.(3)  Buying and selling of existing assets and issuing longer-term liabilities may lead to a gap between lending and deposits in a closed economy.  Additionally, in an open economy such as the United Kingdom, deposits can pass from domestic residents to overseas residents, or sterling deposits could be converted into foreign currency deposits.  These transactions do not destroy money per se, but overseas residents‚Äô deposits and foreign currency deposits are not always counted as part of a country‚Äôs money supply.  Limits to broad money creation Although commercial banks create money through their lending behaviour, they cannot in practice do so without limit. In particular, the price of loans ‚Äî that is, the interest rate (plus  any fees) charged by banks ‚Äî determines the amount that households and companies will want to borrow.  A number of factors influence the price of new lending, not least the monetary policy of the Bank of England, which affects the level of various interest rates in the economy.  The limits to money creation by the banking system were discussed in a paper by Nobel Prize winning economist James Tobin and this topic has recently been the subject of debate among a number of economic commentators and bloggers.(4)  In the modern economy there are three main sets of constraints that restrict the amount of money that banks can create.  (i)  Banks themselves face limits on how much they can  lend.  In particular:  ¬Å  Market forces constrain lending because individual  banks have to be able to lend profitably in a competitive market.  ¬Å  Lending is also constrained because banks have to take  steps to mitigate the risks associated with making additional loans.  ¬Å  Regulatory policy acts as a constraint on banks‚Äô  activities in order to mitigate a build-up of risks that could pose a threat to the stability of the financial system.  (ii)  Money creation is also constrained by the behaviour of the money holders ‚Äî households and businesses. Households and companies who receive the newly created money might respond by undertaking transactions that immediately destroy it, for example by repaying outstanding loans.  (iii)  The ultimate constraint on money creation is monetary policy.  By influencing the level of interest rates in the economy, the Bank of England‚Äôs monetary policy affects how much households and companies want to borrow. This occurs both directly, through influencing the loan rates charged by banks, but also indirectly through the overall effect of monetary policy on economic activity in  (1)  It is for this reason that holdings of some government bonds are counted towards meeting prudential liquidity requirements, as described in more detail by Farag, Harland and Nixon (2013).  (2)  In a balance sheet diagram such as Figure 1, a purchase of government bonds from consumers by banks would be represented by a change in the composition of consumers‚Äô assets from government bonds to deposits and an increase in both deposits and government bonds on the commercial banks‚Äô balance sheet.  (3)  Commercial banks‚Äô purchases of government bonds and their issuance of long-term  debt and equity have both been important influences on broad money growth during the financial crisis as discussed in Bridges, Rossiter and Thomas (2011) and Butt et al (2012).  (4)  Tobin (1963) argued that banks do not possess a ‚Äòwidow‚Äôs cruse‚Äô, referring to a biblical story (earlier referenced in economics by John Maynard Keynes) in which a widow is able to miraculously refill a cruse (a pot or jar) of oil during a famine.  Tobin was arguing that there were limits to how many loans could be automatically matched by deposits.  18  Quarterly Bulletin  2014 Q1  the economy.  As a result, the Bank of England is able to ensure that money growth is consistent with its objective of low and stable inflation.  make many such loans every day.  So if a given bank financed all of its new loans in this way, it would soon run out of reserves.  The remainder of this section explains how each of these mechanisms work in practice.  (i) Limits on how much banks can lend Market forces facing individual banks Figure 1 showed how, for the aggregate banking sector, loans are initially created with matching deposits.  But that does not mean that any given individual bank can freely lend and create money without limit.  That is because banks have to be able to lend profitably in a competitive market, and ensure that they adequately manage the risks associated with making loans.  Banks receive interest payments on their assets, such as loans, but they also generally have to pay interest on their liabilities, such as savings accounts.  A bank‚Äôs business model relies on receiving a higher interest rate on the loans (or other assets) than the rate it pays out on its deposits (or other liabilities). Interest rates on both banks‚Äô assets and liabilities depend on the policy rate set by the Bank of England, which acts as the ultimate constraint on money creation.  The commercial bank uses the difference, or spread, between the expected return on their assets and liabilities to cover its operating costs and to make profits.(1)  In order to make extra loans, an individual bank will typically have to lower its loan rates relative to its competitors to induce households and companies to borrow more.  And once it has made the loan it may well ‚Äòlose‚Äô the deposits it has created to those competing banks.  Both of these factors affect the profitability of making a loan for an individual bank and influence how much borrowing takes place.  For example, suppose an individual bank lowers the rate it charges on its loans, and that attracts a household to take out a mortgage to buy a house.  The moment the mortgage loan is made, the household‚Äôs account is credited with new deposits. And once they purchase the house, they pass their new deposits on to the house seller.  This situation is shown in the first row of Figure 2.  The buyer is left with a new asset in the form of a house and a new liability in the form of a new loan. The seller is left with money in the form of bank deposits instead of a house.  It is more likely than not that the seller‚Äôs account will be with a different bank to the buyer‚Äôs.  So when the transaction takes place, the new deposits will be transferred to the seller‚Äôs bank, as shown in the second row of Figure 2.  The buyer‚Äôs bank would then have fewer deposits than assets.  In the first instance, the buyer‚Äôs bank settles with the seller‚Äôs bank by transferring reserves.  But that would leave the buyer‚Äôs bank with fewer reserves and more loans relative to its deposits than before.  This is likely to be problematic for the bank since it would increase the risk that it would not be able to meet all of its likely outflows.  And, in practice, banks  Banks therefore try to attract or retain additional liabilities to accompany their new loans.  In practice other banks would also be making new loans and creating new deposits, so one way they can do this is to try and attract some of those newly created deposits.  In a competitive banking sector, that may involve increasing the rate they offer to households on their savings accounts.  By attracting new deposits, the bank can increase its lending without running down its reserves, as shown in the third row of Figure 2.  Alternatively, a bank can borrow from other banks or attract other forms of liabilities, at least temporarily.  But whether through deposits or other liabilities, the bank would need to make sure it was attracting and retaining some kind of funds in order to keep expanding lending.  And the cost of that needs to be measured against the interest the bank expects to earn on the loans it is making, which in turn depends on the level of Bank Rate set by the Bank of England.  For example, if a bank continued to attract new borrowers and increase lending by reducing mortgage rates, and sought to attract new deposits by increasing the rates it was paying on its customers‚Äô deposits, it might soon find it unprofitable to keep expanding its lending.  Competition for loans and deposits, and the desire to make a profit, therefore limit money creation by banks.  Managing the risks associated with making loans Banks also need to manage the risks associated with making new loans.  One way in which they do this is by making sure that they attract relatively stable deposits to match their new loans, that is, deposits that are unlikely or unable to be withdrawn in large amounts.  This can act as an additional limit to how much banks can lend.  For example, if all of the deposits that a bank held were in the form of instant access accounts, such as current accounts, then the bank might run the risk of lots of these deposits being withdrawn in a short period of time.  Because banks tend to lend for periods of many months or years, the bank may not be able to repay all of those deposits ‚Äî it would face a great deal of liquidity risk. In order to reduce liquidity risk, banks try to make sure that some of their deposits are fixed for a certain period of time, or term.(2)  Consumers are likely to require compensation for the inconvenience of holding longer-term deposits, however, so these are likely to be more costly for banks, limiting the amount of lending banks wish to do.  And as discussed earlier, if banks guard against liquidity risk by issuing long-term liabilities, this may destroy money directly when companies pay for them using deposits.  (1)  See Button, Pezzini and Rossiter (2010) for an explanation of how banks price new  loans.  (2)  Banks also guard against liquidity risk by holding liquid assets (including reserves and currency), which either can be used directly to cover outflows, or if not can quickly and cheaply be converted into assets that can.  Although if banks purchase liquid assets such as government bonds from non-banks, this could create further deposits.  Topical articles  Money creation in the modern economy  19  Figure 2  Money creation for an individual bank making an additional loan(a)  Changes to the balance sheets of the house buyer and seller  House buyer  House seller  House buyer  House seller  House buyer  House seller  Assets  Liabilities  Assets  Liabilities  Assets  Liabilities  Assets  Liabilities  Assets  Liabilities  Assets  Liabilities  Non-money (house)  GovernmentDeposits debt Currency  Deposits  Currency  Non-money  New deposit  New loan  Non-money (house)  Non-money (house)  New loan  New deposit  Non-money  Non-money  Non-money  Deposits  Currency  Non-money  GovernmentDeposits debt Currency  Deposits  Currency  Non-money  GovernmentDeposits debt Currency  Balance sheets before the loan is made.  The house buyer takes out a mortgage‚Ä¶  ‚Ä¶and uses its new deposits to pay the house seller.  Changes to the balance sheets of the house buyer and seller‚Äôs banks  Buyer‚Äôs bank  Seller‚Äôs bank  Buyer‚Äôs bank  Seller‚Äôs bank  Buyer‚Äôs bank  Seller‚Äôs bank  Assets  Liabilities  Assets  Liabilities  Assets  Liabilities  Assets  Liabilities  Assets  Liabilities  Assets  Liabilities  New loan  New deposit  Transferred reserves  New deposit  Reserves  Deposits  Reserves  Deposits  Reserves  Deposits  Reserves  Deposits  Currency  Currency  Currency  Currency  Balance sheets before the loan is made.  The mortgage lender creates new deposits‚Ä¶  New loan  Reserves  Currency  Deposits  Reserves  Currency  Deposits  ‚Ä¶which are transferred to the seller‚Äôs bank, along with reserves, which the buyer‚Äôs bank uses to settle the transaction.  But settling all transactions in this way would be unsustainable: ‚Ä¢  The buyer‚Äôs bank would have fewer reserves to meet its possible  outfows, for example from deposit withdrawals.  ‚Ä¢  And if it made many new loans it would eventually run out  of reserves.  Buyer‚Äôs bank  Seller‚Äôs bank  Assets  Liabilities  Assets  Liabilities  New loan  New deposit  Reserves  Reserves  Currency  Deposits  Reserves  Currency  Deposits  So the buyer‚Äôs bank will in practice seek to attract or retain new deposits (and reserves) ‚Äî in the example shown here, from the seller‚Äôs bank ‚Äî to accompany their new loans.  (a)  Balance sheets are highly stylised for ease of exposition:  the quantities of each type of money shown do not correspond to the quantities actually held on each sector‚Äôs balance sheet.  Individual banks‚Äô lending is also limited by considerations of credit risk.  This is the risk to the bank of lending to borrowers who turn out to be unable to repay their loans.  In part, banks can guard against credit risk by having sufficient capital to absorb any unexpected losses on their loans.  But since loans will always involve some risk to banks of incurring losses, the cost of these losses will be taken into account when pricing loans.  When a bank makes a loan, the interest rate it charges will typically include compensation for the average level of credit losses the bank expects to suffer.  The size of this component of the interest rate will be larger when banks estimate that they will suffer higher losses, for example when lending to mortgagors with a high loan to value ratio.  As banks expand lending, their average expected loss per loan is likely to increase, making those loans less profitable.  This further limits the amount of lending banks can profitably do, and the money they can therefore create.  Market forces do not always lead individual banks to sufficiently protect themselves against liquidity and credit risks.  Because of this, prudential regulation aims to ensure that banks do not take excessive risks when making new loans, including via requirements for banks‚Äô capital and liquidity positions.  These requirements can therefore act as an additional brake on how much money commercial banks create by lending.  The prudential regulatory framework, along with more detail on capital and liquidity, is described in Farag, Harland and Nixon (2013).  So far this section has considered the case of an individual bank making additional loans by offering competitive interest rates ‚Äî both on its loans and deposits.  But if all banks simultaneously decide to try to do more lending, money growth may not be limited in quite the same way.  Although an individual bank may lose deposits to other banks, it would itself be likely to gain some deposits as a result of the other banks making loans.     20  Quarterly Bulletin  2014 Q1  There are a number of reasons why many banks may choose to increase their lending markedly at the same time.  For example, the profitability of lending at given interest rates could increase because of a general improvement in economic conditions.  Alternatively, banks may decide to lend more if they perceive the risks associated with making loans to households and companies to have fallen.  This sort of development is sometimes argued to be one of the reasons why bank lending expanded so much in the lead up to the financial crisis.(1)  But if that perception of a less risky environment were unwarranted, the result could be a more fragile financial system.(2)  One of the responses to the crisis in the United Kingdom has been the creation of a macroprudential authority, the Financial Policy Committee, to identify, monitor and take action to reduce or remove risks which threaten the resilience of the financial system as a whole.(3)  (ii) Constraints arising from the response of households and companies In addition to the range of constraints facing banks that act to limit money creation, the behaviour of households and companies in response to money creation by the banking sector can also be important, as argued by Tobin.  The behaviour of the non-bank private sector influences the ultimate impact that credit creation by the banking sector has on the stock of money because more (or less) money may be created than they wish to hold relative to other assets (such as property or shares).  As the households and companies who take out loans do so because they want to spend more, they will quickly pass that money on to others as they do so.  How those households and companies then respond will determine the stock of money in the economy, and potentially have implications for spending and inflation.  There are two main possibilities for what could happen to newly created deposits.  First, as suggested by Tobin, the money may quickly be destroyed if the households or companies receiving the money after the loan is spent wish to use it to repay their own outstanding bank loans.  This is sometimes referred to as the ‚Äòreflux theory‚Äô.(4) For example, a first-time house buyer may take out a mortgage to purchase a house from an elderly person who, in turn, repays their existing mortgage and moves in with their family.  As discussed earlier, repaying bank loans destroys money just as making loans creates it.  So, in this case, the balance sheet of consumers in the economy would be returned to the position it was in before the loan was made.  in the economy.(5)  Instead, the money may initially pass to households or companies with positive holdings of financial assets:  the elderly person may have already paid off their mortgage, or a company receiving money as a payment may already have sufficient liquid assets to cover possible outgoings.  They may then be left holding more money than they desire, and attempt to reduce their ‚Äòexcess‚Äô money holdings by increasing their spending on goods and services. (In the case of a company it may instead buy other, higher-yielding, assets.)  These two scenarios for what happens to newly created money ‚Äî being quickly destroyed or being passed on via spending ‚Äî have very different implications for economic activity.  In the latter, the money may continue to be passed between different households and companies each of whom may, in turn, increase their spending.  This process ‚Äî sometimes referred to as the ‚Äòhot potato‚Äô effect ‚Äî can lead, other things equal, to increased inflationary pressure on the economy.(6)  In contrast, if the money is quickly destroyed as in the former scenario, there need be no further effects on the economy.  This section has so far discussed how the actions of banks, households and companies can affect the amount of money in the economy, and therefore inflationary pressure.  But the ultimate determinant of monetary conditions in the economy is the monetary policy of the central bank.  (iii) Monetary policy ‚Äî the ultimate constraint on money creation One of the Bank of England‚Äôs primary objectives is to ensure monetary stability by keeping consumer price inflation on track to meet the 2% target set by the Government.  And, as discussed in the box on pages 22‚Äì23, over some periods of time, various measures of money have grown at a similar rate to nominal spending, which determines inflationary pressure in the economy in the medium term.  So setting monetary policy appropriately to meet the inflation target should ultimately ensure a stable rate of credit and money creation consistent with meeting that target.  This section explains the relationship between monetary policy and different types of money.  In normal times, the Monetary Policy Committee (MPC), like most of its equivalents in other countries, implements monetary policy by setting short-term interest rates, specifically by setting the interest rate paid on central bank reserves held by commercial banks.  It is able to do so because  The second possible outcome is that the extra money creation by banks can lead to more spending in the economy.  For newly created money to be destroyed, it needs to pass to households and companies with existing loans who want to repay them.  But this will not always be the case, since asset and debt holdings tend to vary considerably across individuals  (1)  See, for example, Haldane (2009). (2)  Tucker (2009) discusses the possibility of such ‚Äòrisk illusion‚Äô in the financial system. (3)  Tucker, Hall and Pattani (2013) describe the new powers for macroprudential policymaking in the United Kingdom in the wake of the recent financial crisis.  (4)  See Kaldor and Trevithick (1981). (5)  See Kamath et al (2011). (6)  This mechanism is explained in more detail in papers including Laidler (1984),  Congdon (1992, 2005), Howells (1995), Laidler and Robson (1995), Bridges, Rossiter and Thomas (2011) and Bridges and Thomas (2012).  Topical articles  Money creation in the modern economy  21  of the Bank‚Äôs position as the monopoly provider of central bank money in the United Kingdom.  And it is because there is demand for central bank money ‚Äî the ultimate means of settlement for banks, the creators of broad money ‚Äî that the price of reserves has a meaningful impact on other interest rates in the economy.  The interest rate that commercial banks can obtain on money placed at the central bank influences the rate at which they are willing to lend on similar terms in sterling money markets ‚Äî the markets in which the Bank and commercial banks lend to each other and other financial institutions.  The exact details of how the Bank uses its money market operations to implement monetary policy has varied over time, and central bank operating procedures today differ somewhat from country to country, as discussed in Clews, Salmon and Weeken (2010).(1)  Changes in interbank interest rates then feed through to a wider range of interest rates in different markets and at different maturities, including the interest rates that banks charge borrowers for loans and offer savers for deposits.(2)  By influencing the price of credit in this way, monetary policy affects the creation of broad money.  This description of the relationship between monetary policy and money differs from the description in many introductory textbooks, where central banks determine the quantity of broad money via a ‚Äòmoney multiplier‚Äô by actively varying the quantity of reserves.(3)  In that view, central banks implement monetary policy by choosing the quantity of reserves.  And, because there is assumed to be a stable ratio of broad money to base money, these reserves are then ‚Äòmultiplied up‚Äô to a much greater change in bank deposits as banks increase lending and deposits.  Neither step in that story represents an accurate description of the relationship between money and monetary policy in the modern economy.  Central banks do not typically choose a quantity  of reserves to bring about the desired short-term interest rate.(4)  Rather, they focus on prices ‚Äî setting interest rates.(5)  The Bank of England controls interest rates by supplying and remunerating reserves at its chosen policy rate.  The supply of both reserves and currency (which together make up base money) is determined by banks‚Äô demand for reserves both for the settlement of payments and to meet demand for currency from their customers ‚Äî demand that the central bank typically accommodates.  This demand for base money is therefore more likely to be a consequence rather than a cause of banks making loans and creating broad money.  This is because banks‚Äô decisions to extend credit are based on the availability of profitable lending opportunities at any given point in time.  The profitability of making a loan will depend on a number of factors, as discussed earlier.  One of these is the cost of funds that banks face, which is closely related to the interest rate paid on reserves, the policy rate.  In contrast, the quantity of reserves already in the system does not constrain the creation of broad money through the act of lending.(6)  This leg of the money multiplier is sometimes motivated by appealing to central bank reserve requirements, whereby banks are obliged to hold a minimum amount of reserves equal to a fixed proportion of their holdings of deposits.  But reserve requirements are not an important aspect of monetary policy frameworks in most advanced economies today.(7)  A looser stance of monetary policy is likely to increase the stock of broad money by reducing loan rates and increasing the volume of loans.  And a larger stock of broad money, accompanied by an increased level of spending in the economy, may cause banks and customers to demand more reserves and currency.(8)  So, in reality, the theory of the money multiplier operates in the reverse way to that normally described.  QE ‚Äî creating broad money directly with monetary policy  The previous section discussed how monetary policy can be seen as the ultimate limit to money creation by commercial banks.  But commercial banks could alternatively create too little money to be consistent with the economy meeting the inflation target.  In normal times, the MPC can respond by lowering the policy rate to encourage more lending and hence more money creation.  But, in response to the financial crisis, the MPC cut Bank Rate to 0.5% ‚Äî the so-called effective lower bound.  Once short-term interest rates reach the effective lower bound, it is not possible for the central bank to provide further stimulus to the economy by lowering the rate at which reserves are remunerated.(9)  One possible way of providing further monetary stimulus to the economy is through a programme of asset purchases (QE).  Like reductions in Bank  (1)  The framework for the Bank‚Äôs operations in the sterling money markets is set out in  the Bank‚Äôs ‚ÄòRed Book‚Äô, available at www.bankofengland.co.uk/markets/Documents/money/publications/redbook.pdf. Recent developments in sterling money markets are discussed by Jackson and Sim (2013).  (2)  Bank of England (1999) discusses the transmission mechanism of monetary policy in  more detail.  (3)  Benes and Kumhof (2012) discuss the money multiplier myth in more detail. (4)  As discussed by Disyatat (2008). (5)  Bindseil (2004) provides a detailed account of how monetary policy implementation  works through short-term interest rates.  (6)  Carpenter and Demiralp (2012) show that changes in quantities of reserves are  unrelated to changes in quantities of loans in the United States.  (7)  The Bank of England currently has no formal reserve requirements, for example. (It does require banks to hold a proportion of non-interest bearing ‚Äòcash ratio deposits‚Äô with the Bank for a subset of their liabilities.  But the function of these cash ratio deposits is non-operational.  Their sole purpose is to provide income for the Bank.)  Bernanke (2007) discusses how reserve requirements now present less of a constraint than in the past in the United States.  (8)  Kydland and Prescott (1990) found that broad money aggregates led the cycle, while  base money aggregates tended to lag the cycle slightly.  (9)  If the central bank were to lower interest rates significantly below zero, banks could swap their bank reserves into currency, which would pay a higher interest rate (of zero, or slightly less after taking into account the costs of storing currency).  Or put another way, the demand for central bank reserves would disappear, so the central bank could no longer influence the economy by changing the price of those reserves.  22  Quarterly Bulletin  2014 Q1  The information content of different types of money and monetary aggregates  One of the Bank of England‚Äôs primary objectives is to ensure monetary stability by keeping inflation on track to meet the Government‚Äôs 2% target.  Milton Friedman (1963) famously argued that ‚Äòinflation is always and everywhere a monetary phenomenon‚Äô.  So changes in the money supply may contain valuable information about spending and inflationary pressure in the economy.  Since money is essential for buying goods and services, it is likely to contain corroborative information about the current level of nominal spending in the economy.  It may also provide incremental information about future movements in nominal spending, and so can be a useful indicator of future inflationary pressure.  Finally, the behaviour of money may help to reveal the nature of the monetary transmission mechanism, especially when monetary policy is operated through ‚Äòquantitative easing‚Äô (QE).  In practice, a key difficulty is assessing which measures of money are the appropriate ones to look at for each of the different purposes.  The Bank currently constructs a number of monetary aggregates and publishes a range of data that allow to be created, summarised in Table 1.  Chart A shows some long-run historical time series of the growth of monetary aggregates compared with that of nominal spending in the economy.(1)  Given the various changes in the UK monetary regime over the past 150 years, it is unlikely that a single monetary indicator perfectly captures both the corroborative and incremental information in money.  The UK financial sector has also undergone various structural changes that need to be taken into account when considering the underlying link between money and spending.  For example, during periods when the financial sector has grown relative to the rest of the economy (such as in the early 1980s and the 2000s), broad money has tended to grow persistently faster than nominal spending.  Narrower measures of money, such as notes and coin and sight deposits (accounts that can be withdrawn immediately without penalty) are, in principle, better corroborative indicators of spending, as these are likely to be the types of money used to carry out the majority of transactions in goods and services in the economy.  The sum of notes and coin and sight deposits held by the non-bank private sector is sometimes known as zero maturity money or ‚ÄòMZM‚Äô.(2)  Broader measures of money might be more appropriate as incremental indicators of future spending and more revealing about the nature of the transmission mechanism.  M2, for example, additionally includes household time deposits such as savings accounts.(3)  And M4 is an even broader measure, including all sight and time deposits held by non-financial companies and non-bank financial companies.  The main article describes how QE works by first increasing the deposits of financial companies.  As these companies rebalance their  portfolios, asset prices are likely to increase and, with a lag, lead to an increase in households‚Äô and companies‚Äô spending.  So monitoring broad money has been an important part of assessing the effectiveness of QE.(4)  A number of econometric studies have suggested that sectoral movements in broad money may also provide valuable incremental information about spending in the economy.(5)  For example, non-financial companies‚Äô deposits appear to be a leading indicator of business investment in the economy. One can also try and weight different types of narrow and broad money together using some metric of how much each type of money is used in transactions ‚Äî known as a Divisia index.(6)  In practice, the interest paid on a given type of money is typically used as a weighting metric.  That is because individuals and companies are only likely to hold money which earns a low interest rate relative to other financial instruments if it compensates them by providing greater transactions services.  Identifying the appropriate measurement of money has been complicated by the continued development of the financial sector.  This has both expanded the range of instruments that might serve as money and the range of financial institutions that borrow from and deposit with the traditional banking system.  For example, sale and repurchase agreements (known as repos) ‚Äî where a company agrees to buy a security from a bank with agreement to sell it back later ‚Äî are currently included in M4 since the claim held on the bank can be thought of as a secured deposit.  In addition, some economists have argued that a range of instruments that provide collateral for various types of borrowing and lending could also be included in a broader measure of money.(7)  Moreover, many of the non-bank institutions that hold deposits mainly intermediate between banks themselves.  The deposits of these institutions, known as ‚Äòintermediate other financial corporations‚Äô (IOFCs), are likely to reflect activities within the banking system that are not directly related to spending in the economy.(8)  For this reason, the Bank‚Äôs headline measure of broad money is M4ex, which excludes IOFC deposits.  (1)  These series involve splicing together current Bank of England data with historic data  on monetary aggregates.  A spreadsheet of the data is available at www.bankofengland.co.uk/publications/Documents/quarterlybulletin/2014/ longrunmoneydata.xls.  (2)  A narrower measure known as non-interest bearing M1 can also be constructed.  This measure has become a less useful aggregate as most sight deposits now pay some form of interest.  For example, during the financial crisis when interest rates fell close to zero, the growth of non-interest bearing M1 picked up markedly as the relative cost of holding a non-interest bearing deposit fell sharply compared to an interest-bearing one.  Focusing on M1 would have given a misleading signal about the growth of nominal spending in the economy.  (3)  M2 contains the non-bank private sector‚Äôs holdings of notes and coin plus ‚Äòretail‚Äô  deposits which are deposits that pay an advertised interest rate.  Those will largely be deposits held by households but will also apply to some corporate deposits.  (4)  See Bridges, Rossiter and Thomas (2011) and Butt et al (2012). (5)  See, for example, Astley and Haldane (1995), Thomas (1997a, b) and Brigden and  Mizen (2004).  (6)  See Hancock (2005), for example. (7)  See, for example, Singh (2013). (8)  See Burgess and Janssen (2007) and  www.bankofengland.co.uk/statistics/Pages/iadb/notesiadb/m4adjusted.aspx for more detail.  Topical articles  Money creation in the modern economy  23  Table 1  Popular monetary aggregates that can be constructed from available UK data(a)  Name  Definition  Description(b)  Availability  Notes and coin  M0  Notes and coin in circulation outside the Bank of England.  Notes and coin plus central bank reserves.  The narrowest measure of money and used as an indicator of cash-based transactions.  1870‚Äìpresent(c)  Historically the base measure of money used in money multiplier calculations.  Often used as an approximate measure of the size of the Bank of England‚Äôs balance sheet. No longer published by the Bank of England but can be reconstructed.(d)  1870‚Äìpresent(c)  Non-interest bearing M1  Notes and coin plus non-interest bearing sight deposits held by the non-bank private sector.  An indicator of transactions in goods and services in the economy, less useful now since most sight deposits pay some form of interest.  1921‚Äìpresent(c)  Not published by the Bank of England but can be constructed from published components.  MZM  Notes and coin plus all sight deposits held by the non-bank private sector.  M2 or retail M4  Notes and coin plus all retail deposits (including retail time deposits) held by the non-bank private sector.  Notes and coin plus all sight and time deposits held with banks (excluding building societies) by the non-bank private sector.  Notes and coin, deposits, certificates of deposit, repos and securities with a maturity of less than five years held by the non-bank private sector.  M3  M4  M4ex  Divisia  An indicator of transactions in goods and services in the economy.  1977‚Äìpresent  Not published by the Bank of England but can be constructed from published components. The Bank also produces a measure based on an ECB definition of M1.  A broader measure of money than MZM encompassing all retail deposits.  The key additions are household time deposits and some corporate retail time deposits.  1982‚Äìpresent  Published by the Bank of England.  The Bank also produces a measure based on an ECB definition of M2.  Up until 1987 the headline broad monetary aggregate constructed by the Bank of England.  1870‚Äì1990(c)  The Bank also produces a measure based on an ECB definition of M3.  Up until 2007 the headline broad monetary aggregate constructed by the Bank of England.  1963‚Äìpresent  M4 excluding the deposits of IOFCs.  Since 2007 the headline broad monetary aggregate constructed by the Bank of England.  1997‚Äìpresent  A weighted sum of different types of money.  Aims to weight the component assets of broad money according to the transactions services they provide.(e)  1977‚Äìpresent  (a)  All definitions refer to sterling instruments only.  Some of the definitions in this table were changed at various points in time.  For example the original M3 aggregate included public sector deposits and thesector‚Äôs holdings of deposits in foreign currency.  A more comprehensive history of the development of UK monetary aggregates can be found at www.bankofengland.co.uk/statistics/Documents/ms/articl  non-bank private es/art2jul03.pdf.  (b)  Published by the Bank of England unless otherwise stated. (c)  This series uses the data constructed by Capie and Webber (1985). (d)  Data on M0 were discontinued following reforms to the Bank of England‚Äôs money market operations in 2006.  See www.bankofengland.co.uk/statistics/Documents/ms/articles/artjun06.pdf for more detai(e)  The Divisia indices for other financial corporations and for the non-bank private sector were discontinued in 2013.  See www.bankofengland.co.uk/statistics/Documents/ms/articles/art1aug13.pdf for more  ls. details.  Chart A  Different monetary aggregates and nominal spending  Notes and coin(a) Non-interest bearing M1(b)  MZM(c) M2(d) Divisia M3/M4/M4ex(e)  Nominal GDP(f)  Percentage changes on a year earlier  1870  80  90  1900  10  20  30  40  50  60  70  80  90  2000 10  60  50  40  30  20  10 + 0 ‚Äì 10  20  30  Sources:  Bank of England, Capie and Webber (1985), Mitchell (1988), ONS, Sefton and Weale (1995), Solomou and Weale (1991) and Bank calculations.  All series seasonally adjusted and break-adjusted where possible.  Historical data seasonally adjusted using X12.  (a)  1969 Q2 to 2013 Q4 ‚Äî notes and coin in circulation.  1870 Q1 to 1969 Q2 ‚Äî M0 from Capie and Webber (1985). (b)  1977 Q1 to 2013 Q4 ‚Äî notes and coin held by the non-bank and building society private sector plus non-interest bearing deposits.  Prior to 2008 Q1, excludes deposits with  building societies.  1963 Q1 to 1977 Q1 ‚Äî historical M1 data from Bank of England Quarterly Bulletins.  1921 Q4 to 1963 Q1 ‚Äî Capie and Webber (1985). (c)  Notes and coin held by the non-bank and building society private sector plus total sight deposits.  Prior to 1998 Q4 excludes deposits with building societies. (d)  Notes and coin and retail deposits held by the non-bank and building society private sector. (e)  1997 Q4 to 2013 Q4 ‚Äî M4 excluding intermediate OFCs.  1963 Q1 to 1997 Q4 ‚Äî M4.  1870 Q2 to 1963 Q1 ‚Äî M3 from Capie and Webber (1985). (f)  Composite estimate of nominal GDP at market prices.  See appendix of Hills, Thomas and Dimsdale (2010) for details.  24  Quarterly Bulletin  2014 Q1  Rate, asset purchases are a way in which the MPC can loosen the stance of monetary policy in order to stimulate economic activity and meet its inflation target.  But the role of money in the two policies is not the same.  QE involves a shift in the focus of monetary policy to the quantity of money:  the central bank purchases a quantity of assets, financed by the creation of broad money and a corresponding increase in the amount of central bank reserves. The sellers of the assets will be left holding the newly created deposits in place of government bonds.  They will be likely to be holding more money than they would like, relative to other assets that they wish to hold.  They will therefore want to rebalance their portfolios, for example by using the new deposits to buy higher-yielding assets such as bonds and shares issued by companies ‚Äî leading to the ‚Äòhot potato‚Äô effect discussed earlier.  This will raise the value of those assets and lower the cost to companies of raising funds in these markets.  That, in turn, should lead to higher spending in the economy.(1)  The way in which QE works therefore differs from two common misconceptions about central bank asset purchases:  that QE involves giving banks ‚Äòfree money‚Äô;  and that the key aim of QE is to increase bank lending by providing more reserves to the banking system, as might be described by the money multiplier theory.  This section explains the relationship between money and QE and dispels these misconceptions.  The link between QE and quantities of money QE has a direct effect on the quantities of both base and broad money because of the way in which the Bank carries out its asset purchases.  The policy aims to buy assets, government bonds, mainly from non-bank financial companies, such as pension funds or insurance companies.  Consider, for example, the purchase of ¬£1 billion of government bonds from a pension fund.  One way in which the Bank could carry out the purchase would be to print ¬£1 billion of banknotes and swap these directly with the pension fund.  But transacting in such large quantities of banknotes is impractical.  These sorts of transactions are therefore carried out using electronic forms of money.  As the pension fund does not hold a reserves account with the Bank of England, the commercial bank with whom they hold a bank account is used as an intermediary.  The pension fund‚Äôs bank credits the pension fund‚Äôs account with ¬£1 billion of deposits in exchange for the government bonds.  This is shown in the first panel of Figure 3.  The Bank of England finances its purchase by crediting reserves to the pension fund‚Äôs bank ‚Äî it gives the commercial bank an IOU (second row).  The commercial bank‚Äôs balance sheet expands:  new deposit liabilities are matched with an asset in the form of new reserves (third row).  Figure 3  Impact of QE on balance sheets(a)  Before asset purchase  After asset purchase  Pension fund  Assets  Liabilities  Assets  Liabilities  Government debt  Other  Deposits  Other  Central bank(b)  Assets  Liabilities  Assets  Liabilities  Government debt  Reserves  Other assets  Reserves  Other assets  Commercial bank  Assets  Liabilities  Assets  Liabilities  Reserves  Deposits Reserves  Deposits (a)  Balance sheets are highly stylised for ease of exposition:  quantities of assets and liabilities shown do not correspond to the quantities actually held by those sectors.  The figure only shows assets and liabilities relevant to the transaction.  (b)  Government debt is actually purchased by the Bank of England‚Äôs Asset Purchase Facility using a loan from the Bank of England, so does not actually appear directly on the Bank‚Äôs official consolidated balance sheet.  Two misconceptions about how QE works Why the extra reserves are not ‚Äòfree money‚Äô for banks While the central bank‚Äôs asset purchases involve ‚Äî and affect ‚Äî commercial banks‚Äô balance sheets, the primary role of those banks is as an intermediary to facilitate the transaction between the central bank and the pension fund.  The additional reserves shown in Figure 3 are simply a by-product of this transaction.  It is sometimes argued that, because they are assets held by commercial banks that earn interest, these reserves represent ‚Äòfree money‚Äô for banks.  While banks do earn interest on the newly created reserves, QE also creates an accompanying liability for the bank in the form of the pension fund‚Äôs deposit, which the bank will itself typically have to pay interest on.  In other words, QE leaves banks with both a new IOU from the central bank but also a new, equally sized IOU to consumers (in this case, the pension fund), and the interest rates on both of these depend on Bank Rate.  Why the extra reserves are not multiplied up into new loans and broad money As discussed earlier, the transmission mechanism of QE relies on the effects of the newly created broad ‚Äî rather than base ‚Äî money.  The start of that transmission is the creation of  (1)  The ways in which QE affects the economy are covered in more detail in Benford et al (2009), Joyce, Tong and Woods (2011) and Bowdler and Radia (2012).  The role of money more specifically is described in Bridges, Rossiter and Thomas (2011), Bridges and Thomas (2012) and Butt et al (2012).  Topical articles  Money creation in the modern economy  25  bank deposits on the asset holder‚Äôs balance sheet in the place of government debt (Figure 3, first row).  Importantly, the reserves created in the banking sector (Figure 3, third row) do not play a central role.  This is because, as explained earlier, banks cannot directly lend out reserves.  Reserves are an IOU from the central bank to commercial banks.  Those banks can use them to make payments to each other, but they cannot ‚Äòlend‚Äô them on to consumers in the economy, who do not hold reserves accounts.  When banks make additional loans they are matched by extra deposits ‚Äî the amount of reserves does not change.  Moreover, the new reserves are not mechanically multiplied up into new loans and new deposits as predicted by the money multiplier theory.  QE boosts broad money without directly leading to, or requiring, an increase in lending.  While the first leg of the money multiplier theory does hold during QE ‚Äî the monetary stance mechanically determines the quantity of reserves ‚Äî the newly created reserves do not, by themselves, meaningfully change the incentives for the banks to create new broad money by lending.  It is possible that QE might indirectly affect the incentives facing banks to make new loans, for example by reducing their funding costs, or by increasing the quantity of credit by boosting activity.(1)  But equally, QE could lead to companies repaying bank credit, if they were to issue more bonds or equity and use those funds  to repay bank loans.  On balance, it is therefore possible for QE to increase or to reduce the amount of bank lending in the economy.  However these channels were not expected to be key parts of its transmission:  instead, QE works by circumventing the banking sector, aiming to increase private sector spending directly.(2)  Conclusion  This article has discussed how money is created in the modern economy.  Most of the money in circulation is created, not by the printing presses of the Bank of England, but by the commercial banks themselves:  banks create money whenever they lend to someone in the economy or buy an asset from consumers.  And in contrast to descriptions found in some textbooks, the Bank of England does not directly control the quantity of either base or broad money.  The Bank of England is nevertheless still able to influence the amount of money in the economy.  It does so in normal times by setting monetary policy ‚Äî through the interest rate that it pays on reserves held by commercial banks with the Bank of England.  More recently, though, with Bank Rate constrained by the effective lower bound, the Bank of England‚Äôs asset purchase programme has sought to raise the quantity of broad money in circulation. This in turn affects the prices and quantities of a range of assets in the economy, including money.  (1)  A similar mechanism whereby QE could increase bank lending by enabling banks to  attract more stable funding is discussed in Miles (2012).  (2)  These channels, along with the effect of QE on bank lending more broadly, are  discussed in detail in a box in Butt et al (2012).  26  Quarterly Bulletin  2014 Q1  References  Astley, M and Haldane, A (1995), ‚ÄòMoney as an indicator‚Äô, Bank of England Working Paper No. 35.  Bank of England (1999), ‚ÄòThe transmission mechanism of monetary policy‚Äô, available at www.bankofengland.co.uk/publications/ Documents/other/monetary/montrans.pdf.  Benes, J and Kumhof, M (2012), ‚ÄòThe Chicago Plan revisited‚Äô, IMF Working Paper No. 12/202.  Benford, J, Berry, S, Nikolov, K, Robson, M and Young, C (2009), ‚ÄòQuantitative easing‚Äô, Bank of England Quarterly Bulletin, Vol. 49, No. 2, pages 90‚Äì100.  Bernanke, B (2007), ‚ÄòThe financial accelerator and the credit channel‚Äô, speech at a conference on The Credit Channel of Monetary Policy in the Twenty-first Century, Federal Reserve Bank of Atlanta.  Bindseil, U (2004), ‚ÄòThe operational target of monetary policy and the rise and fall of the reserve position doctrine‚Äô, ECB Working Paper No. 372.  Bowdler, C and Radia, A (2012), ‚ÄòUnconventional monetary policy: the assessment‚Äô, Oxford Review of Economic Policy, Vol. 28, No. 4, pages 603‚Äì21.  Clews, R, Salmon, C and Weeken, O (2010), ‚ÄòThe Bank‚Äôs money market framework‚Äô, Bank of England Quarterly Bulletin, Vol. 50, No. 4, pages 292‚Äì301.  Congdon, T (1992), Reflections on monetarism, Clarendon Press.  Congdon, T (2005), ‚ÄòMoney and asset prices in boom and bust‚Äô, Institute of Economic Affairs, Hobart Paper No. 152.  Disyatat, P (2008), ‚ÄòMonetary policy implementation: misconceptions and their consequences‚Äô, BIS Working Paper No. 269.  Farag, M, Harland, D and Nixon, D (2013), ‚ÄòBank capital and liquidity‚Äô, Bank of England Quarterly Bulletin, Vol. 53, No. 3, pages 201‚Äì15.  Friedman, M (1963), Inflation:  causes and consequences, Asia Publishing House.  Haldane, A (2009), ‚ÄòWhy banks failed the stress test‚Äô, available at www.bankofengland.co.uk/archive/documents/historicpubs/ speeches/2009/speech374.pdf.  Hancock, M (2005), ‚ÄòDivisia money‚Äô, Bank of England Quarterly Bulletin, Spring, pages 39‚Äì46.  Bridges, J, Rossiter, N and Thomas, R (2011), ‚ÄòUnderstanding the recent weakness in broad money growth‚Äô, Bank of England Quarterly Bulletin, Vol. 51, No. 1, pages 22‚Äì35.  Hills, S, Thomas, R and Dimsdale, N (2010), ‚ÄòThe UK recession in context ‚Äî what do three centuries of data tell us?‚Äô, Bank of England Quarterly Bulletin, Vol. 50, No. 4, pages 277‚Äì91.  Bridges, J and Thomas, R (2012), ‚ÄòThe impact of QE on the UK economy ‚Äî some supportive monetarist arithmetic‚Äô, Bank of England Working Paper No. 442.  Brigden, A and Mizen, P (2004), ‚ÄòMoney, credit and investment in the UK industrial and commercial companies sector‚Äô, The Manchester School, Vol. 72, No. 1, pages 72‚Äì79.  Burgess, S and Janssen, N (2007), ‚ÄòProposals to modify the measurement of broad money in the United Kingdom:  a user consultation‚Äô, Bank of England Quarterly Bulletin, Vol. 47, No. 3, pages 402‚Äì14.  Butt, N, Domit, S, Kirkham, L, McLeay, M and Thomas, R (2012), ‚ÄòWhat can the money data tell us about the impact of QE?‚Äô, Bank of England Quarterly Bulletin, Vol. 52, No. 4, pages 321‚Äì31.  Button, R, Pezzini, S and Rossiter, N (2010), ‚ÄòUnderstanding the price of new lending to households‚Äô, Bank of England Quarterly Bulletin, Vol. 50, No. 3, pages 172‚Äì82.  Capie, F and Webber, A (1985), A monetary history of the United Kingdom, 1870‚Äì1982, Vol. 1, Routledge.  Carpenter, S and Demiralp, S (2012), ‚ÄòMoney, reserves, and the transmission of monetary policy:  does the money multiplier exist?‚Äô, Journal of Macroeconomics, Vol. 34, No. 1, pages 59‚Äì75.  Howells, P (1995), ‚ÄòThe demand for endogenous money‚Äô, Journal of Post Keynesian Economics, Vol. 18, No. 1, pages 89‚Äì106.  Jackson, C and Sim, M (2013), ‚ÄòRecent developments in the sterling overnight money market‚Äô, Bank of England Quarterly Bulletin, Vol. 53, No. 3, pages 223‚Äì32.  Joyce, M, Tong, M and Woods, R (2011), ‚ÄòThe United Kingdom‚Äôs quantitative easing policy:  design, operation and impact‚Äô, Bank of England Quarterly Bulletin, Vol. 51, No. 3, pages 200‚Äì12.  Kaldor, N and Trevithick, J (1981), ‚ÄòA Keynesian perspective on money‚Äô, Lloyds Bank Review, January, pages 1‚Äì19.  Kamath, K, Reinold, K, Nielsen, M and Radia, A (2011), ‚ÄòThe financial position of British households:  evidence from the 2011 NMG Consulting survey‚Äô, Bank of England Quarterly Bulletin, Vol. 51, No. 4, pages 305‚Äì18.  Kydland, F and Prescott, E (1990), ‚ÄòBusiness cycles:  real facts and a monetary myth‚Äô, Federal Reserve Bank of Minneapolis Quarterly Review, Vol. 14, No. 2, pages 3‚Äì18.  Laidler, D (1984), ‚ÄòThe buffer stock notion in monetary economics‚Äô, The Economic Journal, Vol. 94, Supplement:  Conference Papers, pages 17‚Äì34.  Topical articles  Money creation in the modern economy  27  Laidler, D and Robson, W (1995), ‚ÄòEndogenous buffer-stock money‚Äô, Credit, interest rate spreads and the monetary policy transmission mechanism, Session 3, conference on The Transmission of Monetary Policy held at the Bank of Canada in November 1994.  Miles, D (2012), ‚ÄòAsset prices, saving and the wider effects of monetary policy‚Äô, available at www.bankofengland.co.uk/ publications/Documents/speeches/2012/speech549.pdf.  Mitchell, B R (1988), British historical statistics, Cambridge University Press.  Moore, B (1988), Horizontalists and verticalists:  the macroeconomics of credit money, Cambridge University Press.  Palley, T (1996), Post Keynesian economics:  debt, distribution and the macro economy, Macmillan.  Sefton, J and Weale, M (1995), Reconciliation of National Income and Expenditure:  balanced estimates of national income for the United Kingdom, 1920‚Äì1990, Cambridge University Press.  Singh, M (2013), ‚ÄòCollateral and monetary policy‚Äô, IMF Working Paper No. 13/186.  Solomou, S N and Weale, M (1991), ‚ÄòBalanced estimates of UK GDP 1870‚Äì1913‚Äô, Explorations in Economic History, Vol. 28, No. 1, pages 54‚Äì63.  Thomas, R (1997a), ‚ÄòThe demand for M4:  a sectoral analysis, Part 1 ‚Äî the personal sector‚Äô, Bank of England Working Paper No. 61.  Thomas, R (1997b), ‚ÄòThe demand for M4:  a sectoral analysis, Part 2 ‚Äî the corporate sector‚Äô, Bank of England Working Paper No. 62.  Tobin, J (1963), ‚ÄòCommercial banks as creators of ‚Äòmoney‚Äô‚Äô, Cowles Foundation Discussion Papers No. 159.  Tucker, P (2009), ‚ÄòThe debate on financial system resilience: macroprudential instruments‚Äô, available at www.bankofengland.co.uk/archive/Documents/historicpubs/ speeches/2009/speech407.pdf.  Tucker, P, Hall, S and Pattani, A (2013), ‚ÄòMacroprudential policy at the Bank of England‚Äô, Bank of England Quarterly Bulletin, Vol. 53, No. 3, pages 192‚Äì200.  "
https://news.ycombinator.com/rss,"‚ÄòExcuuuuse me, Princess ‚Äô: An oral history of The Legend of Zelda cartoon",https://www.polygon.com/zelda/23540526/legend-of-zelda-cartoon-oral-history-zeldathon,Comments,"

Share this story




Share this on Facebook





Share this on Twitter








Share
All sharing options






Share
All sharing options for:
‚ÄòExcuuuuse me, Princess!‚Äô: An oral history of The Legend of Zelda cartoon












Reddit







Pocket









Flipboard





Email









This story is part of a group of stories called 





    In 2023, Polygon is embarking on a Zeldathon. Join us on our journey through The Legend of Zelda series, from the original 1986 game to the release of The Legend of Zelda: Tears of the Kingdom, and beyond.
  


The world knows The Legend of Zelda‚Äôs Link as the brave hero of Hyrule ‚Äî a young warrior of few words. Link is a master with his bow and an excellent swordsman. But back in 1989, when The Legend of Zelda cartoon first aired, all Link wanted was a smooch. A kiss from Zelda, to be exact ‚Äî but he‚Äôs not exactly picky, and unlike the laconic hero of the games, he would not shut up about it. The hero of Hyrule is still tasked with defending the Triforce of Wisdom from Ganon‚Äôs grasp on the TV show, but that‚Äôs secondary to his insistence on a little kiss. The show‚Äôs bizarre portrayal of Link ‚Äî especially his constant begging of ‚ÄúExcuse me, Princess!‚Äù ‚Äî has made The Legend of Zelda cartoon a hilarious head-scratcher to this day. 




In 2023, Polygon is embarking on a Zeldathon. Join us on our journey through The Legend of Zelda series, from the original 1986 game to the release of The Legend of Zelda: Tears of the Kingdom, and beyond.



Back in 1989, The Legend of Zelda aired in 15-minute episodes every Friday during The Super Mario Bros. Super Show!, a mix of live-action and animated segments based on Nintendo games. Once a week, The Legend of Zelda replaced the Super Mario Bros. show, which featured animated segments of Mario and Luigi but, more memorably, the wacky, iconic live-action performances of WWF wrestler Lou Albano as Mario and The Jeffersons‚Äô Danny Wells as Luigi, who welcomed fans of the show with the catchphrase, ‚ÄúHey there, paisanos.‚Äù
Clearly, Super Mario Bros. was the main event for the Nintendo-themed TV block. It ran for 52 episodes compared to The Legend of Zelda‚Äôs 13. But for the writers of the Zelda cartoon, that was a boon: They had very little oversight and direction beyond character designs, a franchise ‚Äúbible‚Äù provided by Nintendo, and the original game, also called The Legend of Zelda, and its sequel, Zelda 2: The Adventure of Link. As they were not video game players themselves, the writers did their research and decided to go in a different direction ‚Äî one that‚Äôs more focused on story than gameplay. There were elements of the games, like sound effects and visuals, but the show mostly has Zelda and Link posted up in Hyrule castle defending the Triforce of Wisdom from Ganon while trying to acquire the Triforce of Power from the evil wizard himself. (The Triforces talk, by the way.)
Between the mischief that Zelda, Link, and fairy friend Spryte get into, The Legend of Zelda relied heavily on the relationship between Zelda and Link. Zelda, donning pink pants and purple thigh-high boots, more often plays the hero to Link‚Äôs bumbling teenage angst.
What we get from the short-lived ordeal is a charming and absurd rendition of a beloved (and often quiet and unvoiced) franchise.
 









Image: DiC Entertainment/Nintendo



From pixels to the small screen
Most of the Super Mario Bros. Super Show‚Äôs budget was tied up in the main part of the show ‚Äî the Super Mario Bros. show that led the time slot. When Super Mario. Bros Super Show was canceled, The Legend of Zelda was shut down alongside it. But for the show‚Äôs short run, writers said they had little interference from Nintendo, which just wanted more eyes on its game properties ‚Äî especially a new one like The Legend of Zelda. It was the first time ‚Äî and still one of the rare times ‚Äî that Link and Zelda got their own voice actor performances, and probably not the ones fans expected. 
Rather than simply recreating the video game, The Legend of Zelda‚Äôs writers positioned the show more as a mix of action, comedy, and drama, taking specific inspiration from Cybill Shepherd‚Äôs and Bruce Willis‚Äô ‚Äô80s show Moonlighting. Writers wanted Zelda and Link‚Äôs relationship to mirror Shepherd‚Äôs and Willis‚Äô rapport as Maddie and David on the detective show ‚Äî the same angry sexual tension, but goofier and lighter for the kid-friendly cartoon TV show. 
 











Bob Forward Story editor and writer, The Legend of Zelda
The Legend of Zelda was going to be a small addendum to the Super Mario Bros. Super Show, which was the actual star of the time slot. DiC needed somebody who could handle it on their own without a lot of supervision. After we had the initial discussion, they supplied me with a VHS tape of [a playthrough of] the game itself, since I wasn‚Äôt actually a person who played video games ‚Äî not that I had any objection. I just hadn‚Äôt really done it. They had a playthrough of the game that my sons were fascinated by. That was my research for it.
I don‚Äôt know if anyone cares about this, but the playthrough VHS tape that they supplied me with I guess had been played by one of the new Charlie‚Äôs Angels. I think it was Tonya Roberts. I guess she was a gamer when she was younger.

 









Image: DiC Entertainment/Nintendo



 











Reed Shelly Story editor and writer, Super Mario Bros. Super Show
The project originated as a concept by Andy Heyward as Super Mario Bros. Power Hour, a one hour-long animation block that would have featured series based on a number of intellectual properties. Concept art was produced for adaptations of Super Mario Bros., The Legend of Zelda, Metroid, Castlevania, Double Dragon, and California Games. With the exception of Mario and Zelda, none of these additional adaptations were ultimately produced.

 











John Grusd Director, The Legend of Zelda
Nintendo wanted us to base the show on the new game [Zelda 2: The Adventure of Link], because, you know, it‚Äôs great marketing. What they did was give me the Japanese version of the game, because it wasn‚Äôt out here yet. I didn‚Äôt know anything about the game when I started. I‚Äôd never played them. I wasn‚Äôt a gamer or anything. That‚Äôs how I learned how the characters move, the sound effects, the music. I got to be able to do the games all the way through pretty quickly, as a matter of fact, because I knew all the shortcuts. I could get through both of them in less than two minutes, probably. It‚Äôs pretty fast.

 











Phil Harnage Writer, The Legend of Zelda
It was a fun little show. And I say little, because they tacked it on to Super Mario. It really should have been a stand-alone show. It was very limiting for what the writers could do. I worked on the bible and wrote a couple of episodes. When you write the bible, you hand it off to somebody else, but occasionally you get to write a script. That‚Äôs the fun part. It was a fun show to write for because of the tension between Link and the princess. We modeled it after Moonlighting. We tried to capture that, and I think we did. Maybe over the top a little bit, but that‚Äôs what we were shooting for. We could have come up with a lot more shows. That was the sad part, that we only got to do one season. 


 









Image: Eve Forward



 











Eve Forward Writer, The Legend of Zelda
My brother somehow ended up suggesting I try writing an episode, and I was able to turn out a couple of scripts that, with his editing, ended up getting used. I was about 16-17 at the time. The only direction I had was the show bible, which outlined the basic characters and sorts of stories they were looking for. I didn‚Äôt have a Nintendo, so I rented one, and the game, and tried to play it, but I didn‚Äôt get very far. But the basic relationships were all established in the show bible; Ganon bad guy, Zelda tough girl, Link charming scamp, Triforce MacGuffin, etc.
I did play Dungeons & Dragons though, at the time, and some of that feel made it into the show. [The seventh episode] ‚ÄúDoppelganger‚Äù was based on a cursed mirror in D&D. Well, the monsters in Zelda were all based on things from the Nintendo game; same with the weapons, like Link‚Äôs boomerang. But in D&D of course you‚Äôre always fighting monsters and imagining how cool your character looks doing it, so a lot of the various swashbuckling stuff I liked to put in was based on things that had happened in our D&D games. I always thought of Link as more of a rogue than a fighter.

 











Bob Forward
We had a schedule we had to put the scripts through, and I think it was two a week. That wasn‚Äôt hard ‚Äî I worked on shows we had to do five a week, so two a week was just fine. Eve and I were just writing them on our own. We even had my mom pitch a story. She wrote something that we ended up having to do a lot of work on, but it wasn‚Äôt a bad initial concept. [Bob and Eve‚Äôs mom, Marsha Forward, had her script adapted as The Legend of Zelda‚Äôs 11th episode, ‚ÄúFairies in the Spring.‚Äù]
I wrote a bible for my own purposes, something that just outlined who all the characters were and what they wanted. Robby London [DiC executive] wanted to have some signature lines, and Moonlighting had just come out, or was very popular. Robby London came up with the idea of the line, ‚ÄúExcuuuuse me, Princess,‚Äù which is inspired by the Moonlighting relationship and a snarky line from a Steve Martin routine. I‚Äôll be honest, what I liked about Robby is that he would make quick decisions. As much as I was giving him a hard time about it, I put [that line] into the show way more than it was really necessary. But it turned out to be OK, even though people made fun of it. People remembered it, so I guess he was right. I have to admit, it caught on.

 









Image: DiC Entertainment/Nintendo




No one had ever heard Link or Zelda speak
People were certainly familiar with Link and Zelda by the time The Legend of Zelda cartoon was released ‚Äî The Legend of Zelda and Zelda 2: The Adventure of Link had been out for some time and already were popular. But characters were composed of just a few dozen pixels, and they weren‚Äôt voiced. It gave the TV writers lots of room to mess around; the show existed outside of the games, with Link just hanging around Zelda and her father‚Äôs castle, defending the Triforce from Ganon every once in a while. 
The show had to be largely carried by Link and Zelda‚Äôs personalities, plus the few other characters who appeared: Spryte, a fairy, and the two talking Triforce pieces (Wisdom and Power). So, the writers made those few characters big. Ganon is merely an annoyance to Link, whose more pressing problem is convincing Zelda to give him a kiss.
 











Bob Forward
We very much made it up as we went along. The other nice thing was that everybody was so concentrated on the Mario brothers that they completely left us alone, which is always my favorite way of working. You know, as long as we hit the page count and got the scripts in on time, nobody was looking. 
Link always wanted a kiss. That was one of Robby‚Äôs inventions. I thought it worked out. I was down for it. I kept expecting people to tell us we couldn‚Äôt do it. But apparently it worked.

 











Jonathan Potts Voice actor, Link
I pictured Link as being a teenager who was like the ultimate teenage boy, who was like a puppy. If you can imagine what a puppy would be [like] ‚Äî running around, peeing on the carpet, and overreacting ‚Äî everything was dramatic. I remember wanting to do that. I wasn‚Äôt a teenager then; I was well into my 20s when I did the part. I had to be that youthful, goofy teenage boy who acts before he thinks.

 











Cynthia Preston Voice actor, Zelda
You start reading something and you just have instincts ‚Äî all of your experience, and all of the movies you‚Äôve done, and all of the classes you‚Äôve taken, and that feeds into how to start molding a character. What does this character want? What do they want from this character? I don‚Äôt think I was playing Zelda as a teenager. She was an independent woman ‚Äî a young woman, but she was independent. She didn‚Äôt need a hero to save her, and that was so cool.
The show certainly wasn‚Äôt ahead of its time, but nonetheless it was a cool aspect that it wasn‚Äôt playing a damsel in distress.

 











Phil Harnage
We didn‚Äôt want a Disney princess. We‚Äôre not going to be selling princess dresses to six-year-olds. So yeah, she was an action hero in her own right, and that was kind of unique. But the writers didn‚Äôt come up with [Zelda wearing pants] ‚Äî that was something the artists came up with, and Nintendo loved it.
It was ahead of its time in some ways, but wasn‚Äôt always. Zelda was a good role model for girls. She was confident and took charge. She did want what she wanted, but was also very responsible. And Link was irresponsible. He was out there conniving: ‚ÄúHow am I gonna get her to kiss me?‚Äù There‚Äôs fun in that. That‚Äôs where the Moonlighting model really worked.

 











Jonathan Potts
The scripts weren‚Äôt complex. There weren‚Äôt a lot of deep things going on. It was all right there, sort of obvious. So [direction] usually came down to technical things ‚Äî more energy. 

 











Cynthia Preston
There was this time a director wanted me to laugh more as Zelda. I was trying, but laughing is harder than crying to do naturally. Shockingly, he mooned me and I fell over laughing. I really have the feeling I didn‚Äôt get the right laugh, but it was damn funny.

 









Image: DiC Entertainment/Nintendo



A talking Triforce?
Writers said Nintendo didn‚Äôt want them coming up with new characters and backstories, so they worked with what they had. That‚Äôs where the Triforce pieces came in ‚Äî the show couldn‚Äôt only be Zelda, Link, Ganon, and Spryte. There was the Triforce. Why not make it talk? Successful or not, the Wisdom piece of the Triforce did have a role in the show: Moving the story forward and explaining the situation.
 











Bob Forward
Link and Zelda wanted the Triforce of Power, and Ganon wanted the Triforce of Wisdom, so [in] half the shows Link and Zelda would be the ones to instigate the action as opposed to just hanging around and waiting for Ganon to start something and trying to reestablish the status quo.

 











Phil Harnage
The whole Triforce thing, it came out of the game and everything, but I don‚Äôt know ‚Äî it was hard to figure out. What does that mean? The Triforce? What do you have to do with it to make it work? I wasn‚Äôt really happy with that. I thought it would be much more fun to have them fighting over who‚Äôs going to control the land. But [the Triforce] was from the game, and you had to do it for the gamers. 
The more things talk, the more explanatory it can be. You‚Äôre like, Why did this happen? And the Triforce can tell you, you know? It‚Äôs magic. In a magical world, you have to set the rules, of course. But you set the rules yourself.

 









Image: DiC Entertainment/Nintendo



A sword fighter in a show without fighting
For a TV show about a game with a hero who hits things with swords, The Legend of Zelda has surprisingly little sword fighting. The Legend of Zelda was a kids‚Äô TV show, and that meant it had to  follow the network‚Äôs standards ‚Äî so characters couldn‚Äôt die. Link and Zelda still have weapons, of course, but they don‚Äôt seem deadly. Link‚Äôs sword shoots out magic bullets that stun enemies, and Zelda often uses a magic bow that uses magic instead of arrows.
 











John Grusd
Link has a sword, but can he actually use it to chop somebody‚Äôs head off? He can‚Äôt do what he does in the game. Nintendo wants us to do what they do in the game, but the standards and practices at the network say no. We can‚Äôt kill someone on children‚Äôs TV.

 











Phil Harnage
Magic brings a whole different ambiance to a cartoon, because it‚Äôs something you can do that‚Äôs not repeatable by kids. You can shoot a lightning bolt and turn someone into toast. And the toast gets up and walks away. You just have to be careful ‚Äî you can‚Äôt do everything you want to do. You can‚Äôt do anything that could be copied by a child. You don‚Äôt want kids sword fighting.

 











Bob Forward
Link‚Äôs sword could fire like a ranged weapon. Actually hitting people with swords was questionable. It wasn‚Äôt something they wanted to do back then. It was easier to just shoot zaps from the sword. We also had to establish that nobody was dying, so there was the jar of evil or something, where everyone hit by zaps were sent to and got put into storage for a while. We had to downplay a lot of things.

 









Image: DiC Entertainment/Nintendo



One and done
While Super Mario Bros. Super Show had tons of episodes, The Legend of Zelda has only one season. That‚Äôs the way of TV cartoons ‚Äî things get canceled and people move on. The Legend of Zelda itself has gone on to be one of Nintendo‚Äôs most successful properties, but the TV show is still a small part of that legacy.
 











Reed Shelly
The show feels like a time capsule to me. It‚Äôs such a different world now and so different for kids. The shows were made for a different era.
It was an incredible creative playground. We had to deliver 52 episodes at a rate of four a week [for the Super Mario. Bros Super Show]. We had live action, animation, and an action sequence set to a well known song. It was an amazing production circus to be a part of.
With Andy Heyward and Haim Saban executive producing and running the shows, we were allowed to have a ton of fun. All we had to do was make millions of kids laugh.

 











Eve Forward
I‚Äôve no idea what the reception to the show was. This was in the days before internet; you couldn‚Äôt just log in and see your work torn apart in real time. My own feeling is that the Super Mario Bros. show wasn‚Äôt very good, especially the live-action bits, and that Zelda was the best part of it, but y‚Äôknow, it was a cartoon, for kids. We weren‚Äôt trying to make Citizen Kane or something. But of course it was a huge thrill for me to see my work on television!

 











Phil Harnage
Part of the reason [the show was canceled] is that it wasn‚Äôt its own show ‚Äî it was part of the Mario Bros. show. It was tied to it, and they didn‚Äôt want to renew The Mario Bros., and Zelda got shuffled off. History, at that point. I wish I had done more. We could have come up with a lot more shows. That was the sad part, that we only got to do one season.
I think the show holds up pretty well after all these years. They‚Äôre all on YouTube. [Ed. note: And Amazon Prime Video!] I don‚Äôt know if you know this, but we don‚Äôt get residuals.
Everybody wishes that Link and Zelda had gone on to bigger and better things [with the TV show], but they didn‚Äôt. You have these regrets about every show you do. Sometimes you wish you could have done more, that you could do more, but there were certain things you had to do to please the network.
We got a lot of good feedback from kids, and even older kids who knew the video game. They would watch the show out of curiosity and get sucked in. We had a few letters saying, ‚ÄúOh, please don‚Äôt cancel it!‚Äù But getting a few letters isn‚Äôt enough to convince the network. They‚Äôre the boss, because they funded the things. DiC, the studio I worked for at the time ‚Äî they were known for finding the current properties they could exploit. They were purely in the business to make money, like all the studios.

 











Jonathan Potts
I‚Äôm always surprised at how much notoriety it has. I don‚Äôt think it was a hit at the time, because then we would have done more. We did it years ago, and it was one season with 13 episodes. It was a one-and-done sort of thing. It had its time, and it just keeps growing. I get letters from all over the world. 
I was teaching voice classes at Second City, and the class would be people in their 30s, and the engineer would look at me like, Go ahead, tell them. And I‚Äôd say, ‚ÄúYou know, I was the voice of Link in The Legend of Zelda,‚Äù and inevitably, three or four people would be like‚Ä¶ I became a celebrity. I can‚Äôt believe that. It was just a gig years ago.
They would be so starstruck, which is a joke, because I‚Äôm not a star. But they‚Äôd get ‚Ä¶ [imitates expression of amazement]

 











Cynthia Preston
It came up [at a party] that I was the voice of Zelda in the cartoon, and [people] were so stunned. They rolled up their shirt sleeves, and they both have the Triforce tattooed on their arms. I‚Äôve been at pitch sessions and somebody will find out that I‚Äôm the voice of Zelda, and the reaction is astounding. People love it so much. 

 











Reed Shelly
I remember on my first trip to Redmond and the Nintendo headquarters, they had a couple of hundred ‚Äúgame counselors‚Äù in a call center at computers giving tips to gamers calling in. It cost, as I remember, something like 99 cents a minute for players to get game tips. When a group got to go on their lunch break, they raced each other to play the newest arcade console game in the cafeteria. I remember thinking, ‚ÄúThis computer gaming thing is gonna be big...‚Äù 




"
https://news.ycombinator.com/rss,Twitter API Page,https://developer.twitter.com/apitools,Comments,"




Twitter / Error















This page is down
I scream. You scream. We all scream... for us to fix this page. We‚Äôll stop making jokes and get things up and running soon.
Retry




Home
Status
Terms of Service
Privacy Policy
Cookie Policy
Imprint
Ads info
¬© Twitter ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ






"
https://news.ycombinator.com/rss,1991: A server-side web framework written in Forth,https://www.1-9-9-1.com/,Comments,"


World Wild Web

                        The year is 1991. The World Wide Web has just seen public release. 1991 looks to ease your interactions with the new web using cutting edge programming techniques in Forth (well, Gforth).
                    


Logging In

                        Getting started in 1991 is easy.
                    

                        All you need to do is include 1991.fs into your Forth source file. Next, you can define your public routes using the /1991 word. Once your routes are all layed out, start the server using 1991:.
                    

\ app.fs
\ Load 1991.
include 1991.fs

\ Define our route handlers.
: handle-/ ( -- addr u )
    \ Any string returned by the handler
    \ will be output to the browser.
    s"" Hello, 1991."" ;

\ Set up our routes.
/1991 / handle-/

\ Start the server on port 8080.
8080 1991:

You can run the server using gforth app.fs.
Logging In II: Logging In, Deeper
Route Wildcards (Fuzzy Routing / URL Mapping)

                        If you want to specify that some part of a route is a wildcard (accepts any value), then you can wrap some named value in <chevrons>. 1991 will accept any URL that matches your wildcard pattern, setting the internal value of whatever you place between the chevrons to whatever is actually requested.
                    

                        In the example below, <uid> specifies that we're willing to accept any (non-empty) value in its place which we'd like to access using the name uid.
                    

\ wildcards.fs
\ Load 1991.
include 1991.fs

\ Define our route handler.
: handle-wildcard-route ( -- addr u )
    s"" contents of the route request: "" get-query-string s+ ;

\ Set up our route.
/1991 /users/<uid> handle-wildcard-route

\ We can set up multiple wildcards too (must be slash-separated).
/1991 /users/<uid>/posts/<pid> handle-wildcard-route

\ Start server on port 8080.
8080 1991:


                         All wildcards are treated similar to query string arguments. As such, wildcards can be retrieved using get-query-string.
                    

                        In the example above, visiting http://localhost:8080/users/urlysses will result in the following query string: uid=urlysses.
                    File Serving

                        Use a public/ directory to act as a basic fileserver.
                        Whenever a requested URL doesn't resolve through the registered routes, 1991 will attempt to find the requested route within your specified public directory.
                    

\ public.fs
\ Load 1991.
include 1991.fs

\ Specify the location of our public directory.
\ Anything in the public/ directory within the
\ same dir as this source file will resolve.
\ You can change ""public"" to anything you want
\ as long as it matches your directory name.
sourcedir s"" public"" s+ set-public-path

\ We can set mimetypes using the `filetype:` word.
\ In the case below, we want .mp4 files to be served
\ with the content-type video/mp4.
s"" video/mp4"" filetype: mp4

\ Start the server on port 8080.
8080 1991:


                        In the above example, If we have a file public/my-video.mp4, then it will be available through http://localhost:8080/my-video.mp4.
                    
Views

1991 offers basic templating through views.
                    

                        In order to get started, you should specify the views/ path. Notice the trailing slash, which differs from how we define public.
                    

                        Once you've specified your views/ directory, you can write views/ files to it. This can be any kind of file, honestly. The benefit offered by views/ is the ability to use basic templating. You can write any valid Forth code within opening (<$ ) and closing ( $>) tags. Additionally, you can use the import word to import other views into your view.
                    

\ views.fs
\ Load 1991.
include 1991.fs

\ Specify the location of our views directory.
sourcedir s"" views/"" s+ set-view-path

\ Define some words we'll use within
\ our view.
: page-title ( -- addr u )
    s"" Dynamic page title"" ;
: ten-lines ( -- )
    10 0 do
        s"" line "" i s>d <# #s #> s+
        s"" <br>"" s+
        $type
    loop ;

\ Use render-view to output the contents
\ of a file in the views/ directory.
: handle-/
    s"" v-index.html"" render-view ;

/1991 / handle-/

\ Start the server on port 8080.
8080 1991:


\ views/index.html
<!DOCTYPE html>
<html>
    <head>
        <meta charset=""utf-8"">
        <title><$ page-title $type $></title>
    </head>
    <body>
        <$ ten-lines $>
        <$ s"" imported-view.html"" import $>
    </body>
</html>


\ views/imported-view.html
It's possible to import view files from within other view files. This is from <code>views/imported-view.html</code>



Wait, what?
Why is 1991: post-fix when /1991 is pre-fix?

                        Forth is a (mostly) post-fix notation language. So, for example, you'd write two plus two as 2 2 +. This is the language's natural and immediate notation. Along those lines, 1991: is an immediate word‚Äî‚Äîrunning it results in immediate action. As such, we use Forth's post-fix notation to set the port and start the server immediately. Alternately, /1991 doesn't exactly have immediate effect per se. All it does is tell 1991 that any request to /path should be handled by path-handler. As such, we opt to write non-immediate code using pre-fix notation.
                    
You're using Gforth, which came out in 1992. Also, it's 2017.
Okay. But Fredric Jameson establishes that in postmodernism we have experienced a weakening sense of historisity such that what is, what was, and what will be all exist as presents in time. 1970, 1991, 1992, and 2017 all happen simultaneously. Hence developers working on new projects while still coding in decades-old text editors. They write the future in the past and are made present in so doing.


"
https://news.ycombinator.com/rss,NASA‚Äôs Double Asteroid Redirection Test Is a Smashing Success,https://eos.org/articles/nasas-double-asteroid-redirection-test-is-a-smashing-success,Comments,"

Posted inNews 
			NASA‚Äôs Double Asteroid Redirection Test Is a Smashing Success		

			The mission, focused on the Didymos-Dimorphos binary asteroid system, proved that an asteroid‚Äôs orbit can be altered by kinetic impactor technology.		




by
Katherine Kornei 
12 January 202312 January 2023 
Share this:Print 



 This illustration of NASA‚Äôs Double Asteroid Redirection Test (DART) spacecraft and the Italian Space Agency‚Äôs LICIACube depicts them just prior to impact at the Didymos binary system on 26 September 2022. Credit: NASA/Johns Hopkins APL/Steve Gribben





Rocks from space have walloped Earth for eons, and it‚Äôs only a matter of time until our planet lands yet again in the crosshairs of a very large asteroid. But unlike other forms of life‚Äîhere‚Äôs looking at you, dinosaurs‚Äîhumans have a fighting chance of altering our cosmic destiny. At AGU‚Äôs Fall Meeting 2022 held in December, researchers presented a slate of new results from NASA‚Äôs Double Asteroid Redirection Test (DART) mission, the first demonstration of asteroid deflection.
Peering at an Orbit
DART‚Äôs target, the Didymos-Dimorphos asteroid system, was first discovered in the mid-1990s. But astronomers back then spotted only its larger member, Didymos, which is roughly 800 meters (half a mile) in diameter. It wasn‚Äôt until 2003 that scientists realized that a much smaller body, dubbed Dimorphos, was also present. Dimorphos is about one fifth the size of Didymos, and its orbit takes it in front of and behind Didymos as seen from Earth. That‚Äôs serendipitous, because by monitoring how the brightness of the Didymos-Dimorphos asteroid system varies over time, scientists were able to precisely determine how long it took Dimorphos to complete an orbit: 11 hours and 55 minutes.
‚ÄúWe needed to understand the Didymos-Dimorphos system before we changed it.‚Äù
‚ÄúWe needed to understand the Didymos-Dimorphos system before we changed it,‚Äù said Cristina Thomas, a planetary scientist at Northern Arizona University in Flagstaff, at AGU‚Äôs Fall Meeting 2022.
 



This newsletter rocks.
Get the most fascinating science news stories of the week in your inbox every Friday.

Sign up now



The primary goals of the DART mission were simple, at least in concept: Hit Dimorphos with the roughly 570-kilogram (half-ton) DART spacecraft to alter the orbital period of Dimorphos around Didymos significantly and measure that change and characterize the physics of the impact. If successful, it would be the first demonstration of deflecting an asteroid using so-called kinetic impactor technology. (In 2005, another NASA mission, Deep Impact, tested kinetic impactor technology with a comet.)
On 23 November 2021, a Falcon 9 rocket lifted off from California‚Äôs Vandenberg Space Force Base. By then, the SpaceX-designed rocket had notched more than 100 successful launches, but for members of the DART mission, the event was anything but ordinary: Nestled within the rocket‚Äôs nose cone was the spacecraft they‚Äôd spent well over a decade designing, building, and testing.
The launch went smoothly, and DART soon entered into orbit around the Sun. For roughly 10 months, the spacecraft largely tracked the orbit of Earth, essentially waiting to catch up to the Didymos-Dimorphos asteroid system, which orbits the Sun between Earth and Mars. ‚ÄúWe stayed close to Earth the entire time and just caught up with the Didymos system at its closest approach to Earth,‚Äù said Elena Adams, DART mission systems engineer at the Johns Hopkins University Applied Physics Laboratory in Laurel, Md.
Approaching the Unknown
It was only around July of 2022 that DART‚Äôs onboard camera‚Äîthe Didymos Reconnaissance and Asteroid Camera for Optical navigation (DRACO)‚Äîcaught its first glimpse of Didymos. But Dimorphos wouldn‚Äôt come into view until much, much later: Just an hour before impact, at a distance of roughly 25,000 kilometers, the tiny moonlet was still a mere two pixels across in DRACO images.
‚ÄúWe didn‚Äôt see Dimorphos until late in the game,‚Äù said Adams. To prepare for the uncertainties of impacting a body they knew virtually nothing about, DART team members ran thousands of Monte Carlo simulations beforehand in which they varied the moonlet‚Äôs size, shape, albedo, and a slew of other parameters.
The DART spacecraft successfully impacted Dimorphos on 26 September 2022. The event was recorded by a cadre of Earth-based telescopes and also the Light Italian Cubesat for Imaging of Asteroids (LICIACube), a briefcase-sized spacecraft carrying two cameras that launched with DART and was released from the spacecraft 15 days prior to impact.
A Serendipitous Boost
Researchers had calculated that the impact, which occurred roughly head-on, would shorten Dimorphos‚Äôs orbital period by just under 10 minutes. That was assuming the simplest case of no ejecta being produced, said Andy Cheng, DART investigation team lead at the Johns Hopkins University Applied Physics Laboratory, at a press conference.
‚ÄúThe amount of momentum that you put in the target is exactly equal to the momentum that the spacecraft came in with.‚Äù But if ejecta flies off the asteroid after impact, physics dictates that the asteroid can get an extra boost, said Cheng. ‚ÄúYou end up with a bigger deflection.‚Äù
‚ÄúIf you‚Äôre trying to save the Earth, that makes a big difference.‚Äù
That‚Äôs good news when it comes to pushing a potentially harmful space rock out of the way, said Cheng. ‚ÄúIf you‚Äôre trying to save the Earth, that makes a big difference.‚Äù
And ejecta there was, in spades‚Äîon the basis of detailed follow-up observations of the Didymos-Dimorphos system, scientists discovered that Dimorphos is now traveling around Didymos once every 11 hours and 22 minutes. That‚Äôs a full 33 minutes shorter than its original orbital period, a finding that implied that a substantial amount of ejecta was produced. Imagery obtained from ground- and space-based telescopes has borne that out‚Äîa plume of debris tens of thousands of kilometers long currently stretches out from Dimorphos. Researchers have estimated that at least a million kilograms (1,100 U.S. tons) of material were blasted off the asteroid by the impact. That‚Äôs enough debris to fill several rail cars, said Andy Rivkin, DART investigation team lead at the Johns Hopkins University Applied Physics Laboratory, at a press conference at the Fall Meeting.
Follow the Debris
Interestingly, the ejecta shed by Dimorphos has remained in distinctly more plumelike configurations than the debris shed by comet 9P/Tempel 1 when NASA‚Äôs Deep Impact spacecraft intentionally crashed into it in 2005. ‚ÄúThe Dimorphos ejecta has a lot of morphological features,‚Äù said Jian-Yang Li, a planetary scientist at the Planetary Science Institute in Fairfax County, Virginia, and a member of the DART team, at the Fall Meeting.
The reason is probably the different compositions and surface features of the two bodies, he said. Tempel 1 is rich in volatiles and fine-grained dust; Dimorphos‚Äôs surface, on the other hand, is littered with boulders. Scientists plan to continue to monitor Dimorphos‚Äôs debris plume through at least March.
The DART mission has also enabled scientists to investigate a fundamental question about the Didymos-Dimorphos asteroid system: Do the two asteroids have the same composition? It‚Äôs a common assumption when it comes to binary asteroids, but it‚Äôs never been confirmed. Thomas, leader of the DART Observations Working Group, presented new results on the subject at a press conference at the Fall Meeting. She shared near-infrared spectra of the binary asteroid system that astronomers had collected both before and after impact using a NASA telescope in Hawaii.
Observations obtained prior to impact (when the overwhelming majority of the sunlight reflected off the asteroid system came from Didymos) and after impact (when the debris shed by Dimorphos was responsible for more than two thirds of the reflected light) revealed very similar spectra, with characteristic dips at wavelengths of 1 and 2 micrometers in both cases. That‚Äôs strong evidence that the two asteroids have similar compositions, said Thomas.
Scientists aren‚Äôt yet finished with Didymos and Dimorphos: In 2024, researchers involved in the European Space Agency‚Äôs Hera mission plan to launch a spacecraft to the system to further characterize the asteroids‚Äîincluding accurately measuring the mass of Dimorphos‚Äîand to study the crater created by the DART impact.
‚ÄîKatherine Kornei (@KatherineKornei), Science Writer
Citation: Kornei, K. (2023), NASA‚Äôs Double Asteroid Redirection Test is a smashing success, Eos, 104, https://doi.org/10.1029/2023EO230010. Published on 12 January 2023.
Text ¬© 2023. The authors.¬†CC BY-NC-ND 3.0Except where otherwise noted, images are subject to copyright. Any reuse without express permission from the copyright owner is prohibited.
RelatedAre We Prepared for an Asteroid Headed Straight to Earth?NASA's New Asteroid Sampler Will Illuminate Solar System's HistoryExploring Planetary Breadcrumbs One Asteroid at a Time 

Tagged: #AGU22,¬†asteroids,¬†NASA,¬†orbits & rotations,¬†solar system,¬†Space & Planets 









"
https://news.ycombinator.com/rss,Janet Malcolm on the Stand,https://www.nplusonemag.com/online-only/book-review/malcolm-on-the-stand/,Comments,"         Malcolm on the Stand | Online Only | n+1 | Max Abelson                                      Sign InYour AccountHomeMagazineOnline OnlyBookstoreEventsDonateSubscribeFull
 NavigationSign In to n+1    Forgot Password Subscribe NowCloseSearch   Online Only February 3, 2023A discussion of The Feeling SonnetsEventsEugene Ostashevsky and Genya Turovskaya in conversation  January 6, 2023Film ReviewAn Entire Society Exists Within MeMark Krotov  December 24, 2022Online OnlyCouscous and ChickenNicholas Hamburger   December 23, 2022Online OnlyA Strike DiaryKyle McCarthy   Book ReviewMax AbelsonMalcolm on the StandShe is cutting, wary, funny, and wise. Her style is what I wish I had instead of the chipper inner voice I‚Äôm stuck with. Nothing in Malcolm‚Äôs writing is dull or amiss unless she‚Äôs quoting somebody else. Her lines put me in mind of the painter Agnes Martin‚Äîeverything so even and tight.To read Malcolm is to be moved by the clarity of her journalism‚Äîand warned, again and again, that the form is no good    January 10, 2023  Tags Reading, Writing, and Publishing Reviews  Share and Save Twitter Facebook Google
 Plus    Instapaper Email NewsletterGet n+1 in your inbox. Email Address    Janet Malcolm: The Last Interview and Other Conversations. Introduction by Katie Roiphe. Melville House, 2022.In the few times Janet Malcolm let other reporters interview her, she did what she could to keep herself safe.‚ÄúDoing this interview by email gives me a chance to think of answers to your questions,‚Äù Malcolm wrote to the Believer in 2004. ‚ÄúIf we did it in person, I might just look at you in blank helplessness.‚Äù She invited a Paris Review interviewer over to her Gramercy Park apartment seven years later, but didn‚Äôt answer the questions until typing on her desktop Mac.Malcolm, who died in 2021 at 86, was as attuned as anyone to the dangers‚Äîmalice, betrayal, misunderstanding‚Äîof a tape recorder clicking on. The monster in her masterpiece, The Journalist and the Murderer, isn‚Äôt the man convicted of killing his family but the bestselling author he took to court for publishing a tell-all; what haunts The Silent Woman, her book about Sylvia Plath, isn‚Äôt the poet‚Äôs suicide or Ted Hughes but the couple‚Äôs biographers. To read Malcolm‚Äôs decades of work for the New Yorker is to be moved by the clarity of her journalism‚Äîand warned, again and again, that the form is no good.There are few reporters you‚Äôd rather see on the other side‚Äîthe wrong end‚Äîof a Q&A. That‚Äôs where we find her in Janet Malcolm: The Last Interview and Other Conversations, a compilation of her exchanges with critic Nan Goldberg for Salon in 2001, novelist Daphne Beal in the Believer, Canadian radio host Eleanor Wachtel in 2008, writer Katie Roiphe in the Paris Review, and the New York Times Book Review in 2019. At their best, the transcripts channel and help explain Malcolm‚Äôs mesmerizing journalism, only the tables are turned. Reading the interviews has the perverse quality of seeing a judge on trial or your analyst in therapy.Often, though, it‚Äôs a polite book‚Äîone in Melville House‚Äôs series of ‚Äúlast‚Äù interviews with interesting people‚Äîthat chooses the wrong times to go soft. Malcolm, who knew the subjects of journalism are always ‚Äúastonished when they see the flash of the knife,‚Äù doesn‚Äôt even get nicked. The friction that‚Äôs missing here is what electrifies not just Malcolm‚Äôs writing but the record of what happened when she was actually put on the hot seat. When, decades ago, the star of one of her books sued her for libel, taking her to the Supreme Court and then to two trials, Malcolm‚Äîin front of a jury‚Äîgave the moral accounting these interviews avoid.What makes Malcolm‚Äôs reporting unusual, besides the trouble it caused her, is how much fun it is to be in her company on the page. She is cutting, wary, funny, and wise. Her style is what I wish I had instead of the chipper inner voice I‚Äôm stuck with. Nothing in Malcolm‚Äôs writing is dull or amiss unless she‚Äôs quoting somebody else. Her lines put me in mind of the painter Agnes Martin‚Äîeverything so even and tight.I like the way Beal puts it in the introduction to the Believer interview: ‚ÄúWhat grabs and re-grabs the reader in her writing is its deft commingling of sleuthing and contemplation,‚Äù she writes. ‚ÄúReading Malcolm, one has the sensation of being in the presence of a mind constantly in action on several levels, mediating between external reality (one most often consisting of facts that are at odds with one another) and her own consciousness.‚ÄùFor reporters, Malcolm offers even more than just a guidebook to craft. She‚Äôs a tuning fork whose pitch tells the rest of us when we‚Äôve fallen flat or drifted sharp. That‚Äôs because of the clarity of her writing‚Äî‚Äúvanity, hypocrisy, pomposity, inanity, mediocrity‚Äù is in The Journalist and the Murderer with ‚Äútenderness, sensitivity, judgment, warmth‚Äù as well as ‚Äúambiguity, obscurity, doubt, disappointment, compromise, and accommodation‚Äù‚Äîand how in touch it is with what‚Äôs going on, how it comes together, and why it sometimes falls apart. When I read Malcolm I‚Äôm like Roiphe greeting her for their Paris Review interview: ‚ÄúAround her it is hard not to feel large, flashy, blowsy, theatrical, reckless.‚ÄùMalcolm was born Jana Klara Wienerov√° in Prague in July 1934. Five years later, after Hitler had marched through the city, her family escaped on one of the last civilian ships to America from Europe before the war. Her father became a successful New York psychiatrist‚Äîin these interviews she swears she ‚Äúpaid little attention to my father‚Äôs work‚Äù and that psychoanalysis ‚Äúhas had curiously little influence‚Äù on her style, but one can‚Äôt quite believe her. At the University of Michigan, she wrote for the newspaper, edited its humor magazine, and met her first husband. They both went on to write for the New Yorker, and after he died she married her editor, whose stepfather‚Äôs yeast fortune helped fund the magazine. It wasn‚Äôt until she gave up cigarettes in the late¬†‚Äô70s that Malcolm did her first long piece of journalism: ‚ÄúI figured that by the time I finished the reporting I would be ready to try writing without smoking.‚ÄùIf you want Malcolm at her most rabbinical, there‚Äôs Reading Chekhov, her underrated and atmospheric meditation on the Russian genius from 2001. For momentum that crime writers would kill for, she has Iphigenia in Forest Hills, a 2011 thriller about an Orthodox Jewish woman on trial for murder. Her stories about psychotherapy have the sweet swing of sportswriting, and her work about the law, too, is riveting and deep. Malcolm‚Äôs ear and eye‚Äîand unusual sense of structure‚Äîare most dazzling in her writing about art, especially ‚ÄúForty-one False Starts,‚Äù a portrait of the painter David Salle that begins again and again, and ‚ÄúA Girl of the Zeitgeist,‚Äù a profile of the editor Ingrid Sischy that waits and waits to find her. The shapes of the pieces convey so much about their subjects that a reader can‚Äôt help but feel both are also about the machinery of journalism.There are different forms of Malcolm on the page. The observant and sometimes cold journalist who asks her subjects unsettlingly short questions isn‚Äôt quite the same figure as the ingenious narrator whose essayistic contemplation radiates generosity. Then there‚Äôs the small and sometimes anxious woman who emerges to play key plot roles, especially in Iphigenia.The Malcolm we encounter in The Last Interview shares the self-awareness, briskness, clarity, and humor she possesses elsewhere: ‚ÄúI walk fast and am impatient. I get bored easily,‚Äù Malcolm tells the Paris Review. ‚ÄúI often get stuck. Then I get sleepy and have to lie down. Or I make myself leave the house‚Äîwalking sometimes produces a solution. The problem is usually one of logic or point of view. I keep regular morning hours. The first hour is the most productive one.‚Äù Worrywart writers will find much to love in Malcolm‚Äôs description of herself: ‚ÄúThe machinery works slowly and erratically and I am always a little nervous about it, though by now I‚Äôm pretty used to it,‚Äù she emails. ‚ÄúI guess I trust it more.‚ÄùBut where Malcolm the journalist is unsparing and direct, Malcolm the interviewee is ultimately vague and evasive. ‚ÄúWhat‚Äôs true? Is it possible to know what‚Äôs true?‚Äù Goldberg asks in the Salon interview. Malcolm answers: ‚ÄúI‚Äôd love to hear you talk about it rather than me.‚Äù‚ÄúWhy do you think the subject of betrayal is something that‚Äôs your subject?‚Äù Wachtel asks her on the radio. ‚ÄúThat‚Äôs very interesting,‚Äù Malcolm says. ‚ÄúYou‚Äôre kind of putting me on the spot.‚ÄùInterviews aren‚Äôt the same as sworn testimony, but they rhyme. They use questions to flatter, badger, and trap witnesses who, in turn, evade when they can and admit things they don‚Äôt want to. Reporting and the law both rely on evidence and discovery, asking for honesty and promising fairness in exchange. They offer just about the best systems we have for hearing arguments, measuring doubt, rendering judgment, and appealing verdicts‚Äîexcept, maybe, for psychoanalysis. All three approaches use confrontation to turn ambiguity into clarity, but only one can punish an outburst or lie by locking the speaker away.The long and famous case against Malcolm began in 1984, after she published a New Yorker profile about a lawsuit from a star scholar named Jeffrey Moussaieff Masson against the ‚Äã‚ÄãSigmund Freud Archives. It was also a vibrant portrait of a charming and ambitious heel. Masson accused Malcolm in the Washington Post of misquoting him ‚Äúany number of times.‚Äù (The newspaper reporter, a young David Remnick, wrote that Malcolm was away on vacation in Italy and couldn‚Äôt be reached for comment.) When Malcolm expanded the piece into a book, In the Freud Archives, Masson complained again, in a letter to the New York Times. The response she sent offered to play the tapes of their conversations for Times editors ‚Äúwhenever they have 40 or 50 short hours to spare.‚Äù Masson sued her for libel soon after.His case began terribly. Many of the quotes he had denied saying turned out to be on her tape. Others really were missing, though, and Malcolm had an unusual story: she had tripped over her recorder‚Äôs cord before a morning interview, took notes instead, typed them up, and misplaced the originals. But a judge decided Malcolm had reasonably interpreted whatever Masson had actually said and threw out the suit. Just after Malcolm published The Journalist and the Murderer, the Supreme Court agreed to hear Masson‚Äôs appeal. Anthony Kennedy, joined by six other justices, wrote that a misquote has to hit the reader‚Äôs mind differently than the right one would to cross the line into libel. It would be up to a jury to decide if Malcolm‚Äôs writing and Masson‚Äôs words shared ‚Äúthe substance, the gist, the sting.‚Äù (When the Times asked for comment, Malcolm was back in Italy.)Inside a federal court in California in May 1993, Malcolm took the stand. Masson‚Äôs lawyer, a former quarterback and Air Force navigator named Charles O. Morgan Jr., asked Malcolm about a key monologue at the Berkeley restaurant Chez Panisse. ‚ÄúYou reported in the article that the entire statement was made by Mr. Masson at lunch,‚Äù Morgan asked.1‚ÄúYes,‚Äù Malcolm said.‚ÄúAnd that is not true.‚Äù‚ÄúThat‚Äôs right,‚Äù Malcolm said. She had compressed conversations over seven months into one monologue, she told the jury, using them like ‚Äúsketches incorporated into one painting.‚Äù Anything else, she testified, would be foolish: ‚ÄúI do not want to write the exact words, I do not want to write a transcript,‚Äù she went on. ‚ÄúThis thing called speech is sloppy, redundant, repetitious, full of uhs and ahs.‚Äù When that line surfaces in the introduction to The Last Interview, Roiphe cites it admiringly, praising Malcolm for improving on the ‚Äúcasualness and mediocrity of expression‚Äù by ‚Äútrimming and shaping.‚Äù Morgan, the attorney, argued otherwise.‚ÄúDo you call that rearranging events?‚Äù he asked.‚ÄúI don‚Äôt know what that means.‚Äù‚ÄúDo you call it creating a conversation?‚Äù‚ÄúI wouldn‚Äôt put it that way, no.‚ÄùBefore the trial ended, Malcolm testified that the chaos and contradiction of speech had forced her hand: ‚ÄúHe‚Äôs trying to tell too many things at the same time. You had to work hard to get the story straight because he was all over the place.‚ÄùJurors decided for Masson. But they couldn‚Äôt agree on damages, so the judge announced they‚Äôd start the whole thing over. In one of her most gripping pieces, published in the New York Review of Books months before her death, Malcolm recalls the makeover she gave herself with a speech coach before returning to the stand. Back in the courthouse, she gave ‚Äúa long speech about the monologue technique that Morgan kept interrupting but was unable to stop,‚Äù Malcolm writes. ‚ÄúI went relentlessly on and on. I talked about the difference between the full and compelling account of his rise and fall in the Freud Archives that Masson gives in the article and his wandering incomplete speech in the restaurant. I spoke of the months of interviews out of which, bit by bit, the monologue was formed. I concluded by saying, ‚ÄòI have taken this round-about way of answering your question, Mr. Morgan, because I wanted the jury to know how I work, and what we‚Äôre talking about here in talking about this monologue.‚Äô‚ÄùAfter one kind of Malcolm monologue about another, the jury dismissed concerns about three of the five quotes in question. But jurors decided the two others‚Äîabout the sterility of psychoanalysis and Masson‚Äôs bosses‚Äîwere false, and that the latter qualified as defamation. They also decided, though, that Malcolm hadn‚Äôt been reckless enough to cross the legal line of libel. She won and wept.What happened a year later gets more attention in the book of her interviews than her testimony. ‚ÄúI was in my country house, and there was something red on the floor, and I picked it up, this red notebook. My granddaughter had seen something red in the bookcase and pulled it out, and there were the notes‚Äù‚Äîthe ones she took after tripping over the recorder‚Äôs cord. ‚ÄúI felt like I was going to faint.‚Äù If only she had found them earlier, she tells Wachtel, ‚Äúthe whole thing could‚Äôve been avoided.‚Äù She emails the story to the Believer, too: ‚ÄúThe jury had decided to believe me anyway. But if the notebook hadn‚Äôt got misplaced, there would have been no lawsuit.‚ÄùThe fact is that Malcolm‚Äôs accounts, as she liked to write about other people, ‚Äúdon‚Äôt add up.‚Äù The missing red notebook had three of the quotes in question, but not the two that had bothered the jury. ‚ÄúDo we ourselves add up?‚Äù Goldberg asks Malcolm in the Salon interview.‚ÄúNo,‚Äù Malcolm answers. ‚ÄúOf course we don‚Äôt.‚ÄùThat someone so thoughtful about the moral perils of journalism could be messy enough to collage scenes together‚Äîthen blithe enough to testify it was all for the best and deluded enough to say a missing notebook explained it all‚Äîis a paradox that we Malcolm fans have to live with. It‚Äôs also, of course, a version of what her work was warning about. Whether her shortcomings bring her journalism to life or do something more like undermine it is the kind of thing you would want to ask her, right before running out of the room.Roiphe‚Äôs introduction to The Last Interview avoids Malcolm‚Äôs mysteries and messes. It‚Äôs less about the morals or machinery of her journalism than what it was like to be her bud. ‚ÄúWhen a friend texted me that Janet Malcolm had died, I experienced more than the usual amount of disbelief,‚Äù it begins. ‚ÄúThis is one of the conversations I wish I‚Äôd had with Janet herself at Choshi,‚Äù Roiphe writes later, ‚Äúthe now-closed sushi place she favored around the corner from her house. I know she would have had thoughts on it.‚Äù If you‚Äôre in a generous mood, you can read the intro as a kind of pun on Malcolm‚Äôs interest in the ‚ÄúI‚Äù who narrates literary nonfiction: ‚ÄúI wonder,‚Äù ‚ÄúI confessed,‚Äù ‚ÄúI suggested,‚Äù ‚ÄúI fixate,‚Äù I understand,‚Äù ‚ÄúI hear,‚Äù Roiphe writes, and then ‚ÄúI love‚Äù three times in a row.It all comes to a crescendo with a sort of Freudian slip. ‚ÄúI have always used her writing to teach confidence,‚Äù she writes, meaning to refer to Malcolm‚Äôs authoritativeness but channeling the line that follows The Journalist and the Murderer‚Äôs famous opening: ‚ÄúHe is a kind of confidence man, preying on people‚Äôs vanity, ignorance, or loneliness, gaining their trust and betraying them without remorse.‚ÄùThe first of the interviews, with Salon, opens with the kind of reportorial antagonism I found myself missing as the book went on: If journalists are murderers, Goldberg asks, why was Malcolm speaking to one? Malcolm twists away by complimenting the question and pointing out she used to avoid reporters entirely. ‚ÄúWhen the book came out and people wanted to ask me questions, I said, ‚ÄòWell, read the book.‚Äù‚ÄúI did,‚Äù Goldberg answers, standing her ground. ‚ÄúThat‚Äôs why I‚Äôm asking.‚Äù Instead of saying why she agreed to the interview, Malcolm explains why she shouldn‚Äôt have: ‚ÄúI‚Äôm just not very good at it. I often have no answers to the questions; I think of the answers later.‚ÄùIt‚Äôs a moment when the tension and confrontation that the book mostly suppresses manages to leak out, but not the only one. In the Believer, when Beal dares to ask if getting sued changed her approach with subjects, Malcolm shows her teeth: ‚ÄúUntil this moment you were the first interviewer who did not bring Jeffrey Masson into the discussion. I guess that isn‚Äôt possible after all.‚Äù You again get the sense that the nastiness of journalism was only fun for Malcolm to consider when it was someone else‚Äôs.Beal backs off: ‚ÄúSorry to be so tiresome,‚Äù she writes back. ‚ÄúJust like the rest.‚Äù The exchange ends soon after, but, following a line break, an italicized note says Malcolm read the transcript and sent this in an email: ‚ÄúI read the interview in the way one looks at photographs of oneself, and, except for one place, I thought I came out looking okay. But the exception may be the most interesting part of the interview.‚Äù It‚Äôs Masson. ‚ÄúUntil that moment the atmosphere of the interview is friendly and collegial, almost conspiratorial. Now it turns icy.‚Äù Malcolm goes on: ‚ÄúWhat is most interesting about this moment in our interview is the illustration it offers of a subject‚Äôs feeling of betrayal when he or she realizes that the journalist is writing his or her own story.‚ÄùIf a goal of Malcolm‚Äôs journalism was to measure the distance between the stories that reporters shape and the ones subjects tell about themselves, this book makes the mistake of letting her maintain almost complete control of the tape‚Äîor, in the case of Roiphe‚Äôs Paris Review interview, the notebook. ‚ÄúI want to talk about that moment in our meeting at my apartment last week, when I left the room to find a book and suggested that while I was away you might want to take notes about the living room for the descriptive opening of this interview,‚Äù Malcolm writes in an email that‚Äôs quoted in the interview‚Äôs introduction. ‚ÄúYou obediently took out a notebook, and gave me a rather stricken look, as if I had asked you to do something faintly embarrassing.‚Äù Malcolm fills it in for her in the interview: ‚ÄúMy living room has an oakwood floor, Persian carpets, floor-to-ceiling bookcases, a large ficus and large fern, a fireplace with a group of photographs and drawings over it, a glass-top coffee table with a bowl of dried pomegranates on it, and sofas and chairs covered in off-white linen.‚ÄùThat‚Äôs not to say deference is so terrible. Even though the ‚ÄúBy the Book‚Äù feature in the Times only asks Malcolm about reading, she looks around her bookshelves and spots ‚Äúpetulant desperation,‚Äù ‚Äúwild terrain,‚Äù ‚Äúthe eye of eternity,‚Äù and on top of her night table ‚Äúa box of Kleenex, a two-year-old Garnet Hill catalog and a cough drop on it.‚ÄùBut you find yourself yearning for confrontation and catharsis. Did she, in her later writing, stick with the collage method she defended on the stand, or was it sublimated into the delicate collages she started making‚Äîand exhibiting at art galleries‚Äîfrom handwriting, typewritten papers and book pages?Salon asks this: ‚ÄúDo you see any relationship between your collages and your writing?‚Äù‚ÄúI think so,‚Äù Malcolm answers. ‚ÄúI like to think about my work as kind of collage-like.‚Äù There isn‚Äôt a followup, because their interview, right there, is over.Roiphe ends her essay with herself, so I get to end mine with me.When I was hired as a newspaper reporter in 2006, taking over the New York Observer‚Äôs weekly column on the city‚Äôs most expensive real estate, I was introduced to business journalism at the peak of what turned out to be a bubble. I wrote about buyers and sellers who played a role in inflating and then bursting it: ‚ÄúMoney just doesn‚Äôt mean anything,‚Äù one of the city‚Äôs high-end brokers told me not long before Bear Stearns collapsed and the era came to an end. I switched beats in 2009 to report on the landscape of Wall Street‚Äôs culture, covering some of the same people, only how they made their money instead of where they spent it.I fell in love with Malcolm‚Äôs journalism because it seemed to me at the time to be a map to the crises I would have to navigate. I imagined that the tensions her books describe only multiply if interview subjects are rich and powerful. Higher stakes, I figured, only complicate access and relationships. Reading these interviews makes me think I was wrong. They are reminders that even the subjects who best understand what‚Äôs happening can‚Äôt fully explain themselves to outsiders, and that no journalist knows how to get them to reveal it all.What is there to do about it? ‚ÄúPerhaps the way to minimize one‚Äôs feeling that one has not been as straightforward with the subject as one should have been,‚Äù she tells the Believer, ‚Äúis to be a little more straightforward.‚Äù Sometimes I talk to my subjects about the trouble Malcolm picked up on, and the trouble she got into. And sometimes I can feel the acknowledgement make us both relax, at least for a little bit.But Malcolm wouldn‚Äôt want anybody to get too comfortable. When the Believer asks if subjects occupy a different place in her mind at the end of writing than they had during interviews, she writes back that she isn‚Äôt sure she understands the question. Beal tries again: ‚ÄúHow do you make the switch from supplicant or equal interviewer to authority writer?‚Äù‚ÄúYes, it is a problem,‚Äù Malcolm answers, ‚Äúand no, it can‚Äôt be resolved.‚ÄùQuotes from the trials come from coverage in the New York Times, Village Voice and Washington Post.¬†‚Ü© If you like this article, please subscribe or leave a tax-deductible tip below to support n+1.    The Burglaries Were Never the Story Related Articles  Issue 2 HappinessKeith Gessen replies: The genital flag?Issue 2LettersThe Editors   Issue 5 Decivilizing ProcessIt has lately become clear that nothing burdens a life like an email account.Issue 5Against EmailThe Editors   Issue 39 Take CareI can tell you only what I found helpful.Issue 39Baby YeahAnthony Veasna So   Issue 6 MainstreamCanons in daily life just demarcate the books you can count on other people feeling comfortable about in conversation.Issue 6The Spirit of RevivalThe Editors More by this Author August 20, 2021‚ÄúListen to the last half-hour of ‚ÄòDark Star‚Äô in a darkened room and see if you feel remotely secure.‚ÄùOnline OnlyIn the Dead ArchivesMax Abelson  n+1n+1 is a print and digital magazine of literature, culture, and politics published three times a year. We also post new online-only work several times each week and publish books expanding on the interests of the magazine.MagazineCurrent IssueRenew SubscriptionSubscribeGift SubscriptionsYour AccountBack IssuesBookstoresLibrariesAdvertiseRSSAbout n+1AboutFoundationEventsContactBack to TopCopyright ¬© 2023 n+1 Foundation, Inc.Terms & Conditions | Privacy Policy                                        "
https://news.ycombinator.com/rss,CircleCI says hackers stole encryption keys and customers‚Äô source code,https://techcrunch.com/2023/01/14/circleci-hackers-stole-customer-source-code/,Comments,"










 


CircleCI says hackers stole encryption keys and customers' secrets ‚Ä¢ TechCrunch















































































 
 



 













CircleCI says hackers stole encryption keys and customers‚Äô secrets




			Zack Whittaker		

@zackwhittaker
 / 
						23 hours		







CircleCi, a software company whose products are popular with developers and software engineers, confirmed that some customers‚Äô data was stolen in a data breach last month.
The company said in a detailed blog post on Friday that it identified the intruder‚Äôs initial point of access as an employee‚Äôs laptop that was compromised with malware, allowing the theft of session tokens used to keep the employee logged in to certain applications, even though their access was protected with two-factor authentication.
The company took the blame for the compromise, calling it a ‚Äúsystems failure,‚Äù adding that its antivirus software failed to detect the token-stealing malware on the employee‚Äôs laptop.
Session tokens allow a user to stay logged in without having to keep re-entering their password or re-authorizing using two-factor authentication each time. But a stolen session token allows an intruder to gain the same access as the account holder without needing their password or two-factor code. As such, it can be difficult to differentiate between a session token of the account owner, or a hacker who stole the token.
CircleCi said the theft of the session token allowed the cybercriminals to impersonate the employee and gain access to some of the company‚Äôs production systems, which store customer data.
‚ÄúBecause the targeted employee had privileges to generate production access tokens as part of the employee‚Äôs regular duties, the unauthorized third party was able to access and exfiltrate data from a subset of databases and stores, including customer environment variables, tokens, and keys,‚Äù said Rob Zuber, the company‚Äôs chief technology officer. Zuber said the intruders had access from December 16 through January 4.
Zuber said that while customer data was encrypted, the cybercriminals also obtained the encryption keys able to decrypt customer data. ‚ÄúWe encourage customers who have yet to take action to do so in order to prevent unauthorized access to third-party systems and stores,‚Äù Zuber added.
Several customers have already informed CircleCi of unauthorized access to their systems, Zuber said.
The post-mortem comes days after the company warned customers to rotate ‚Äúany and all secrets‚Äù stored in its platform, fearing that hackers had stolen its customers‚Äô code and other sensitive secrets used for access to other applications and services.
Zuber said that CircleCi employees who retain access to production systems ‚Äúhave added additional step-up authentication steps and controls,‚Äù which should prevent a repeat-incident, likely by way of using hardware security keys.
The initial point of access ‚Äî the token-stealing on an employee‚Äôs laptop ‚Äî bears some resemblance to how the password manager giant LastPass was hacked, which also involved an intruder targeting an employee‚Äôs device, though it‚Äôs not known if the two incidents are linked. LastPass confirmed in December that its customers‚Äô encrypted password vaults were stolen in an earlier breach. LastPass said the intruders had initially compromised an employee‚Äôs device and account access, allowing them to break into LastPass‚Äô internal developer environment.
Updated headline to better reflect the customer data that was taken.















 
 


"
https://news.ycombinator.com/rss,America‚Äôs trustbusters plan to curtail the use of non-compete clauses. Good,https://www.economist.com/leaders/2023/01/12/americas-trustbusters-plan-to-curtail-the-use-of-non-compete-clauses-good,Comments,"LeadersAmerica‚Äôs trustbusters plan to curtail the use of non-compete clauses. GoodThe clue is in the name Jan 12th 2023ShareThree-quarters of Americans who work, do so for a firm. They have contracts setting out their pay, holiday, benefits and sometimes the appropriate way to dress (although not in journalism). A lot of contracts also say whether employees may work for a competitor if they leave the company. It is hard to know what share of American workers are restricted by these non-compete clauses, but the available evidence suggests it may be as high as one in five. More worrying, these clauses are as likely to apply to workers operating deep-fat fryers in fast-food kitchens as they are to workers operating in the conference rooms of white-shoe law firms. The Federal Trade Commission (FTC) has these clauses in its sights, on the grounds that they are anticompetitive and suppress wages. Listen to this story. Enjoy more audio and podcasts on iOS or Android.Your browser does not support the <audio> element.Listen to this storySave time by listening to our audio articles as you multitaskOKFans of non-compete clauses argue that scrapping them by decree will invite the state into the realm of private contracts, a symptom of regulatory excess. They have a point, but the FTC‚Äôs case is stronger.It is easy to see why firms like non-compete clauses, which are designed to suppress competition. It suits companies to be able to prevent a star employee from joining a rival, or starting out on their own and wooing clients. But there are also some arguments that non-competes could serve the public interest. Companies sometimes say that the clauses incentivise them to think about talent in a longer-term way. Why bother to spend time and money on training employees if they then join rival firms that go on to reap the benefit of the investment? Some companies also have legitimate worries about trade secrets walking off to a competitor when an employee leaves.However, a non-compete clause is a heavy-handed way to achieve those ends. Intellectual-property law and non-disclosure agreements exist to preserve true trade secrets, and lots of firms find ways to keep valuable employees without shackling them to their jobs using non-compete clauses. The public interest also conflicts with the firm‚Äôs interest: innovation and productivity spread when better ideas about how to do things become widely adopted. Hiring people with specific knowledge and experience can speed this process up, which is one reason why the engineers fired by tech giants like Meta and Twitter are sought after by firms in older industries eager to learn.If the theory points in one direction, the evidence from how non-competes are used practically screams. In 2014 Jimmy John‚Äôs, a chain of sandwich shops, was found to have inserted a two-year non-compete clause in its employees‚Äô contracts which barred them from seeking employment with any rival business that made money by ‚Äúselling submarine, hero-type, deli-style, pita and/or wrapped or rolled sandwiches‚Äù within a three-mile radius of where they currently worked. After this egregious example came to light, the company ended the practice. But franchises often stop employees from going to work at other outlets of the same franchise, reducing their bargaining power.It strains credulity to argue that these workers are the guardians of trade secrets. Instead, the evidence is that firms use non-compete clauses to drive down wages by lowering the value of workers in the job market. About half of people with non-compete clauses in their contracts work in states where they cannot legally be enforced. They may get away with it because employees do not know their rights, especially those in the low-paid part of the labour market. The evidence that non-compete clauses really make companies more innovative and higher-skilled is scarcely more convincing. Washington state, home to Amazon and Microsoft, takes a middle path by restricting non-compete clauses to the contracts of high-earners. California, the global hq of disruptive innovation, goes a step further and bans non-competes altogether. The FTC should do the same, on the grounds that they are anticompetitive. ‚ñ†This article appeared in the Leaders section of the print edition under the headline ""The clue is in the name""Leaders January 14th 2023The destructive new logic that threatens globalisationThe West should supply tanks to UkraineHow Brazil should deal with the bolsonarista insurrectionAmerica‚Äôs trustbusters plan to curtail the use of non-compete clauses. GoodFixing Britain‚Äôs health service means fixing its family doctorsFrom the January 14th 2023 editionDiscover stories from this section and more in the list of contents Explore the editionShareReuse this contentMore from LeadersThe glory of grandparentsWhy the soaring number of grandmas and grandpas is a good thingHow Brazil should deal with the bolsonarista insurrectionPunish those who broke the law, but govern inclusivelyFixing Britain‚Äôs health service means fixing its family doctorsDon‚Äôt change the partnership model. Do change the targets"
https://news.ycombinator.com/rss,Wobbly clock,https://somethingorotherwhatever.com/wobble-clock/,Comments,"


Wobbly clock!













"
https://news.ycombinator.com/rss,Godot for AA/AAA game development ‚Äì What's missing?,https://godotengine.org/article/whats-missing-in-godot-for-aaa/,Comments,"














					Godot for AA/AAA game development - What's missing?
				

					By: Juan Linietsky
					 16 January 2023



News



Godot 4.0 is coming out soon. It includes major improvements all across the board in features, performance, and usability. Still, one of the biggest questions the community has is: How does it compare with mainstream commercial offerings?
Godot 4.0 improvements
Rendering
Godot 4.0 has an entirely new rendering architecture, which is divided into modern and compatibility backends.
The modern one does rendering via RenderingDevice (which is implemented in drivers such as Vulkan, Direct3D 12, and more in the future). Additionally, the modern backend can implement rendering methods, such as forward clustered, mobile, and more in the future (such as deferred clustered, cinematic, etc.).
The compatibility backend is based on OpenGL ES 3.0 / OpenGL 3.3 / WebGL 2.0 and is intended to run on very old PC hardware as well as most older (still working) mobile phones.
Rendering is significantly more efficient in Godot 4.0, using data oriented algorithms to process the culling of objects and both secondary command buffers and automatic batching to efficiently submit the draw primitives.
The features offered are also a lot more reminiscent of AAA games, such as far more material options and advanced visual effects (including circle DOF, volumetric fog, AMD FSR, etc.). Additionally, Godot 4.0 supports advanced global illumination techniques such as lightmapping (including SH lightmapping), Voxel GI (which is fully real-time) and SDFGI (which is a single click, open world GI solution). Screen space GI can be used to enhance the realism even more.
Physics
After an unsatisfactory attempt at using Bullet, Godot 4.0 returns to its own physics engine which, despite not being a high end physics engine like PhysX, aims to offer a lot more flexibility and ‚Äújust works‚Äù capabilities to users.
Several features were added to Godot Physics since 3.x, such as soft bodies and cylinder shape support, as well as several optimizations to make use of multiple threads.
The custom physics engine still has a considerable amount of issues remaining but we are working hard to ensure it is in a decent state for shipping when 4.0 reaches stability. It will continue seeing improvements afterwards, during the following 4.x release cycles.
That said, Godot 4.0 introduces the ability to bind custom physics engines at runtime (without recompiling Godot) via GDExtension, so it‚Äôs perfectly possible for the community to integrate other engines such as PhysX, Jolt, or Box2D if need to be.
Scripting
Godot 4.0 has a new version of GDScript, which is far more powerful and overcomes most shortcomings found in 3.x. Majorly, the addition of lambdas, first class functions/signals and a much reduced reliance on string identifiers (which are prone to errors). It also has more useful built-in data types such as integer vectors.
Core engine
The core engine has been significantly optimized, especially on the memory and data-oriented areas. Core and Variant have been massively cleaned up and made more extensible. Besides being faster and more modern, the core codebase is now significantly easier to maintain and extend.
GDExtension
It is now possible to extend Godot and add features to it practically in any language and without recompiling the engine, thanks to the new GDExtension system. Aside from Godot C++ (which makes it easy to extend Godot as easy as with modules but allowing pluggable, dynamic add-ons), there are other bindings in the work such as Python, Rust, Go, etc.
A lot more
Several other areas got improvements, like the editor (which has been vastly reworked), UI system, multiplayer, navigation, audio, animation, etc. This is a major release with major improvements all across the board.
So, what‚Äôs missing?
Do not be mistaken: A lot is still missing from Godot in order to be used comfortably for large projects and teams. That said, what remains is now much less work than it was for Godot 3.x.
First of all, most of the new features still have significant bugs and performance problems that will not be solved in time for the upcoming 4.0 release (there is just too much new code that needs to be tested throughly).
These problems will be fixed across the 4.x point releases (which we are now intending to do more often, allowing several releases per year). It may be an extra year or even two until everything feels as solid and fast as everyone expects. See this article about our plans for 4.0 and beyond.
But other than that, there are still some fundamental aspects missing in Godot. The following is an incomplete list of the most important ones:
Streaming
The traditional way to make games longer since the beginning of times is to divide them in stages. As soon as one stage is completed, it is unloaded while the new one is loaded.
Many games still use this approach nowadays (after all, if it‚Äôs not broken, don‚Äôt fix it) but, increasingly, game design has been moving from ‚Äúindividual stages‚Äù to ‚Äúopen‚Äù or ‚Äúcontinuous‚Äù worlds where the boundaries between levels disappear. Creating games this way is, as a result, more challenging.
This is handled nowadays by a type of technology called ‚Äústreaming‚Äù. It means that assets are pulled from disk on demand (loaded only at the time they are needed), rather than as a part of a larger stage. The most common types of streaming are:

Texture streaming: All textures are loaded in a tiny size by default. As textures get closer to the camera, higher resolution versions (or mip-maps) are streamed from disk. Textures which haven‚Äôt been used for some frames are freed instead. At any given time, the textures loaded (and their detail) closely reflect the place the player is in.
Mesh streaming: Models are loaded as low detail (few vertices). As they gradually approach the camera, higher resolution versions are streamed from disk. Models that were not used (displayed) since a while are often just freed and will be loaded again when needed.
Animation streaming: Modern games have long cinematics, which require a lot of animation data. Loading those animations require a lot of memory and loading them takes a lot of time. To avoid this, animations are streamed by generally keeping the first second or two in memory and then new sections are loaded on demand as the animation plays. Godot 4.0 supports strong animation compression and animation pages, so most of the work is already done.
Audio streaming: Similar to animation streaming, it requires storing the first second or two of audio and then streaming the rest directly from disk.

Of the above, most are relatively straightforward to implement. The most complex is mesh streaming, which generally needs to be implemented together with a GPU culling strategy to ensure that very large amounts of models can be drawn at no CPU cost. This is more or less what techniques like Nanite do in Unreal, although Godot does not need to implement something that complex to be of use in most cases.
Streaming is the most important feature missing for managing large scenes or open worlds. Without it, Godot users are subject to long loading times (as every texture, model and animation has to load before anything is shown). There is also a risk of running out of memory if too many assets are loaded in parallel instead of streaming them.
Low level rendering access
Despite the new renderer in Godot 4.0, there is no architecture that can be considered a one size fits all solution. Often developers need to implement rendering techniques, post processing effects, etc. that don‚Äôt come bundled with the engine.
The Godot philosophy has always been to cater to solving the most common use cases, and leave the door open for users to solve the less common on their own.
As such, this means that low level access to all the rendering server structures needs to be exposed via GDExtension. This will allow creating custom renderers or plugging custom code during the rendering steps, which is very useful for custom rendering techniques or post processes.
Scene job system
Most of the work done for the Godot 4.0 involved large feature and performance improvements to all the servers (rendering, physics, navigation, etc.). Servers are also now multithreaded and optimized. Even asset loading can now be done multithreaded (using multiple threads to load multiple assets).
Still, the scene system (which uses those servers), despite several usability improvements, has not seen significant optimization.
Scenes nodes in Godot are mostly intended to carry complex high level behaviors (such as animation trees, kinematic characters, IK, skeletons, etc.) for limited amounts of objects (in the hundreds at most). Currently, no threading happens at all and only a single CPU core is used. This makes it very inefficient.
This makes it an ideal target for optimizing with multithreading. There is an initial proposal on threaded processing for scene nodes, which should give complex scenes a very significant performance boost.
Swarms
Scenes, as mentioned before, are designed for complex high level behaviors in the hundreds of instances. Still, sometimes, some games require larger amounts of instances but less complex behaviors instead.
This is needed for some types of game mechanics such as:

Projectiles (bullet hell for example).
Units in some types of strategy games with thousands of entitites roaming across a map.
Cars/people in city simulators, where thousands appear all across the city.
Sandbox style simulations.
Complex custom particles that run on CPU.
Flocks, swarms, mobs, debris, etc.

More experienced programmers can use the servers directly or even plug C++ code to do the heavy lifting. ECS is often also proposed as a solution for this. Even GPU Compute (which is fully supported in Godot) can be easily used to solve this pattern.
But for the sake of keeping Godot accessible and easy to use, the idea is to create a swarm system that takes care of the rendering/physics/etc. in large amounts of those objects and the user only has to fill in the code logic.
Large team VCS support
Godot‚Äôs text file formats are very friendly to version control. They only write what is needed (no redundant information), keep the ordering of sections and are simple enough to understand changes by just looking at the diff. Few other technologies work as well in this area.
Despite that, this is far from enough to enable large team collaboration. To enable this, Godot VCS support has to improve in several areas:

Better integration with the filesystem dock.
Better real-time refresh of assets if they were modified externally (and checked out).
Support for permissions and file locking: Git does not support this out of the box, but Git LFS and Perforce do. This feature is essential for large teams to avoid conflicts and keep files protected from unintended modifications (e.g. a team member modifying code or a scene they don‚Äôt own by mistake).

Unless the support for this is solid, using Godot in large teams will remain difficult.
Commercial asset store
While for very large studios this is not an area of interest, medium-sized studios still rely on significant amounts of assets and pre-made functionality. The Asset Library currently existing in Godot only links to open source resources (e.g. hosted on GitHub or GitLab) and is unable to be used for commercial assets.
For the Godot project, a commercial asset store would be a great way to add an extra source of income, but it was not legally possible given our legal status until recently. With the move to the Godot Foundation, this is a new possibility that opens up.
Is solving these problems enough for Godot to become a top AA / AAA game engine?
The answer is ‚Äúit depends‚Äù. Godot, at its core, is and will always be (by design) a very general purpose game engine. This mean that the tools provided, while certainly capable, are still game neutral. The goal for Godot is to provide a great set of building blocks that can be used and combined to create more specialized game functions and tools.
In contrast, other types of game engines already come with a lot of high level and ready to use components and behaviors.
I don‚Äôt meant to say that Godot should not support any of that in the future. If it does, though, it will most certainly be as official extensions.
So, what kind of features are we talking about? Well..
Game specific templates and behaviors
As an example, Unreal comes with a player controller, environment controller, and a lot of tools to manage the game pacing and flow. Most likely aimed at TPS/FPS games, which is the most popular game type made with the engine.
Some of these can be found as templates in Godot‚Äôs Asset Library but are nowhere close to that functionality. Eventually, official ones should be created that are more powerful and complete.
Visual scripting
While Godot had visual scripting in the past, we found that the form we had implemented didn‚Äôt really prove adequate for the needs of the community, so it was discontinued.
What we realized is that visual scripting really shines when combined together with the premade behaviors mentioned in the previous section. Without a significant amount of high level behaviors available, visual scripting is cumbersome to use as it requires a lot of work to achieve simple things by itself.
All this means that, if we produce a visual scripting solution again, it needs to go hand in hand with high level behaviors and, as such, it should be part of a set of extensions to the engine.
Specialized artist UIs
When doing tasks such as shader editing, VFX (particles) or animation, there is a large difference between Godot and engines such as Unreal.
The difference is not so much in features supported. In fact, the feature set is fairly similar! The main actual difference is in how they are presented to the user.
Godot is a very modular game engine: this means that you achieve results by combining what is there. As an example, editing a particle system in Godot means a lot of subsystems must be understood and used in combination:

GPUParticles node.
GPUParticlesMaterial resource (or even an optional dedicated shader).
Mesh resource for each pass of the particle.
Mesh material resource for each surface of the mesh (or even an optional dedicated shader).

As another example, the AnimationTree in Godot requires that AnimationNodes are laid out in a tree fashion. They can export parameters, sections can be reused (because they are resources), etc.
Or even more. Godot‚Äôs animation system is often praised because anything can be animated. Any property, other nodes, etc.
This makes Godot an extremely powerful engine that gives developers a lot of flexibility, but‚Ä¶
It also assumes that the user is knowledgable enough about Godot and all its inner workings in order to take advantage of it. To clarify, none of these systems are too technically complex and this is part of what makes Godot appealing and accessible, but it still requires a certain level of technical and engine knowledge.
In contrast, engines like Unreal have entirely dedicated and isolated interfaces for each of these tasks (materials, cinematic timeline, VFX, animation, etc.).
Sure, they are monolithic and hence less flexible, but for a large team with high amounts of specialization, an artist does not need to understand as much in-depth how the engine works in order to produce content with it.
This shows the fundamental difference of target user between engines. If Godot wants to appeal to larger studios, it needs to provide simpler and more monolithic interfaces for artists to be able to do their job without requiring significant more time investment in learning the technology.
This could, again, be supplied via official add-ons and, like the sections above, would require a significant amount of research to understand how to build it, since without actual feedback from artists we would only be guessing what is needed. But the question here is, is it worth it?
So, are we not even close?
While the goal of this article is to make clear how significant is the work remaining to make Godot an offering closer to the ones in the commercial segment, it is important to not forget one key detail:
Godot is Free and Open Source Software. And as such, it can be modified by anyone to fit any purpose.
Currently, many large studios have the ability to create their own in-house technology. Still, as hardware becomes more and more complex to develop for, they are giving up in favor of spending money on pre-existing commercial technology offerings.
Godot, on the other hand, serves as an excellent platform to build upon, as it solves the vast majority of problems already. As a result, more and more studios are using Godot as a base to derive their own technology from.
This is a win/win situation, as it allows them to keep their freedom to innovate and, at the same time, avoid paying expensive technology licensing costs.
Time will tell how Godot transitions from its current state to something more widely used by larger studios, but it will definitely need significantly more work from our side.
Future
I hope that this write up made more evident why Godot is such a key technology for the future of the game industry. We will continue working hard to ensure that more and more individuals and companies find Godot useful! But we need your help to happen, so please consider donating to the project.



"
https://news.ycombinator.com/rss,Reverse engineering a neural network's clever solution to binary addition,https://cprimozic.net/blog/reverse-engineering-a-small-neural-network/,Comments,"Reverse Engineering a Neural Network's Clever Solution to Binary Addition - Casey Primozic's Homepagecprimozic.net | @ameobea10cprimozic.net@ameobea10‚Ä¢Portfolio‚Ä¢Contact‚Ä¢Blog‚Ä¢Professional ExperienceReverse Engineering a Neural Network's Clever Solution to Binary AdditionSubscribe to Blog via RSS 

Training the Network


Unique Activation Functions


Dissecting the Model


The Network's Clever Solution

Summary



Epilogue

There's a ton of attention lately on massive neural networks with billions of parameters, and rightly so.  By combining huge parameter counts with powerful architectures like transformers and diffusion, neural networks are capable of accomplishing astounding feats.
However, even small networks can be surprisingly effective - especially when they're specifically designed for a specialized use-case.  As part of some previous work I did, I was training small (<1000 parameter) networks to generate sequence-to-sequence mappings and perform other simple logic tasks.  I wanted the models to be as small and simple as possible with the goal of building little interactive visualizations of their internal states.
After finding good success on very simple problems, I tried training neural networks to perform binary addition.  The networks would receive the bits for two 8-bit unsigned integers as input (converted the bits to floats as -1 for binary 0 and +1 for binary 1) and would be expected to produce properly-added output, including handling wrapping of overflows.
Training example in binary:

  01001011 + 11010110 -> 00100001

As input/output vectors for NN training:

  input:  [-1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1]
  output: [-1, -1, 1, -1, -1, -1, -1, 1]
What I hoped/imagined the network would learn internally is something akin to a binary adder circuit:










I expected that it would identify the relationships between different bits in the input and output, route them around as needed, and use the neurons as logic gates - which I'd seen happen in the past for other problems I tested.
Training the Network
To start out, I created a network with a pretty generous architecture that had 5 layers and several thousand parameters.  However, I wasn't sure even that was enough.  The logic circuit diagram above for the binary adder only handles a single bit; adding 8 bits to 8 bits would require a much larger number of gates, and the network would have to model all of them.
Additionally, I wasn't sure how the network would handle long chains of carries.  When adding 11111111 + 00000001, for example, it wraps and produces an output of 00000000.  In order for that to happen, the carry from the least-significant bit needs to propagate all the way through the adder to the most-significant bit.  I thought that there was a good chance the network would need at least 8 layers in order to facilitate this kind of behavior.
Even though I wasn't sure if it was going to be able to learn anything at all, I started off training the model.
I created training data by generating random 8-bit unsigned integers and adding them together with wrapping.  In addition to the loss computed during training of the network, I also added code to validate the network's accuracy on all 32,385 possible input combinations periodically during training to get a feel for how well it was doing overall.
After some tuning of hyperparameters like learning rate and batch size, I was surprised to see that the model was learning extremely well!  I was able to get it to the point where it was converging to perfect or nearly perfect solutions almost every training run.










I wanted to know what the network was doing internally to generate its solutions. The networks I was training were pretty severely overparameterized for the task at hand; it was very difficult to get a grasp of what they were doing through the tens of thousands of weights and biases. So, I started trimming the network down - removing layers and reducing the number of neurons in each layer.
To my continued surprise, it kept working! At some point perfect solutions became less common as networks become dependent on the luck of their starting parameters, but I was able to get it to learn perfect solutions with as few as 3 layers with neuron counts of 12, 10, and 8 respectively:
Layer (type)           Input Shape    Output shape  Param #
===========================================================
input1 (InputLayer)    [[null,16]]    [null,16]     0
___________________________________________________________
dense_Dense1 (Dense)   [[null,16]]    [null,12]     204
___________________________________________________________
dense_Dense2 (Dense)   [[null,12]]    [null,10]     130
___________________________________________________________
dense_Dense3 (Dense)   [[null,10]]    [null,8]      88
===========================================================
That's just 422 total parameters! I didn't expect that the network would be able to learn a complicated function like binary addition with that few.
It seemed too good to be true, to be honest, and I wanted to make sure I wasn't making some mistake with the way I was training the network or validating its outputs.  A review of my example generation code and training pipeline didn't reveal anything that looked off, so the next step was to actually take a look at the parameters after a successful training run.
Unique Activation Functions
One important thing to note at this point is the activation functions used for the different layers in the model.  Part of my previous work in this area consisted of designing and implementing a new activation function for use in neural networks with the goal of doing binary logic as efficiently as possible.  Among other things, it is capable of modeling any 2-input boolean function in a single neuron - meaning that it solves the XOR problem.
You can read about it in more detail in my other post, but here's what it looks like:

It looks a bit like a single period of a flattened sine wave, and it has a couple controllable parameters to configure how flat it is and how it handles out-of-range inputs.
For the models I was training for binary addition, all of them used this activation function (which I named Ameo) in the first layer and used tanh for all the other layers.
Dissecting the Model
Although the number of parameters was now pretty manageable, I couldn't discern what was going on just by looking at them. However, I did notice that there were lots of parameters that were very close to ""round"" values like 0, 1, 0.5, -0.25, etc.
Since lots of the logic gates I'd modeled previously were produced with parameters such as those, I figured that might be a good thing to focus on to find the signal in the noise.
I added some rounding and clamping that was applied to all network parameters closer than some threshold to those round values. I applied it periodically throughout training, giving the optimizer some time to adjust to the changes in between. After repeating several times and waiting for the network to converge to a perfect solution again, some clear patterns started to emerge:
layer 0 weights:
[[0         , 0         , 0.1942478 , 0.3666477, -0.0273195, 1         , 0.4076445 , 0.25     , 0.125    , -0.0775111, 0         , 0.0610434],
 [0         , 0         , 0.3904364 , 0.7304437, -0.0552268, -0.0209046, 0.8210054 , 0.5      , 0.25     , -0.1582894, -0.0270081, 0.125    ],
 [0         , 0         , 0.7264696 , 1.4563066, -0.1063093, -0.2293   , 1.6488117 , 1        , 0.4655252, -0.3091895, -0.051915 , 0.25     ],
 [0.0195805 , -0.1917275, 0.0501585 , 0.0484147, -0.25     , 0.1403822 , -0.0459261, 1.0557909, -1       , -0.5      , -0.125    , 0.5      ],
 [-0.1013674, -0.125    , 0         , 0        , -0.4704586, 0         , 0         , 0        , 0        , -1        , -0.25     , -1       ],
 [-0.25     , -0.25     , 0         , 0        , -1        , 0         , 0         , 0        , 0        , 0.2798074 , -0.5      , 0        ],
 [-0.5      , -0.5226266, 0         , 0        , 0         , 0         , 0         , 0        , 0        , 0.5       , -1        , 0        ],
 [1         , -0.9827325, 0         , 0        , 0         , 0         , 0         , 0        , 0        , -1        , 0         , 0        ],
 [0         , 0         , 0.1848682 , 0.3591821, -0.026541 , -1.0401837, 0.4050815 , 0.25     , 0.125    , -0.0777296, 0         , 0.0616584],
 [0         , 0         , 0.3899804 , 0.7313382, -0.0548765, -0.021433 , 0.8209481 , 0.5      , 0.25     , -0.156925 , -0.0267142, 0.125    ],
 [0         , 0         , 0.7257989 , 1.4584024, -0.1054092, -0.2270812, 1.6465081 , 1        , 0.4654536, -0.3099159, -0.0511372, 0.25     ],
 [-0.125    , 0.069297  , -0.0477796, 0.0764982, -0.2324274, -0.1522287, -0.0539475, -1       , 1        , -0.5      , -0.125    , 0.5      ],
 [-0.1006763, -0.125    , 0         , 0        , -0.4704363, 0         , 0         , 0        , 0        , -1        , -0.25     , 1        ],
 [-0.25     , -0.25     , 0         , 0        , -1        , 0         , 0         , 0        , 0        , 0.2754751 , -0.5      , 0        ],
 [-0.5      , -0.520548 , 0         , 0        , 0         , 0         , 0         , 0        , 0        , 0.5       , 1         , 0        ],
 [-1        , -1        , 0         , 0        , 0         , 0         , 0         , 0        , 0        , -1        , 0         , 0        ]]

layer 0 biases:
[0          , 0         , -0.1824367,-0.3596431, 0.0269886 , 1.0454538 , -0.4033574, -0.25    , -0.125   , 0.0803178 , 0         , -0.0613749]
Above are the final weights generated for the first layer of the network after the clamping and rounding. Each column represents the parameters for a single neuron, meaning that the first 8 weights from top to bottom are applied to bits from the first input number and the next 8 are applied to bits from the second one.
All of these neurons have ended up in a very similar state. There is a pattern of doubling the weights as they move down the line and matching up weights between corresponding bits of both inputs. The bias was selected to match the lowest weight in magnitude. Different neurons had different bases for the multipliers and different offsets for starting digit.
The Network's Clever Solution
After puzzling over that for a while, I eventually started to understand how its solution worked.
Digital to analog converters (DACs) are electronic circuits that take digital signals split into multiple input bits and convert them into a single analog output signal.
DACs are used in applications like audio playback where a sound files are represented by numbers stored in memory. DACs take those binary values and convert them to an analog signal which is used to power the speakers, determining their position and vibrating the air to produce sound. For example, the Nintendo Game Boy had a 4-bit DAC for each of its two output audio channels.
Here's an example circuit diagram for a DAC:










If you look at the resistances of the resistors attached to each of the bits of the binary input, you can see that they double from one input to another from the least significant bit to the most significant.  This is extremely similar to what the network learned to do with the weights of the input layer.  The main difference is that the weights are duplicated between each of the two 8-bit inputs.
This allows the network to both sum the inputs as well as convert the sum to analog all within a single layer/neuron and do it all before any activation functions even come into play.
This was only part of the puzzle, though.  Once the digital inputs were converted to analog and summed together, they were immediately passed through the neuron's activation function.  To help track down what happened next, I plotted the post-activation outputs of a few of the neurons in the first layer as the inputs increased:

The neurons seemed to be generating sine wave-like outputs that changed smoothly as the sum of the binary inputs increased.  Different neurons had different periods; the ones pictured above have periods of 8, 4, and 32 respectively.  Other neurons had different periods or were offset by certain distances.
There's something very remarkable about this pattern: they map directly to the periods at which different binary digits switch between 0 and 1 when counting in binary.  The least significant digit switches between 0 and 1 with a period of 1, the second with a period of 2, and so on to 4, 8, 16, 32, etc.  This means that for at least some of the output bits, the network had learned to compute everything it needed in a single neuron.
Looking at the weights of neurons in the two later layers confirms this to be the case.  The later layers are mostly concerned with routing around the outputs from the first layer and combining them.  One additional benefit that those layers provide is ""saturating"" the signals and making them more square wave-like - pushing them closer to the target values of -1 and 1 for all values.  This is the exact same property which is used in digital signal processing for audio synthesis where tanh is used to add distortion to sound for things like guitar pedals.
While playing around with this setup, I tried re-training the network with the activation function for the first layer replaced with sin(x) and it ends up working pretty much the same way.  Interestingly, the weights learned in that case are fractions of œÄ rather than 1.
For other output digits, the network learned to do some over clever things to generate the output signals it needed.  For example, it combined outputs from the first layer in such a way that it was able to produce a shifted version of the signal not present in any of the first-layer neurons by adding signals from other neurons with different periods together.  It worked out pretty well, more than accurate enough for the purpose of the network.
The sine-based version of the function learned by the network (blue) ends up being roughly equivalent to the function sin(1/2x + pi) (orange):










I have no idea if this is just another random mathematical coincidence or part of some infinite series or something, but it's very neat regardless.
Summary
So, in all, the network was accomplishing binary addition by:

Converting the binary inputs into ""analog"" using a version of a digital to audio converter implemented using the weights of the input layer
Mapping that internal analog signal into periodic sine wave-like signals using the Ameo activation function (even though that activation function isn't periodic)
Saturating the sine wave-like signal to make it more like a square wave so outputs are as close as possible to the expected values of -1 and 1 for all outputs

As I mentioned, before, I had imagined the network learning some fancy combination of logic gates to perform the whole addition process digitally, similarly to how a binary adder operates.  This trick is yet another example of neural networks finding unexpected ways to solve problems.
Epilogue
One thought that occurred to me after this investigation was the premise that the immense bleeding-edge models of today with billions of parameters might be able to be built using orders of magnitude fewer network resources by using more efficient or custom-designed architectures.
It's an exciting prospect to be sure, but my excitement is somewhat dulled because I was immediately reminded of The Bitter Lesson.  If you've not read it, you should read it now (it's very short); it really impacted the way I look at computing and programming.
Even if this particular solution was just a fluke of my network architecture or the system being modeled, it made me even more impressed by the power and versatility of gradient descent and similar optimization algorithms.  The fact that these very particular patterns can be brought into existence so consistently from pure randomness is really amazing to me.
I plan to continue my work with small neural networks and eventually create those visualizations I was talking about.  If you're interested, you can subscribe to my blog via RSS at the top of the page, follow me on Twitter @ameobea10, or Mastodon @ameo@mastodon.ameo.dev.

"
https://news.ycombinator.com/rss,GPT-3 Is the Best Journal I‚Äôve Ever Used,https://every.to/superorganizers/gpt-3-is-the-best-journal-you-ve-ever-used,Comments,"


GPT-3 Is the Best Journal I've Ever Used - Superorganizers - Every






































Subscribe





‚â°


About
Founders‚Äò Letter
Publications
Collections

Contact Us
Become a Sponsor
Login











Superorganizers




          GPT-3 Is the Best Journal I‚Äôve Ever Used
        
My slow and steady progression to living out the plot of the movie 'Her'

by Dan Shipper
January 13, 2023
‚ô• 192





Listen







This is a joke, but it's not entirely wrong either.





Sponsor Every

Do you run a software company looking to reach an audience of early-adopters? Consider sponsoring our smart long-form essays on tech, AI, and productivity:

ÔªøSponsor EveryÔªø


Want to hide ads? Become a subscriber

For the past few weeks, I‚Äôve been using GPT-3 to help me with personal development. I wanted to see if it could help me understand issues in my life better, pull out patterns in my thinking, help me bring more gratitude into my life, and clarify my values.I‚Äôve been journaling for 10 years, and I can attest that using AI is journaling on steroids.¬†To understand what it‚Äôs like, think of a continuum plotting levels of support you might get from different interactions:Talking to GPT-3 has a lot of the same benefits of journaling: it creates a written record, it never gets tired of listening to you talk, and it‚Äôs available day or night.¬†If you know how to use it correctly and you want to use it for this purpose, GPT-3 is pretty close, in a lot of ways, to being at the level of an empathic friend:If you know how to use it right, you can even push it toward some of the support you‚Äôd get from a coach or therapist. It‚Äôs not a replacement for those things, but given its rate of improvement, I could see it being a highly effective adjunct to them over the next few years.¬†People who have been using language models for much longer than I have seem to agree:
Nick@nickcammarata

Replying to @nickcammarata

@krismartens I'm afraid of seeming hyperbolic, but also don't want to lie or hide information. GPT-3 is really just an incredible therapist, and is able to uncover complex patterns in my thinking and distill clean narratives that helps me a lot. It's also a lot warmer than most therapists

July 17th 2020, 4:55am EST

6 Retweets36 Likes

(Nick is a researcher at OpenAI. He‚Äôs also into meditation and is generally a great follow on Twitter.)It sounds wild and weird, but I think language models can have a productive, supportive role in any personal development practice. Here‚Äôs why I think it works.Why chatbots are great for journalingJournaling is already an effective personal development practice.¬†It can help you get your thoughts out of your head, rendering them less scary. It shows you patterns in your thinking, which increases your self-awareness and makes it easier for you to change.It creates a record of your journey through life, which can tell you who you are at crucial moments. It can help you create a new narrative or storyline for life events so that you can make meaning out of them.It can also guide your focus toward emotional states like gratitude, or directions you want your life to go in, rather than letting you get swept up in whatever is currently going on in your life.¬†But journaling has a few problems. For one, it‚Äôs sometimes hard to sit down and do it. It can be difficult to stare at a blank page and know what to write. For another, sometimes it feels a little silly‚Äîis summarizing my day really worth something?Once you get over those hurdles, as a practice it tends to get stale. You don‚Äôt read through your old entries that often, so the act of writing down your thoughts and experiences doesn‚Äôt compound in the way that it should. The prompts you use often get old: one like, ‚ÄúWhat are you grateful for today?‚Äù might work for the first few weeks, but after a while you need something fresh in order for the question to feel genuine.You want your journal to feel like an intimate friend that you can confide in‚Äîsomeone who‚Äôs seen you in different situations and can reflect back to you what‚Äôs important in crucial moments. You want your journal to be personal to you, and the act of journaling to feel fresh and full of hope and possibility every time you do.Unfortunately, paper isn‚Äôt great at those things. But GPT-3 is.¬†Journaling in GPT-3 feels more like a conversation, so you don‚Äôt have to stare at a blank page or feel silly because you don‚Äôt know what to say. The way it reacts to you depends on what you say to it, so it‚Äôs much less likely to get stale or old. (Sometimes it does repeat itself, which is annoying but I think long-term solvable.) It can summarize things you‚Äôve said to it in new language that helps you look at yourself in a different light and reframe situations more effectively.¬†In this way, GPT-3 is a mashup of journaling and more involved forms of support like talking to a friend. It becomes a guide through your mind‚Äîone that shows unconditional positive regard and acceptance for whatever you‚Äôre feeling. It asks thoughtful questions, and doesn‚Äôt judge. It‚Äôs around 24/7, it never gets tired or sick, and it‚Äôs not very expensive.Let me tell you about how I use it, what its limitations are, and where I think it might be going.How I started with GPT-3 journalingI didn‚Äôt think of using GPT-3 in this way myself. I saw Nick Cammarata‚Äôs tweets about it over the years first. My initial reaction was a lot of skepticism mixed with some curiosity.¬†After we launched Lex and I got more interested in AI, I remembered those tweets and decided to play around for myself.¬†I started in the OpenAI playground‚Äîa text box where you input a prompt that tells GPT-3 how you want it to behave, and then interact with it:I had a bunch of ideas to start. I tried one from a Facebook PM, Mina Fahmi, whom I met at the AI hackathon I wrote about a few weeks ago. He suggested telling GPT-3 to take on a persona, and told me that he‚Äôd had great results asking it to be Socrates.GPT-3 as famous compassionate figureI started experimenting with prompts like this:The green messages are responses from GPT-3. I tried Socrates, the Buddha, Jesus, and a few others, and found I liked Socrates the best (apologies to my Christian and Buddhist readers). The GPT-3 version of him is effective at driving toward the root of an issue and helping you figure out small steps to take to resolve it.There‚Äôs a long tradition in various religions of visualizing and interacting with a divine, compassionate figure as a way of getting support‚Äîand this was a surprisingly successful alternative route to a similar experience.After a while, though, I became a little bored of Socrates. I‚Äôm a verified therapy nerd, so the obvious next step was to try asking GPT-3 to do interactions based on various therapy modalities.GPT-3 as therapy modality expertI tried asking GPT-3 to become a bot that‚Äôs well-versed in Internal Family Systems‚Äîa style of therapy that emphasizes the idea that the self is composed of many different parts or sub-personalities, and that a lot of growth comes from learning to understand and integrate those parts. It turns out, GPT-3 isn‚Äôt bad at that:ÔªøI also tried asking it to be a psychoanalyst and a cognitive behavioral therapist, both of which were interesting and useful. I even asked it to do Jungian dream interpretation:I don‚Äôt know what to make of the efficacy of dream interpretation in general, nor do I know what an actual Jungian might say about this interpretation. But I have found that having dreams reflected back to me in this way can help me understand some of what I‚Äôve been feeling day to day but haven‚Äôt been able to put into words.¬†GPT-3 as gratitude journalAnother thing I tried is asking GPT-3 to help me increase my sense of gratitude and joy‚Äîlike a better gratitude journal:You‚Äôll notice it starts by acting like a normal gratitude journal, asking me to list three things I‚Äôm grateful for. But once I respond, it probes about details of what you‚Äôre grateful for to get you past your stock answers and into the emotional experience of gratitude.¬†GPT-3 as values coachOne of my favorite therapy modalities is ACT‚Äîacceptance and commitment therapy‚Äîbecause I love its focus on values. ACT emphasizes helping people understand what‚Äôs most important to them and uses that knowledge to help them navigate difficult emotions and experiences in their lives.Values work is challenging because sometimes it‚Äôs hard to connect your day-to-day experiences to your values. So I wanted to see if GPT-3 could help.¬†This is one of the experiments I tried:This works well, and one of the cool things about it is how the prompt works. I took a sample therapy dialog from an ACT-focused values book that I love, Values in Therapy, and asked GPT-3 to generalize from that dialog to learn how to talk to me about values.It worked‚Äîsuccessfully guiding our conversation toward talking about what was most important to me. It‚Äôs not perfect, but it suggests interesting possibilities for things to try going forward.Problems and limitationsWhile I liked these early experiments, they had a few significant problems.First, the OpenAI playground isn‚Äôt designed to facilitate chats, so it‚Äôs hard to use. Second, it doesn‚Äôt record inputs between sessions, so I ended up having to re-explain myself every time I started a new session. Third, it sometimes gets repetitive and asks the same questions.These are solvable, though. I know because I built a solution: a web app with a chatbot interface that remembers what I say in every session so I never have to repeat myself.¬†¬†The bot lets me select a persona‚Äîlike Socrates or an Internal Family Systems therapist‚Äîwhich corresponds to the prompts above. Then I can have a conversation with it. It will help me work through something I‚Äôm dealing with, or set goals, or bring my attention to something I‚Äôm grateful for. It can even output and save a summary of the session to help me notice patterns in my thinking over time.¬†It‚Äôs still early and there are a lot of problems to fix, but I find myself gravitating toward it every day. I feel like I‚Äôm building up a record of myself and my patterns over time, and the more I write in it, the more it compounds.I‚Äôll be releasing the bot soon for paying Every members, so if you want access, make sure to subscribe.¬†What‚Äôs nextHere‚Äôs what I‚Äôve learned so far through all of these experiments with GPT-3 as a journaling tool.There is something innately appealing about  building a relationship with an empathetic friend that you can talk to any time. It‚Äôs comforting to know that it‚Äôs available, and it‚Äôs exciting to think about all of the different prompts you can experiment with to help it support you in the way you need.There is also something weird about all of this. Spilling your guts to a robot somehow cheapens the experience because it doesn‚Äôt cost much for a robot to tell you it understands you.¬†This mix of feelings is reflected in this Twitter thread by Rob Morris, the founder of a peer-to-peer support app called Koko:
Rob Morris@RobertRMorris

We provided mental health support to about 4,000 people ‚Äî using GPT-3. Here‚Äôs what happened üëá

January 6th 2023, 2:50pm EST

1k Retweets6k Likes

When people were using GPT-3 to help them provide support to peers, their responses were rated significantly more highly than responses that were generated by humans alone:
Rob Morris@RobertRMorris

Replying to @RobertRMorris

Messages composed by AI (and supervised by humans) were rated significantly higher than those written by humans on their own (p < .001). Response times went down 50%, to well under a minute.

January 6th 2023, 2:50pm EST

66 Retweets785 Likes

But they had to stop using the GPT-3 integration because people felt like getting a response from GPT-3 wasn‚Äôt genuine and ruined the experience.¬†Those feelings are understandable, but whether or not they ruin the experience depends on how the interaction is framed to you, and how familiar you are with these tools.I don‚Äôt think these objections will last over time for most people. It‚Äôs more likely a temporary result of contact with new technology. When you see a movie that you loved, does it cheapen the experience to know that you were touched by a set of pixels moving in the correct sequence over the course of a few hours? Obviously not, but if I had to bet, when movies were first introduced many people probably felt it was a cheaper version of a live performance experience.As these kinds of bots get more common, and we learn to interact with them and depend on them for different parts of our lives, we‚Äôll be less likely to feel that our interactions with them are cheap or stilted.(None of this, by the way, means that in-person interactions aren‚Äôt valuable anymore‚Äîjust that there‚Äôs probably more room for bot interactions in your life than you might realize.)If you're someone that's journaled for a long time, you'll find a lot of value in trying GPT-3 out as an alternative to your day-to-day practice. And if you've never journaled before this might be a good way to get started.I‚Äôll be experimenting with this a lot more over the coming weeks and months, and I‚Äôll be sharing everything I learn with you here. I‚Äôm excited for what‚Äôs next.




What did you think of this post?

Amazing
Good
Meh
Bad





Send Privately

      Your feedback has been saved anonymously. If you want it to be attributed to you, login or sign up.
    



Like this?Become a subscriber.
Subscribe ‚Üí
Or, learn more.




Read this next:








Superorganizers


Managing Your Manager
How Helping Your Manager Succeed Will Help You Succeed

‚ô• 173

          Mar 9, 2022
          by Brie Wolfson











Superorganizers


The Four Kinds of Side Hustles
The CEO of Kettle and Fire breaks down how he thinks about side business opportunities

‚ô• 411

          Sep 16, 2020
          by Justin Mares











Superorganizers


The Fall of Roam
I don‚Äôt use Roam anymore. Why?

‚ô• 208

          Feb 12, 2022
          by Dan Shipper











Napkin Math


In Defense of the Unoptimized Life
Give yourself the space to be inspired

‚ô• 189

          Jan 12, 2023
          by Evan Armstrong











Every


Introducing: Thesis
Meet some of the internet‚Äôs best writers in person

‚ô• 1
üîí 
          Jan 12, 2023
      






Comments







Post









Post



    You need to login before you can comment.
    Don't have an account? Sign up!














@nattaliehartwig
about 2 hours ago


Loved this, are any of your projects available to try?



‚ô° 0

      ¬∑
      Reply










‚úï
Thanks for reading Every!
Sign up for our daily email featuring the most interesting thinking (and thinkers) in tech.
Subscribe
Already a subscriber? Login




Contact Us ¬∑
            Become a Sponsor ¬∑
            Search ¬∑
            Terms

¬©2023 Every Media, Inc





"
https://news.ycombinator.com/rss,The Cab Ride I'll Never Forget,https://kentnerburn.com/the-cab-ride-ill-never-forget/,Comments,"





















The Cab Ride I'll Never Forget | Kent Nerburn













































































 









		Skip to content













					Kent Nerburn
				


				wandering, wondering, writing
			
 





About

Menu Toggle





Interviews


Photo Gallery


Books
Speaking | Book Clubs
Musings
Shop
Contact
Home
 







 










					Kent Nerburn
				


				wandering, wondering, writing
			
 







Main Menu

 









About

Menu Toggle

InterviewsBook Review: Native EchoesBooksBooks-oldContactDan and Grover talk about Indian MascotsDancing with the Gods: Reflections on Life and ArtKent Nerburn

Menu Toggle

Join our mailing listMusingsPhoto GalleryPrivacyShopSouth Dakota TravelogueSpeaking

Menu Toggle

Presentation OptionsSubscribeThe Cab Ride I‚Äôll Never Forget 

















 










The Cab Ride I'll Never Forget 




There was a time in my life twenty years ago when I was driving a cab for a living. It was a cowboy‚Äôs life, a gambler‚Äôs life, a life for someone who wanted no boss, constant movement and the thrill of a dice roll every time a new passenger got into the cab.What I didn‚Äôt count on when I took the job was that it was also a ministry. Because I drove the night shift, my cab became a rolling confessional. Passengers would climb in, sit behind me in total anonymity and tell me of their lives.We were like strangers on a train, the passengers and I, hurtling through the night, revealing intimacies we would never have dreamed of sharing during the brighter light of day. I encountered people whose lives amazed me, ennobled me, made me laugh and made me weep. And none of those lives touched me more than that of a woman I picked up late on a warm August night.I was responding to a call from a small brick fourplex in a quiet part of town. I assumed I was being sent to pick up some partiers, or someone who had just had a fight with a lover, or someone going off to an early shift at some factory for the industrial part of town.When I arrived at the address, the building was dark except for a single light in a ground-floor window. Under these circumstances, many drivers would just honk once or twice, wait a short minute, then drive away. Too many bad possibilities awaited a driver who went up to a darkened building at 2:30 in the morning.But I had seen too many people trapped in a life of poverty who depended on the cab as their only means of transportation. Unless a situation had a real whiff of danger, I always went to the door to find the passenger. It might, I reasoned, be someone who needs my assistance. Would I not want a driver to do the same if my mother or father had called for a cab?So I walked to the door and knocked.‚ÄúJust a minute,‚Äù answered a frail and elderly voice. I could hear the sound of something being dragged across the floor. After a long pause, the door opened. A small woman somewhere in her 80s stood before me. She was wearing a print dress and a pillbox hat with a veil pinned on it, like you might see in a costume shop or a Goodwill store or in a 1940s movie. By her side was a small nylon suitcase. The sound had been her dragging it across the floor.The apartment looked as if no one had lived in it for years. All the furniture was covered with sheets. There were no clocks on the walls, no knickknacks or utensils on the counters. In the corner was a cardboard box filled with photos and glassware.‚ÄúWould you carry my bag out to the car?‚Äù she said. ‚ÄúI‚Äôd like a few moments alone. Then, if you could come back and help me? I‚Äôm not very strong.‚ÄùI took the suitcase to the cab, then returned to assist the woman. She took my arm, and we walked slowly toward the curb. She kept thanking me for my kindness.‚ÄúIt‚Äôs nothing,‚Äù I told her. ‚ÄúI just try to treat my passengers the way I would want my mother treated.‚Äù‚ÄúOh, you‚Äôre such a good boy,‚Äù she said. Her praise and appreciation were almost embarrassing.When we got in the cab, she gave me an address, then asked, ‚ÄúCould you drive through downtown?‚Äù‚ÄúIt‚Äôs not the shortest way,‚Äù I answered.‚ÄúOh, I don‚Äôt mind,‚Äù she said. ‚ÄúI‚Äôm in no hurry. I‚Äôm on my way to a hospice.‚ÄùI looked in the rearview mirror. Her eyes were glistening. ‚ÄúI don‚Äôt have any family left,‚Äù she continued. ‚ÄúThe doctor says I should go there. He says I don‚Äôt have very long.‚ÄùI quietly reached over and shut off the meter. ‚ÄúWhat route would you like me to go?‚Äù I asked.For the next two hours we drove through the city. She showed me the building where she had once worked as an elevator operator. We drove through the neighborhood where she and her husband had lived when they had first been married. She had me pull up in front of a furniture warehouse that had once been a ballroom where she had gone dancing as a girl. Sometimes she would have me slow in front of a particular building or corner and would sit staring into the darkness, saying nothing.As the first hint of sun was creasing the horizon, she suddenly said, ‚ÄúI‚Äôm tired. Let‚Äôs go now.‚ÄùWe drove in silence to the address she had given me. It was a low building, like a small convalescent home, with a driveway that passed under a portico. Two orderlies came out to the cab as soon as we pulled up. Without waiting for me, they opened the door and began assisting the woman. They were solicitous and intent, watching her every move. They must have been expecting her; perhaps she had phoned them right before we left.I opened the trunk and took the small suitcase up to the door. The woman was already seated in a wheelchair.‚ÄúHow much do I owe you?‚Äù she asked, reaching into her purse.‚ÄúNothing,‚Äù I said.‚ÄúYou have to make a living,‚Äù she answered.‚ÄúThere are other passengers,‚Äù I responded.Almost without thinking, I bent and gave her a hug. She held on to me tightly. ‚ÄúYou gave an old woman a little moment of joy,‚Äù she said. ‚ÄúThank you.‚ÄùThere was nothing more to say. I squeezed her hand once, then walked out into the dim morning light. Behind me, I could hear the door shut. It was the sound of the closing of a life.I did not pick up any more passengers that shift. I drove aimlessly, lost in thought. For the remainder of that day, I could hardly talk. What if that woman had gotten an angry driver, or one who was impatient to end his shift? What if I had refused to take the run, or had honked once, then driven away? What if I had been in a foul mood and had refused to engage the woman in conversation? How many other moments like that had I missed or failed to grasp?We are so conditioned to think that our lives revolve around great moments. But great moments often catch us unawares. When that woman hugged me and said that I had brought her a moment of joy, it was possible to believe that I had been placed on earth for the sole purpose of providing her with that last ride.I do not think that I have ever done anything in my life that was any more important. 































 







Copyright ¬© 2023 Kent Nerburn | Powered by kincaid-burrows
 










































"
https://news.ycombinator.com/rss,Show HN: Sketch ‚Äì AI code-writing assistant that understands data content,https://github.com/approximatelabs/sketch,Comments,"








approximatelabs

/

sketch

Public




 

Notifications



 

Fork
    4




 


          Star
 163
  









        AI code-writing assistant that understands data content
      





163
          stars
 



4
          forks
 



 


          Star

  





 

Notifications












Code







Issues
0






Pull requests
0






Actions







Projects
0






Security







Insights



 
 



More


 


                  Code
 


                  Issues
 


                  Pull requests
 


                  Actions
 


                  Projects
 


                  Security
 


                  Insights
 







approximatelabs/sketch









This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.











main





Switch branches/tags










Branches
Tags














View all branches















View all tags













Name already in use









      A tag already exists with the provided branch name. Many Git commands accept both tag and branch names, so creating this branch may cause unexpected behavior. Are you sure you want to create this branch?



    Cancel

    Create








1
branch





6
tags







    Code
 







Local



 Codespaces



  










  Clone





            HTTPS
 
            GitHub CLI
 













        Use Git or checkout with SVN using the web URL.
    













      Work fast with our official CLI.
      Learn more.
    








    Open with GitHub Desktop






    Download ZIP



 
Sign In Required

                Please
                sign in
                to use Codespaces.
              



Launching GitHub Desktop

    If nothing happens, download GitHub Desktop and try again.
  




Launching GitHub Desktop

    If nothing happens, download GitHub Desktop and try again.
  




Launching Xcode

    If nothing happens, download Xcode and try again.
  





Launching Visual Studio Code
Your codespace will open once ready.
There was a problem preparing your codespace, please try again.










Latest commit






 




bluecoconut

update readme wording




        ‚Ä¶
      




        9d567ec
      

Jan 16, 2023





update readme wording


9d567ec



Git stats







133

                      commits
                    







Files
Permalink




  
    Failed to load latest commit information.


  
 


Type
Name
Latest commit message
Commit time








.github/workflows



remove python 3.7, add tests, remove uneeded code



Dec 15, 2022









sketch



some bug fix and copy addition



Jan 16, 2023









tests



remove python 3.7, add tests, remove uneeded code



Dec 15, 2022









.gitignore



update with edit and work on text2sql



Oct 13, 2022









README.md



update readme wording



Jan 16, 2023









dev-requirements.txt



starting to rebuild sketch



Dec 15, 2022









pyproject.toml



rename to pandas extension, add missing requirement, use base64 encoding



Jan 11, 2023









setup.py



starting to rebuild sketch



Dec 15, 2022




    View code
 


















sketch
Demo
How to use
.sketch.ask
.sketch.howto
.sketch.apply
Sketch currently uses prompts.approx.dev to help run with minimal setup
How it works





README.md




sketch
Sketch is an AI code-writing assistant for pandas users that understands the context of your data, greatly improving the relevance of suggestions. Sketch is usable in seconds and doesn't require adding a plugin to your IDE.
pip install sketch
Demo
Here we follow a ""standard"" (hypothetical) data-analysis workflow, showing a Natural Language interace that successfully navigates many tasks in the data stack landscape.

Data Catalogging:

General tagging (eg. PII identification)
Metadata generation (names and descriptions)


Data Engineering:

Data cleaning and masking (compliance)
Derived feature creation and extraction


Data Analysis:

Data questions
Data visualization








sketch-demo.mp4





Try it out in colab: 
How to use
It's as simple as importing sketch, and then using the .sketch extension on any pandas dataframe.
import sketch
Now, any pandas dataframe you have will have an extension registered to it. Access this new extension with your dataframes name .sketch
.sketch.ask
Ask is a basic question-answer system on sketch, this will return an answer in text that is based off of the summary statistics and description of the data.
Use ask to get an understanding of the data, get better column names, ask hypotheticals (how would I go about doing X with this data), and more.
df.sketch.ask(""Which columns are integer type?"")
.sketch.howto
Howto is the basic ""code-writing"" prompt in sketch. This will return a code-block you should be able to copy paste and use as a starting point (or possibly ending!) for any question you have to ask of the data. Ask this how to clean the data, normalize, create new features, plot, and even build models!
df.sketch.howto(""Plot the sales versus time"")
.sketch.apply
apply is a more advanced prompt that is more useful for data generation. Use it to parse fields, generate new features, and more. This is built directly on lambdaprompt. In order to use this, you will need to set up a free account with OpenAI, and set an environment variable with your API key. OPENAI_API_KEY=YOUR_API_KEY
df['review_keywords'] = df.sketch.apply(""Keywords for the review [{{ review_text }}] of product [{{ product_name }}] (comma separated):"")
df['capitol'] = pd.DataFrame({'State': ['Colorado', 'Kansas', 'California', 'New York']}).sketch.apply(""What is the capitol of [{{ State }}]?"")
Sketch currently uses prompts.approx.dev to help run with minimal setup
In the future, we plan to update the prompts at this endpoint with our own custom foundation model, built to answer questions more accurately than GPT-3 can with its minimal data context.
You can also directly call OpenAI directly (and not use our endpoint) by using your own API key. To do this, set 2 environment variables.
(1) SKETCH_USE_REMOTE_LAMBDAPROMPT=False
(2) OPENAI_API_KEY=YOUR_API_KEY
How it works
Sketch uses efficient approximation algorithms (data sketches) to quickly summarize your data, and feed that information into language models. Right now it does this by summarizing the columns and writing these summary statistics as additional context to be used by the code-writing prompt. In the future we hope to feed these sketches directly into custom made ""data + language"" foundation models to get more accurate results.









About

      AI code-writing assistant that understands data content
    
Topics



  python


  data-science


  data


  ai


  tabular-data


  pandas


  df


  sketches


  dataframe


  copilot


  codex


  ds


  datasketches


  gpt3


  lambdaprompt


  datasketch



Resources





      Readme
 


Stars





163
    stars

Watchers





2
    watching

Forks





4
    forks







    Releases





6
tags







    Packages 0


        No packages published 







        Used by 22
 




























            + 14
          







    Contributors 2








bluecoconut
Justin Waugh

 






jmbiven
Mike Biven

 





Languages










Python
100.0%











"
https://news.ycombinator.com/rss,EasyPost (YC S13) Is Hiring,https://www.easypost.com/careers,Comments,"Careers at EasyPost - EasyPostSolutionsexpand_lessProductsDiscounted ShippingCreate a LabelShipping APISmartRate APITracking APIAddress Verification APIShipping InsuranceCarbon Offset APIPartner White Label APIUse CasesstoreSmall Businessshopping_cartEcommercestorefrontMarketplacelayersPlatformlocal_shippingFulfillmentPartnersFind a PartnerBecome a PartnerDevelopersexpand_lessGetting StartedAPI DocsClient LibrariesAPI StatusEngineering BlogCarriersCompanyexpand_lessBlogCase StudiesNewsletterAbout UsCareersHelp CenterContact SalesPricingSolutionschevron_rightDeveloperschevron_rightCarriersCompanychevron_rightPricingSolutionsSolve complex shipping logistics problems with a single integration.View All Solutionschevron_rightProductsDiscounted ShippingCreate a LabelShipping APISmartRate APITracking APIAddress Verification APIShipping InsuranceCarbon Offset APIPartner White Label APIPartnersFind a PartnerBecome a PartnerUse CasesstoreSmall Businessshopping_cartEcommercestorefrontMarketplacelayersPlatformlocal_shippingFulfillmentDevelopersAccess our developer resources and learn how to easily integrate with the EasyPost API.Getting StartedAPI DocsClient LibrariesAPI StatusEngineering BlogCompanyExplore our company resources to learn more about EasyPost and the shipping industry.BlogCase StudiesNewsletterAbout UsCareersHelp CenterContact SalesSign up freeLog inCareers at EasyPostOur team of problem solvers brings a modern approach to shipping logistics. We collaborate across departments, ask challenging questions, explore new solutions, and take accountability for our wins and mistakes.See all job openingsThe future of youAs industry experts, we're working not only to help our customers make sense of the industry, but to define where it's headed. We are looking for candidates who are approachable, dynamic, inventive, intelligent, and reliable to join our team in unpacking the future of shipping.Join usThe future of shippingHow can modern, flexible technology improve the customer experience of shipping? What if every business was able to offer same-day shipping? How much waste would be removed from the environment if all our shipments were consolidated into one delivery per week? At EasyPost, we're figuring out the answer to these questions and more.Join usLife at EasyPostlooks_oneAdaptiveEmbrace new challenges to grow your skill set.looks_twoSimpleCreate efficient solutions that are easy to execute.looks_3InclusiveShare new ideas and work collaboratively across teams.Team and technologyWe're a fun group of passionate entrepreneurs who built our own revolutionary software designed to make shipping simple. EasyPost started as an Engineering first company and we are proud to have a pragmatic approach to software development. Our team has a wealth of diverse experience and different backgrounds ranging from startups to large technology companies.Be part of a leading technology company:CI/CD inspired workflows - we deploy dozens of times a daySmall services over monoliths - we've deployed hundreds of servicesStrong engineering tooling and developer supportTransparency and participation around architecture and technology decisionsCulture of blamelessness and improving today from yesterday's shortcomingsCheck out our engineering blogSee openingsBenefits and perksmedical_servicesMedical, dental, vision plansaccess_timeFlexible time-offauto_graphStock option opportunitiessavings401(k) matchsupervisor_accountCross-functional learningtodayMonthly virtual eventsIn the past 3 years, I've learned a staggering amount from our colleagues and have had the best experience of my career thus far.When I work in this type of environment, with such talented and knowledgeable teammates, I really thrive and am extremely motivated to help make EasyPost more successful.Kyle GravesEngineering @ EasyPostStart your adventure at EasyPost¬© Simpler Postage 2023SolutionsPricingCarriersDiscounted shippingCode-free label creationShipping APISmartRate APITracking APIAddress verificationShipping insuranceCarbon Offset APIPartner White Label APIPartnersDevelopersGuidesAPI DocsClient librariesEngineering blogStatusContact usTalk to supportContact salesCompanyAbout usBlogCareersCase studiesNewsletterPrivacy & termsSupport¬© Simpler Postage 2023Switch to Desktop Versioneasypost-web-202301132331-5e82544d2f-master"
https://news.ycombinator.com/rss,Speeding up the JavaScript ecosystem part 2 ‚Äì Module Resolution,https://marvinh.dev/blog/speeding-up-javascript-ecosystem-part-2/,Comments,"


Speeding up the JavaScript ecosystem - module resolution

written by@marvinhagemeist15 January 2023


üìñ tl;dr: Whether you‚Äôre building, testing and/or linting JavaScript, module resolution is always at the heart of everything. Despite its central place in our tools, not much time has been spent on making that aspect fast. With the changes discussed in this blog post tools can be sped up by as much as 30%.

In part 1 of this series we found a few ways to speed various libraries used in JavaScript tools. Whilst those low level patches moved the total build time number by a good chunk, I was wondering if there is something more fundamental in our tooling that can be improved. Something that has a greater impact on the total time of common JavaScript tasks like bundling, testing and linting.
So over the next couple of days I collected about a dozen CPU profiles from various tasks and tools that are commonly used in our industry. After a bit of inspection, I came across a repeating pattern that was present in every profile I looked at and affected the total runtime of these tasks by as much as 30%. It‚Äôs such a critical and influential part of our infrastructure that it deserves to have its own blog post.
That critical piece is called module resolution. And in all the traces I looked at it took more time in total than parsing source code.
The cost of capturing stack traces
It all started when I noticed that the most time consuming aspect in those traces was spent in captureLargerStackTrace an internal node function responsible for attaching stack traces to Error objects. That seemed a bit out of the ordinary, given that both tasks succeeded without showing any signs of errors being thrown.


							After clicking through a bunch of occurrences in the profiling data a clearer picture emerged as to what was happening. Nearly all of the error creations came from calling node‚Äôs native fs.statSync() function and that in turn was called inside a function called isFile. The documentation mentions that fs.statSync() is basically the equivalent to POSIX‚Äôs fstat command and commonly used to check if a path exists on disk, is a file or a directory. With that in mind we should only get an error here in the exceptional use case when the file doesn‚Äôt exist, we lack permissions to read it or something similar. It was time to take a peek at the source of isFile.
						
function isFile(file) {	try {		const stat = fs.statSync(file);		return stat.isFile() || stat.isFIFO();	} catch (err) {		if (err.code === ""ENOENT"" || err.code === ""ENOTDIR"") {			return false;		}		throw err;	}}
From a quick glance it‚Äôs an innocent looking function, but was showing up in traces nonetheless. Noticeably, we ignore certain error cases and return false instead of forwarding the error. Both the ENOENT and ENOTDIR error codes ultimately mean that the path doesn‚Äôt exist on disk. Maybe that‚Äôs the overhead we‚Äôre seeing? I mean we‚Äôre immediately ignoring those errors here. To test that theory I logged out all the errors that the try/catch-block caught. Low and behold every single error that was thrown was either a ENOENT code or an ENOTDIR code.

							A peek into node‚Äôs documentation of fs.statSync reveals that it supports passing a throwIfNoEntry option that prevents errors from being thrown when no file system entry exists. Instead it will return undefined in that case.
						
function isFile(file) {	const stat = fs.statSync(file, { throwIfNoEntry: false });	return stat !== undefined && (stat.isFile() || stat.isFIFO());}
Applying that option allows us to get rid of the if-statment in the catch block which in turn makes the try/catch redundant and allows us to simplify the function even further.
This single change reduced the time to lint the project by 7%. What‚Äôs even more awesome is that tests got a similar speedup from the same change too.
The file system is expensive
With the overhead of stack traces of that function being eliminated, I felt like there was still more to it. You know, throwing a couple of errors shouldn‚Äôt really show up at all in traces captured over the span of a couple of minutes. So I injected a simple counter into that function to get an idea how frequently it was called. It became apparent that it was called about 15k times, about 10x more than there were files in the project. That smells like an opportunity for improvement.
To module or not to module, that is the question
By default there are three kind of specifiers for a tool to know about:

Relative module imports: ./foo, ../bar/boof
Absolute module imports: /foo, /foo/bar/bob
Package imports foo, @foo/bar

The most interesting of the three from a performance perspective is the last one. Bare import specifiers, the ones that don‚Äôt start with a dot . or with a slash /, are a special kind of import that typically refer to npm packages. This algorithm is described in depth in node‚Äôs documentation. The gist of it is that it tries to parse the package name and then it will traverse upwards to check if a special node_modules directory is present that contains the module until it reaches the root of the file system. Let‚Äôs illustrate that with an example.
Let‚Äôs say that we have a file located at /Users/marvinh/my-project/src/features/DetailPage/components/Layout/index.js that tries to import a module foo. The algorithm will then check for the following locations.

/Users/marvinh/my-project/src/features/DetailPage/components/Layout/node_modules/foo/
/Users/marvinh/my-project/src/features/DetailPage/components/node_modules/foo/
/Users/marvinh/my-project/src/features/DetailPage/node_modules/foo/
/Users/marvinh/my-project/src/features/node_modules/foo/
/Users/marvinh/my-project/src/node_modules/foo/
/Users/marvinh/my-project/node_modules/foo/
/Users/marvinh/node_modules/foo/
/Users/node_modules/foo/

That‚Äôs a lot of file system calls. In a nutshell every directory will be checked if it contains a module directory. The amount of checks directly correlates to the number of directories the importing file is in. And the problem is that this happens for every file where foo is imported. Meaning if foo is imported in a file residing somewhere else, we‚Äôll crawl the whole directory tree upwards again until we find a node_modules directory that contains the module. And that‚Äôs an aspect where caching the resolved module greatly helps.
But it gets even better! Lots of projects make use of path mapping aliases to save a little bit of typing, so that you can use the same import specifiers everywhere and avoid lots of dots ../../../. This is typically done via TypeScript‚Äôs paths compiler option or a resolve alias in a bundler. The problem with that is that these typically are indistinguishable from package imports. If I add a path mapping to the features directory at /Users/marvinh/my-project/src/features/ so that I can use an import declaration like import {...} from ‚Äúfeatures/DetailPage‚Äù, then every tool should know about this.
But what if it doesn‚Äôt? Since there is no centralized module resolution package that every JavaScript tool uses, they are multiple competing ones with various levels of features supported. In my case the project makes heavy use of path mappings and it included a linting plugin that wasn‚Äôt aware of the path mappings defined in TypeScript‚Äôs tsconfig.json. Naturally, it assumed that features/DetailPage was referring to a node module, which led it to do the whole recursive upwards traversal dance in hopes of finding the module. But it never did, so it threw an error.
Caching all the things
Next I enhanced the logging to see how many unique file paths the function was called with and if it always returned the same result. Only about 2.5k calls to isFile had a unique file path and there was a strong 1:1 mapping between the passed file argument and the returned value. It‚Äôs still more than the amount of files in the project, but it‚Äôs much lower than the total 15k times it was called. What if we added a cache around that to avoid reaching out to the file system?
const cache = new Map();function resolve(file) {	const cached = cache.get(file);	if (cached !== undefined) return cached;	// ...existing resolution logic here	const resolved = isFile(file);	cache.set(file, resolved);	return file;}
The addition of a cache sped up the total linting time by another 15%. Not bad! The risky bit about caching though is that they might become stale. There is a point in time where they usually have to be invalidated. Just to be on the safe side I ended up picking a more conservative approach that checks if the cached file still exists. This is not an uncommon thing to happen if you think of tooling often being run in watch mode where it‚Äôs expected to cache as much as possible and only invalidate the files that changed.
const cache = new Map();function resolve(file) {	const cached = cache.get(file);	// A bit conservative: Check if the cached file still exists on disk to avoid	// stale caches in watch mode where a file could be moved or be renamed.	if (cached !== undefined && isFile(file)) {		return cached;	}	// ...existing resolution logic here	for (const ext of extensions) {		const filePath = file + ext;		if (isFile(filePath)) {			cache.set(file, filePath);			return filePath;		}	}	throw new Error(`Could not resolve ${file}`);}
I was honestly expecting it to nullify the benefits of adding a cache in the first place since we‚Äôre reaching to the file system even in the cached scenario. But looking at the numbers this only worsened the total linting time only by 0.05%. That‚Äôs a very minor hit in comparison, but shouldn‚Äôt the additional file system call matter more?
The file extension guessing game
The thing with modules in JavaScript is that the language didn‚Äôt have a module system from the get go. When node.js came onto the scene it popularized the CommonJS module system. That system has several ‚Äúcute‚Äù features like the ability to omit the extension of the file you‚Äôre loading. When you write a statement like require(""./foo"") it will automatically add the .js extension and try to read the file at ./foo.js. If that isn‚Äôt present it will check for json file ./foo.json and if that isn‚Äôt available either, it will check for an index file at ./foo/index.js.
Effectively we‚Äôre dealing with ambiguity here and the tooling has to make sense of what ./foo should resolve to. With that there is a high chance of doing wasted file system calls as there is no way of knowing where to resolve the file to, in advance. Tools literally have to try each combination until they find a match. This is worsened if we look at the total amount of possible extensions that exist today. Tools typically have an array of potential extensions to check for. If you include TypeScript the full list for a typical frontend project at the time of this writing is:
const extensions = [	"".js"",	"".jsx"",	"".cjs"",	"".mjs"",	"".ts"",	"".tsx"",	"".mts"",	"".cts"",];
That‚Äôs 8 potential extensions to check for. And that‚Äôs not all. You essentially have to double that list to account for index files which could resolve to all those extensions too! This means that our tools have no other option, other than looping through the list of extensions until we find one that exists on disk. When we want to resolve ./foo and the actual file is foo.ts, we‚Äôd need to check:

foo.js -> doesn‚Äôt exist
foo.jsx -> doesn‚Äôt exist
foo.cjs -> doesn‚Äôt exist
foo.mjs -> doesn‚Äôt exist
foo.ts -> bingo!

That‚Äôs four unnecessary file system calls. Sure you could change the order of the extensions and put the most common ones in your project at the start of the array. That would increase the chances of the correct extension to be found earlier, but it doesn‚Äôt eliminate the problem entirely.
As part of the ES2015 spec a new module system was proposed. All the details weren‚Äôt fleshed out in time, but the syntax was. Import statements quickly took over as they have very benefits over CommonJS for tooling. Due to its staticness it opened up the space for lots more tooling enhanced features like most famously tree-shaking where unused modules and or even functions in modules can be easily detected and dropped from the production build. Naturally, everyone jumped on the new import syntax.
There was one problem though: Only the syntax was finalized and not how the actual module loading or resolution should work. To fill that gap, tools re-used the existing semantics from CommonJS. This was good for adoption as porting most code bases only required syntactical changes and these could be automated via codemods. This was a fantastic aspect from an adoption point of view! But that also meant that we inherited the guessing game of which file extension the import specifier should resolve to.
The actual spec for module loading and resolution was finalized years later and it corrected this mistake by making extensions mandatory.
// Invalid ESM, missing extension in import specifierimport { doSomething } from ""./foo"";// Valid ESMimport { doSomething } from ""./foo.js"";
By removing this source of ambiguity and always adding an extension, we‚Äôre avoiding an entire class of problems. Tools get way faster too. But it will take time until the ecosystem moves forward on that or if at all, since tools have adapted to deal with the ambiguity.
Where to go from here?
Throughout this whole investigation I was a bit surprised to find that much room for improvement in regards to optimizing module resolution, given that it‚Äôs such a central in our tools. The few changes described in this article reduced the linting times by 30%!
The few optimizations we did here are not unique to JavaScript either. Those are the same optimizations that can be found in toolings for other programming languages. When it comes to module resolution the four main takeaways are:

Avoid calling out to the file system as much as possible
Cache as much as you can to avoid calling out to the file system
When you're using fs.stat or fs.statSync always set the throwIfNoEntry: false
Limit upwards traversal as much as possible

The slowness in our tooling wasn‚Äôt caused by JavaScript the language, but by things just not being optimized at all. The fragmentation of the JavaScript ecosystem doesn't help either as there isn‚Äôt a single standard package for module resolution. Instead, there are multiple and they all share a different subset of features. That‚Äôs no surprise though as the list of features to support has grown over the years and there is no single library out there that supports them all at the time of this writing. Having a single library that everyone uses would make solving this problem once and for all for everyone a lot easier.


"
https://news.ycombinator.com/rss,Servo to Advance in 2023,https://servo.org/blog/2023/01/16/servo-2023/,Comments,"














          How to start
        

          Contributing
        

          Blog
        

          Governance
        




GitHub





Twitter





Mastodon








Servo to Advance in 2023
(2023-01-16) A brief update on the Servo project's renewed activity in 2023.

We would like to share some exciting news about the Servo project. This year, thanks to new external funding, a team of developers will be actively working on Servo. The first task is to reactivate the project and the community around it, so we can attract new collaborators and sponsors for the project.
The focus for 2023 is to improve the situation of the layout system in Servo, with the initial goal of getting basic CSS2 layout working. Given the renewed activity in the project, we will keep you posted with more updates throughout the year. Stay tuned!
About Servo 


Created by Mozilla Labs in 2012, the Servo project is a Research & Development effort meant to create an independent, modular, embeddable web engine that allows developers to deliver content and applications using web standards.  Servo is an experimental browser engine written in Rust, taking advantage of the memory safety properties and concurrency features of the language.  Stewardship of Servo moved from Mozilla Labs to the Linux Foundation in 2020, where its mission remains unchanged.


Back



"
https://news.ycombinator.com/rss,"Show HN: Terra Firma, a playable erosion simulation",https://store.steampowered.com/app/1482770/Terra_Firma/,Comments,"





Terra Firma on Steam























































									Login								

		Store	

Home
Discovery Queue
Wishlist
Points Shop
News
Stats


			Community		

Home
Discussions
Workshop
Market
Broadcasts


		Support	


									Change language								

										View desktop website									





								¬© Valve Corporation. All rights reserved. All trademarks are property of their respective owners in the US and other countries.								
Privacy Policy
									¬†| ¬†Legal
									¬†| ¬†Steam Subscriber Agreement
									¬†| ¬†Refunds








































		STORE	

Home
Discovery Queue
Wishlist
Points Shop
News
Stats


			COMMUNITY		

Home
Discussions
Workshop
Market
Broadcasts


				ABOUT			

		SUPPORT	






							Install Steam						

login
											¬†|¬†
						language


ÁÆÄ‰Ωì‰∏≠Êñá (Simplified Chinese)
ÁπÅÈ´î‰∏≠Êñá (Traditional Chinese)
Êó•Êú¨Ë™û (Japanese)
ÌïúÍµ≠Ïñ¥ (Korean)
‡πÑ‡∏ó‡∏¢ (Thai)
–ë—ä–ª–≥–∞—Ä—Å–∫–∏ (Bulgarian)
ƒåe≈°tina (Czech)
Dansk (Danish)
Deutsch (German)
Espa√±ol - Espa√±a (Spanish - Spain)
Espa√±ol - Latinoam√©rica (Spanish - Latin America)
ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨ (Greek)
Fran√ßais (French)
Italiano (Italian)
Magyar (Hungarian)
Nederlands (Dutch)
Norsk (Norwegian)
Polski (Polish)
Portugu√™s (Portuguese - Portugal)
Portugu√™s - Brasil (Portuguese - Brazil)
Rom√¢nƒÉ (Romanian)
–†—É—Å—Å–∫–∏–π (Russian)
Suomi (Finnish)
Svenska (Swedish)
T√ºrk√ße (Turkish)
Ti·∫øng Vi·ªát (Vietnamese)
–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ (Ukrainian)
Report a translation problem


















								Cart								(0)
							









Your Store
Your Store






										Home									

                                            Community Recommendations                                        

										Recently Viewed									

                                            Steam Curators                                        





New & Noteworthy
New & Noteworthy






											Steam Replay 2022										

											Top Sellers										

											Most Played										

										New & Trending                                    

										Special Offers									

                                        Recently Updated                                    

                                        Popular Upcoming                                    





Categories
Categories






Special Sections

														Free to Play													

Demos


														Early Access													

Controller-Friendly


Remote Play


                                                Software											

												Soundtracks											

VR Titles


VR Hardware


Steam Deck


Great on Deck


													macOS												

													SteamOS + Linux												

For PC Caf√©s




													Genres
												

														Action													


															Action														


Arcade & Rhythm
Fighting & Martial Arts
First-Person Shooter
Hack & Slash
Platformer & Runner
Third-Person Shooter
shmup


														Adventure													


															Adventure														


Adventure RPG
Casual
Hidden Object
Metroidvania
Puzzle
Story-Rich
Visual Novel

 




														Role-Playing													


															Role-Playing														


Action RPG
Adventure RPG
JRPG
Party-Based
Rogue-Like
Strategy RPG
Turn-Based


														Simulation													


															Simulation														


Building & Automation
Dating
Farming & Crafting
Hobby & Job
Life & Immersive
Sandbox & Physics
Space & Flight

 




														Strategy													


															Strategy														


Card & Board
City & Settlement
Grand & 4X
Military
Real-Time Strategy
Tower Defense
Turn-Based Strategy


														Sports & Racing													


															Sports & Racing														


All Sports
Fishing & Hunting
Individual Sports
Racing
Racing Sim
Sports Sim
Team Sports

 

														Themes													

														Themes													

Adult Only
Anime
Horror
Mystery & Detective
Open World
Sci-Fi & Cyberpunk
Space
Survival
 

														Player Support													

														Player Support													

Co-Operative
LAN
Local & Party
MMO
Multiplayer
Online Competitive
Singleplayer

 


Points Shop


News


Labs







































All Games
																					> Simulation Games
																				> Terra Firma







Community Hub



Terra Firma
















Terra Firma

Developer

Working as Intended 
Publisher

Working as Intended 
Released

											Jun 27, 2021										



								Play god and create your own world in this complex simulation. Plate tectonics, wind and water erosion and plant life all develop and interact to produce a world that is viewable from a single tree to kilometres across.							



Recent Reviews:

Very Positive

													(15)
												

												- 100% of the 15 user reviews in the last 30 days are positive.											



All Reviews:

Very Positive

													(214)
												

												- 92% of the 214 user reviews for this game are positive.											









Release Date:
Jun 27, 2021


Developer:

Working as Intended 


Publisher:

Working as Intended 




Tags

Popular user-defined tags for this product:


												Simulation												
												Strategy												
												God Game												
												Life Sim												
												Sandbox												
												3D												
												Nature												
												Destruction												
												Early Access												
												Relaxing												
												Physics												
												Singleplayer												+


Reviews


All Reviews:

Very Positive

													(92% of 214)¬†All Time




Recent Reviews:

Very Positive

													(100% of 15)¬†Recent




























































































































Sign in to add this item to your wishlist, follow it, or mark it as ignored














Links & info




Is this game relevant to you?


									Sign in to see reasons why you may or may not like this based on your games, friends, and curators you follow.
								

Sign In

																			or										Open in Steam

Features


Single-player 

Profile Features Limited¬†
										







								Languages:



		English	






Interface
Full Audio
Subtitles



				English			

‚úî 

‚úî 










Title: Terra Firma
Genre: Simulation, Strategy, Early Access

Developer:
Working as Intended


Publisher:
Working as Intended

Release Date: Jun 27, 2021
Early Access Release Date: Jun 27, 2021




mehwoot on Twitter



			View update history		

			Read related news		

			View discussions		

            Find Community Groups        





Share
Embed
¬†








Early Access Game
Get instant access and start playing; get involved with this game as it develops.
Note: This Early Access game is not complete and may or may not change further. If you are not excited to play this game in its current state, then you
									should wait to see if the game progresses further in development. Learn more


What the developers have to say:

Why Early Access?
										‚ÄúThis game is in early access in order to give people a chance to play and give feedback on our initial, working version whilst we continue to develop it.‚Äù

										Approximately how long will this game be in Early Access?
										‚Äú3 years‚Äù

										How is the full version planned to differ from the Early Access version?
										‚ÄúThe full version of the game will feature a greatly expanded simulation that builds on what is currently available.  Extra simulation layers related to the weather, such as temperature, air pressure, wind, ocean currents will provide a much richer set of interactions in the simulated world.

We expect to greatly expand the plants and animals that inhabit the world to provide a more interesting outcomes of the user's choice of geography.

The full version will have vastly better graphics than the current version, which uses only a minimum of graphical assets in order to release a playable version of the game.‚Äù

										What is the current state of the Early Access version?
										‚ÄúThe current early access version is fully playable, featuringWater and plate tectonic simulationsAbility to change the terrain at willDifferent types of plant life developing and responding to the geography of the worldAbility to view the world from the scale of a single tree to dozens of square kilometres at once‚Äù

										Will the game be priced differently during and after Early Access?
										‚ÄúWe plan to gradually raise the price as we ship new content and features.‚Äù

										How are you planning on involving the Community in your development process?
										‚ÄúWe'll be closely monitoring feedback from the community both from reviews and community content to decide what features should be added and how the game should be improved.‚Äù

																	 
Read more







				Play Terra Firma			



							Free						


Play Game








View Community Hub

¬†






See all discussions

Report bugs and leave feedback for this game on the discussion boards





About This Game
							Terra Firma gives you the power to play god in a simulated world where the forces of nature interact in complex ways.  Currently in early access, right now you canWatch water flow through the landscape, eroding and depositing the land to form complex arrangements of tributary river systems, river deltas, lakes and oceans in an emergent fashion.Observe the ecosystem respond to the availability of water.  Plants automatically gross across the lanscape with different plants thriving in different environments depending on the distribution of water, nutrients and the geometry of the land.Create your landscape using simulated plate tectonics, watching mountains form, grow and erode as millions of years pass in the blink of an eye.  Customize the landscape to your will, raising, lowering and flattening it to see how the enviornment changes as a resultZoom all the way from looking at an individual tree or plant to view the entire map across hundreds of square kilometresIn future releases, the game willAllow saving and loading worldsHave a fully simulated enviornment with not just water but also climate factors such as temperature, weather, ice, snow, wind and ocean currents forming and changing depending on the geography as well as affecting each otherFeature a wide variety and animal and plant species that flourish across the map according to the geography as well as each other.  Animals will populate accroding to the presence of either plants or other animals which they consume 


System Requirements




Minimum:OS: Windows 7+Memory: 2048 MB RAMGraphics: Dedicated Graphics Card 



Recommended:OS: Windows 7+Memory: 8096 MB RAMGraphics: Dedicated Graphics Card 









See all

More like this







View all
What Curators Say

					1 Curator has reviewed this product. Click here to see them.				








Customer reviews













Overall Reviews:
Very Positive
(214 reviews)









Recent Reviews:
Very Positive
(15 reviews)










Review Type



All¬†(214)

Positive¬†(199)

Negative¬†(15)




Purchase Type



All¬†(214)

Steam Purchasers¬†(0) 

Other¬†(214) 




Language



All Languages¬†(214)

Your Languages¬†(181) 
Customize




Date Range



							To view reviews within a date range, please click and drag a selection on a graph above or click on a specific bar.							
Show graph


Lifetime

Only Specific Range (Select on graph above)¬†

Exclude Specific Range (Select on graph above)¬†




Playtime



Brought to you by Steam Labs


							Filter reviews by the user's playtime when the review was written:						

No Minimum

Over 1 hour

No minimum to No maximum








Display As: 

Summary
Most Helpful
Recent
Funny



Off-topic Review Activity



							When enabled, off-topic review activity will be filtered out.  This defaults to your Review Score Setting. Read more about it in the blog post.						
Enabled




Show graph ¬†
Hide graph ¬†





Filters

Filters				




Excluding Off-topic Review Activity
Playtime: 






			Loading reviews...		


			Loading reviews...		


			Loading reviews...		


			Loading reviews...		


			Loading reviews...		














There are no more reviews that match the filters set above
Adjust the filters above to see other reviews













Loading reviews...









Review Filters




















You can use this widget-maker to generate a bit of HTML that can be embedded in your website to easily allow customers to purchase this game on Steam.
Enter up to 375 characters to add a description to your widget:




Create widget




Copy and paste the HTML below into your website to make the above widget appear




Link to the game's store pagehttps://store.steampowered.com/app/1482770/Terra_Firma/





Popular user-defined tags for this product:(?)




Sign In
Sign in to add your own tags to this product.


Sign In











 







¬© 2023 Valve Corporation.  All rights reserved.  All trademarks are property of their respective owners in the US and other countries.
VAT included in all prices where applicable.¬†¬†

            Privacy Policy
            ¬† | ¬†
            Legal
            ¬† | ¬†
            Steam Subscriber Agreement
            ¬† | ¬†
            Refunds
            ¬† | ¬†
            Cookies



View mobile website







About Valve
        ¬† | ¬†Jobs
        ¬† | ¬†Steamworks
        ¬† | ¬†Steam Distribution
        ¬† | ¬†Support
        		¬† | ¬†Gift Cards
		¬† | ¬† Steam
		¬† | ¬† @steam



 
 

"
https://news.ycombinator.com/rss,"ASCII table and history ‚Äì Or, why does Ctrl+i insert a Tab in my terminal?",https://bestasciitable.com,Comments,"




ASCII table and history (or, why does Ctrl+i insert a Tab in my terminal?)







ASCII table and history
Or, why does Ctrl+i insert a Tab in my terminal?



DecHexBinaryChar
00x0000 00000NUL
10x0100 00001SOH
20x0200 00010STX
30x0300 00011ETX
40x0400 00100EOT
50x0500 00101ENQ
60x0600 00110ACK
70x0700 00111BEL
80x0800 01000BS
90x0900 01001HT
100x0a00 01010LF
110x0b00 01011VT
120x0c00 01100FF
130x0d00 01101CR
140x0e00 01110SO
150x0f00 01111SI
160x1000 10000DLE
170x1100 10001DC1
180x1200 10010DC2
190x1300 10011DC3
200x1400 10100DC4
210x1500 10101NAK
220x1600 10110SYN
230x1700 10111ETB
240x1800 11000CAN
250x1900 11001EM
260x1a00 11010SUB
270x1b00 11011ESC
280x1c00 11100FS
290x1d00 11101GS
300x1e00 11110RS
310x1f00 11111US


DecHexBinaryChar
320x2001 00000SPACE
330x2101 00001!
340x2201 00010""
350x2301 00011#
360x2401 00100$
370x2501 00101%
380x2601 00110&
390x2701 00111'
400x2801 01000(
410x2901 01001)
420x2a01 01010*
430x2b01 01011+
440x2c01 01100,
450x2d01 01101-
460x2e01 01110.
470x2f01 01111/
480x3001 100000
490x3101 100011
500x3201 100102
510x3301 100113
520x3401 101004
530x3501 101015
540x3601 101106
550x3701 101117
560x3801 110008
570x3901 110019
580x3a01 11010:
590x3b01 11011;
600x3c01 11100<
610x3d01 11101=
620x3e01 11110>
630x3f01 11111?


DecHexBinaryChar
640x4010 00000@
650x4110 00001A
660x4210 00010B
670x4310 00011C
680x4410 00100D
690x4510 00101E
700x4610 00110F
710x4710 00111G
720x4810 01000H
730x4910 01001I
740x4a10 01010J
750x4b10 01011K
760x4c10 01100L
770x4d10 01101M
780x4e10 01110N
790x4f10 01111O
800x5010 10000P
810x5110 10001Q
820x5210 10010R
830x5310 10011S
840x5410 10100T
850x5510 10101U
860x5610 10110V
870x5710 10111W
880x5810 11000X
890x5910 11001Y
900x5a10 11010Z
910x5b10 11011[
920x5c10 11100\
930x5d10 11101]
940x5e10 11110^
950x5f10 11111_


DecHexBinaryChar
960x6011 00000`
970x6111 00001a
980x6211 00010b
990x6311 00011c
1000x6411 00100d
1010x6511 00101e
1020x6611 00110f
1030x6711 00111g
1040x6811 01000h
1050x6911 01001i
1060x6a11 01010j
1070x6b11 01011k
1080x6c11 01100l
1090x6d11 01101m
1100x6e11 01110n
1110x6f11 01111o
1120x7011 10000p
1130x7111 10001q
1140x7211 10010r
1150x7311 10011s
1160x7411 10100t
1170x7511 10101u
1180x7611 10110v
1190x7711 10111w
1200x7811 11000x
1210x7911 11001y
1220x7a11 11010z
1230x7b11 11011{
1240x7c11 11100|
1250x7d11 11101}
1260x7e11 11110~
1270x7f11 11111DEL



The binary representation has the most significant bit first
		(‚Äúbig endian‚Äù).

		ASCII is 7-bit; because many have called encodings such as 
		CP437,
		ISO-8859-1,
		CP-1252,
		and others ‚Äúextended ASCII‚Äù some are under the misapprehension that
		ASCII is 8-bit (1 byte).

Understanding ASCII (and terminals)


To understand why Control+i inserts a Tab in your terminal you need to understand
			ASCII, and to understand ASCII you need know a bit about its history and the world it
			was developed in. Please bear with me.
Teleprinters
Teleprinters evolved from the telegraph. Connect a printer and keyboard to a
			telegraph and you‚Äôve got a teleprinter. Early versions were called ‚Äúprinting
			telegraphs‚Äù.
Most teleprinters communicated using the ITA2 protocol. For the most part this would
			just encode the alphabet, but there are a few control codes: WRU (‚ÄúWho R U‚Äù) would cause
			the receiving teleprinter to send back its identification, BEL would ring a bell, and it
			had the familiar CR (Carriage Return) and LF (Line Feed).
This is all early 20th century stuff. There are no electronic computers; it‚Äôs all
			mechanical working with punched tape. ITA2 (and codes like it) were mechanically
			efficient; common letters such as ‚Äúe‚Äù and ‚Äút‚Äù required only a single hole to be
			punched.
These 5-bit codes could only encode 32 characters, which is not even enough for just
			English. The solution was to add the FIGS and LTRS codes, which would switch between
			‚Äúfigures‚Äù and ‚Äúletters‚Äù mode. ‚ÄúFIGS R W‚Äù would produce ‚Äú42‚Äù. This worked, but typo‚Äôing a
			FIGS or LTRS (or losing one in line noise) would result in gibberish. Not ideal.
Terminals
In the 1950s teleprinters started to get connected to computers, rather than other
			teleprinters. ITA2 was designed for mechanical machines and was awkward to use. ASCII
			was designed specifically for computer use and published in 1962. Teleprinters used with
			computers were called terminals (as in ‚Äúend of a connection‚Äù, like ‚Äútrain
			terminal‚Äù). Teleprinters were also called
			‚ÄúTeleTYpewriter‚Äù, or TTY for short, and you can still
			find names like /dev/tty or /bin/stty on modern systems.
People really programmed computers using teleprinters. Here‚Äôs a
			video of a teleprinter in action,
			and here‚Äôs a somewhat cheesy (but interesting and cute) video which explains how they
			were used to program a PDP 11/10.
A terminal would connect to a computer with a serial port
			(RS-232),
			which simply transfers bytes back and forth. A terminal is more akin to a monitor with a
			keyboard, rather than a computer on its own. A modern monitor connected with HDMI is
			told ‚Äúdraw this pixel in this colour‚Äù, in the 1960s the computer merely said ‚Äúhere are a
			bunch of characters‚Äù.
If you‚Äôre wondering what a ‚Äúshell‚Äù is: a shell is a program to interact with your
			computer. It provides a commandline, runs programs, and displays the result. The
			terminal just displays characters. It‚Äôs the difference between a TV and a DVD
			player.
Teleprinters needed some way to communicate events such as ‚Äústop sending me data‚Äù or
			‚Äúend of transmission‚Äù. This is what control characters are for. The exact meaning of
			control characters has varied greatly over the years (which is why extensive
			termcap databases
			are required). ASCII is more than just a character set; it‚Äôs a way to communicate
			between a terminal and a computer.
An additional method to communicate are
			escape sequences.
			This is a list of characters starting with the ESC control character (0x1b). For example
			F1 is <Esc>OP and the left arrow is <Esc>[OD.
			Computers can give instructions to terminals, too: <Esc>[2C is move
			the cursor 2 positions forward and <Esc>[4m underlines all subsequent
			text. This is also how the Alt key works: Alt+a is <Esc>a.
Modern systems and ASCII properties
All of this matters because modern terminals operate on the same principles as those
			of the 1960s. If you‚Äôre opening three xterm or iTerm2 windows then you‚Äôre emulating
			three terminals connecting to a ‚Äúmainframe‚Äù.
If you look at the ASCII table above then there are some interesting properties: in
			the 1st column you can see how the left two bits are always set to zero, and
			that the other 5 bits count to 31 (32 characters in total; it starts at 0). The
			2nd column repeats this pattern but with the 6th bit set to 1
			(remember, read binary numbers from right-to-left, so that‚Äôs 6th counting
			from the right). The 3rd column repeats this pattern again with the
			7th bit set, and the final column has both bits set.
The interesting part here is that the letters A-Z and some punctuation map directly
			to the control characters in the 1st column. All that‚Äôs needed is removing
			one bit, and that‚Äôs exactly what the Control key did: clear the 7th bit.
			Lowercase and uppercase letters align in the 3rd and 4th columns,
			and this is what the Shift key did: clear the 6th bit.
Pressing Control+i (lowercase) would mean sending ‚Äú)‚Äù, which is not very useful. So
			most terminals interpret this as Control+I (uppercase), which sends HT. DEL is last is
			so all bits are set to 1. This is how you ‚Äúdeleted‚Äù a character in punch tapes: punch
			all the holes!
This is kind of neat and well designed, but for us it means:

There is no way to see if the user pressed only Control or Shift, because from a
					terminal‚Äôs perspective all they do is modify a bit for the typed character.
There is no way to distinguish between the Tab key and Control+i. It‚Äôs not just
					‚Äòthe same‚Äô as Tab, Control+i is Tab.
There is no way to distinguish between Control+a and Control+Shift+a.
Sending Control with a character from the 2nd column is useless.
					Control clears the 7th bit, but this is already 0, so Control+# will
					just send ‚Äú#‚Äù.

The world has not completely stood still and there have been improvements since the
			1960s, but terminals are still fundamentally ASCII-based text interfaces, and programs
			running inside a terminal ‚Äì like a shell or Vim ‚Äì still have very limited facilities for
			modern key events. Non-terminal programs don‚Äôt have these problems as they‚Äôre not
			restricted to a 1960s text interface.
Note: for brevity‚Äôs sake many
			aspects have been omitted in the above: ITA2 was derived from Murray code, the 1967
			ASCII spec changed many aspects (1962 ASCII only had uppercase), there were other
			encodings (e.g. EBCDIC), graphical terminals such as the Tektronix 4014 (which xterm can
			emulate), ioctls, etc.
			References and further reading:
				An annotated history of some character codes,
				7-bit character sets,
				Control characters in ASCII and Unicode,
				The TTY demystified





Image 1, a printing telegraph produced in 1907. The
					alphabetically sorted piano keys are a great example of how the first generation
					of new innovations tends to resemble whatever already exists, and that it takes
					a few more innovations to really get the most out of it. This style of piano
					keyboards was introduced in the 1840s, and while the keyboard as we know it
					today was introduced in the 1870s, it took a while for it to replace all
					piano-style keyboards; this is probably among the last models that was
					made).



Image 2, the Teletype model 33 ASR, introduced in 1963. This is
					one first ASCII teleprinters. Note the machinery on the left; you could feed
					this with a punched tape to automatically type a program for you, similar to how
					you would now load a program from a disk.
					The Teletype model 33 was massively popular, and the brand name Teletype became
					synonymous with terminal.
				



Image 3, Ken Thompson working on the PDP-11 using a Teletype
					(model 33?). What always struck be about this image is the atrocious ergonomics
					of ‚Ä¶ everything. The keyboard, the chair, everything about the posture: it‚Äôs all
					terrible. Inventing Unix almost seems easy compared to dealing with
					that!



Image 4, DEC VT100, a kind of terminal that a terminal emulator
				such as xterm emulates. It has a visual display and supports the essential escape
				sequences still in use today. These were known as ‚Äúvisual terminals‚Äù, referring to
				the visual screen with characters, as opposed to printing them out.




Created by Martin Tournoij,
		because I‚Äôve had to explain ‚ÄúControl+i is Tab‚Äù once too many
		times and figured an in-depth explanation would be helpful.
Source on GitHub;
		PRs and issues welcome.

			Image credits:
			
				Image 1 by Science Museum; CC BY-NC-SA |
			
				Image 2 by AlisonW; CC BY-SA |
			
				Image 3 by Peter Hamer; CC BY-SA |
			
				Image 4 by Jason Scott; CC BY







"
https://news.ycombinator.com/rss,Granian ‚Äì a Rust HTTP server for Python applications,https://github.com/emmett-framework/granian,Comments,"








emmett-framework

/

granian

Public







 

Notifications



 

Fork
    9




 


          Star
 352
  









        A Rust HTTP server for Python applications
      
License





     BSD-3-Clause license
    






352
          stars
 



9
          forks
 



 


          Star

  





 

Notifications












Code







Issues
7






Pull requests
0






Discussions







Actions







Security







Insights



 
 



More


 


                  Code
 


                  Issues
 


                  Pull requests
 


                  Discussions
 


                  Actions
 


                  Security
 


                  Insights
 







emmett-framework/granian









This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.











master





Switch branches/tags










Branches
Tags














View all branches















View all tags













Name already in use









      A tag already exists with the provided branch name. Many Git commands accept both tag and branch names, so creating this branch may cause unexpected behavior. Are you sure you want to create this branch?



    Cancel

    Create








1
branch





13
tags







    Code
 







Local



 Codespaces



  










  Clone





            HTTPS
 
            GitHub CLI
 













        Use Git or checkout with SVN using the web URL.
    













      Work fast with our official CLI.
      Learn more.
    








    Open with GitHub Desktop






    Download ZIP



 
Sign In Required

                Please
                sign in
                to use Codespaces.
              



Launching GitHub Desktop

    If nothing happens, download GitHub Desktop and try again.
  




Launching GitHub Desktop

    If nothing happens, download GitHub Desktop and try again.
  




Launching Xcode

    If nothing happens, download Xcode and try again.
  





Launching Visual Studio Code
Your codespace will open once ready.
There was a problem preparing your codespace, please try again.










Latest commit






 




gi0baro

Update CI release workflow




        ‚Ä¶
      




        b843a90
      

Jan 13, 2023





Update CI release workflow


b843a90



Git stats







132

                      commits
                    







Files
Permalink




  
    Failed to load latest commit information.


  
 


Type
Name
Latest commit message
Commit time








.github



Update CI release workflow



Jan 13, 2023









benchmarks



Update benchmarks



Jan 13, 2023









docs/spec



Fix typos (#14)



Nov 17, 2022









granian



Follow WSGI spec on response iterable (#29)



Jan 13, 2023









lib/pyo3-asyncio



Bump pyo3-asyncio to 0.17



Oct 25, 2022









src



Code cleanup



Jan 13, 2023









tests



Fix wsgi.input out of spec (close #24)



Jan 12, 2023









.gitignore



first implementation



Apr 15, 2022









Cargo.lock



Add PyPy support



Jan 3, 2023









Cargo.toml



Add PyPy support



Jan 3, 2023









LICENSE



first implementation



Apr 15, 2022









README.md



Update benchmarks results



Dec 24, 2022









build.rs



Add PyPy support



Jan 3, 2023









pyproject.toml



Add PyPy support



Jan 3, 2023









setup.py



review package meta



Apr 18, 2022




    View code
 















Granian
Rationale
Features
Quickstart
Project status
License





README.md




Granian
A Rust HTTP server for Python applications.
Rationale
The main reasons behind Granian design are:

Have a single, correct HTTP implementation, supporting versions 1, 2 (and eventually 3)
Provide a single package for several platforms
Avoid the usual Gunicorn + uvicorn + http-tools dependency composition on unix systems
Provide stable performance when compared to existing alternatives

Features

Supports ASGI/3, RSGI and WSGI interface applications
Implements HTTP/1 and HTTP/2 protocols
Supports HTTPS
Supports Websockets over HTTP/1 and HTTP/2

Quickstart
You can install Granian using pip:
$ pip install granian

Create an ASGI application in your main.py:
async def app(scope, receive, send):
    assert scope['type'] == 'http'

    await send({
        'type': 'http.response.start',
        'status': 200,
        'headers': [
            [b'content-type', b'text/plain'],
        ],
    })
    await send({
        'type': 'http.response.body',
        'body': b'Hello, world!',
    })
and serve it:
$ granian --interface asgi main:app

You can also create an app using the RSGI specification:
async def app(scope, proto):
    assert scope.proto == 'http'

    proto.response_str(
        status=200,
        headers=[
            ('content-type', 'text/plain')
        ],
        body=""Hello, world!""
    )
and serve it using:
$ granian --interface rsgi main:app

Project status
Granian is currently under active development.
Granian is compatible with Python 3.7 and above versions on unix platforms and 3.8 and above on Windows.
License
Granian is released under the BSD License.









About

      A Rust HTTP server for Python applications
    
Topics



  python


  rust


  http


  http-server


  asyncio


  asgi



Resources





      Readme
 
License





     BSD-3-Clause license
    



Stars





352
    stars

Watchers





6
    watching

Forks





9
    forks







    Releases
      13







Granian 0.2.1

          Latest
 
Jan 13, 2023

 

        + 12 releases





Sponsor this project



¬†

 

 Sponsor
 
Learn more about GitHub Sponsors







    Packages 0


        No packages published 







        Used by 6
 




























    Contributors 4





¬†



¬†



¬†



¬†







Languages












Rust
83.1%







Python
16.5%







Other
0.4%











"
https://news.ycombinator.com/rss,Wikipedia editors serving long sentences in Saudi Arabia since 2020,https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2023-01-16/Special_report,Comments,"



Wikipedia:Wikipedia Signpost/2023-01-16/Special report - Wikipedia


































Wikipedia:Wikipedia Signpost/2023-01-16/Special report

From Wikipedia, the free encyclopedia
< Wikipedia:Wikipedia Signpost‚Äé | 2023-01-16


Jump to navigation
Jump to search
Coverage of 2022 bans reveals editors serving long sentences in Saudi Arabia since 2020: Long-time contributors imprisoned for 32 and 8 years after ""swaying public opinion"" and ""violating public morals"".

‚Üê Back to ContentsView Latest Issue16 January 2023
Special report
Coverage of 2022 bans reveals editors serving long sentences in Saudi Arabia since 2020


Contribute¬†¬†‚Äî¬†¬†
Share this


‚ÄÇPDF download
‚ÄÇE-mail
‚ÄÇFacebook
‚ÄÇTwitter
‚ÄÇLinkedIn
‚ÄÇReddit



By Andreas Kolbe and JPxG




Former Arabic Wikipedia administrators Osama Khalid (left) and Ziyad Alsufyani (right), both now in prison in Saudi Arabia.



Related articlesNation-state involvement

Missed and Dissed
28 November 2022
Editor given three-year sentence, big RfA makes news, Guy Standing takes it sitting down
26 June 2022
A net loss: Wikipedia attacked, closing off Russia? welcoming back Turkey?
30 September 2019
WMF staff turntable continues to spin; Endowment gets more cash; RfA continues to be a pit of steely knives
31 January 2019
Court-ordered article redaction, paid editing, and rock stars
1 December 2018





More articles





Wales in China; #Edit2015
16 December 2015
Russia temporarily blocks Wikipedia
26 August 2015
Turkish Wikipedia censorship; ""Can Wikipedia survive?""; PR editing
24 June 2015
China blocks secure version of Wikipedia
5 June 2013
French intelligence agents threaten Wikimedia volunteer
8 April 2013
Russian Wikipedia shuts down to fight censorship threat; E3 team and new tools; Wikitravel proposal bogged down
9 July 2012
Censorship, social media in schools, and more
30 March 2009







Wikipedians jailed for 32 and 8 years respectively
On January 5, 2023, we learnt that two Wikipedians, Osama Khalid (User:OsamaK) and Ziyad Alsufyani (User:Ziad), have been sitting in jail for more than two years, sentenced to serving 32 and eight years respectively in al-Ha'ir Prison, a Saudi Arabian maximum security facility. The offenses with which they were charged, according to the press release that broke the news, were ""swaying public opinion"" and ""violating public morals"".
The press release in question was published jointly by Democracy for the Arab World Now (DAWN, a human rights organisation co-founded by slain Saudi journalist Jamal Khashoggi) and Lebanese NGO Social Media Exchange (SMEX). It said that Osama and Ziyad had been arrested on the same day in 2020, and sentenced to 5 and 8 years respectively. In September 2022, Osama's sentence was increased to 32 years after an appeal was made; this reflects a recent trend in Saudi Arabia of imposing ever more draconian prison sentences for online criticism of the Saudi government, as reported by human rights organisation ALQST and The Washington Post. DAWN reports that in 2022, Saudi Arabia's Specialized Criminal Court sentenced women to 34 and 45 years of imprisonment for ""tweeting in support of reform"".
The DAWN/SMEX press release combined its report on Osama's and Ziyad's prison sentences with the news that the WMF had recently banned sixteen Wikipedians in the Middle East/North Africa region, including seven Arabic Wikipedia administrators, for alleged conflict-of-interest editing and advancing ""the aims of external parties"" (see Signpost coverage earlier this month).




DAWN (Democracy for the Arab World Now) was co-founded by murdered Saudi journalist Jamal Khashoggi


Internal Wikimedia Investigation Results in Termination of Entire Saudi-Based Team of Administrators
(January 5, 2023 ‚Äì New York and Beirut): The Saudi Arabian government infiltrated Wikipedia by recruiting the organization's highest ranked administrators in the country to serve as government agents to control information about the country and prosecuting those who contributed critical information about political detainees, said SMEX and Democracy for the Arab World Now (DAWN) today.

Following an internal investigation in 2022, Wikimedia terminated all of its Wikipedia administrators in Saudi Arabia in December. DAWN and SMEX documented Wikipedia's infiltration by the Saudi government based on interviews with sources close to Wikipedia and the imprisoned administrators.
The authors of the press release added:

It's wildly irresponsible for international organizations and businesses to assume their affiliates can ever operate independently of, or safely from, Saudi government control.
The DAWN/SMEX press release was quickly picked up by AFP, resulting in a spate of media reports led by The Guardian and Middle East Eye, followed the next day by Ars Technica and many others.
While these press articles followed the pattern set by DAWN and SMEX, covering the sixteen WMF bans and the imprisonment of the two editors together, it is unclear what connection there is between these two sets of events, or indeed if there is any connection at all. Ars Technica hypothesizes that the prior arrest of Osama and Ziyad may have been related to Saudi infiltration efforts that led to the bans. The Wikimedia Foundation's Trust & Safety office has stated that the December 2022 bans were unrelated to the 2020 arrests.

Who are the jailed Wikimedians?



Osama organized this Wikipedia medical training and editing event at King Saud bin Abdulaziz University for Health Sciences in 2015


Both were longstanding Wikimedia contributors. Osama's first contributions to the English and Arabic Wikipedias date back to 2007. All in all, he made over 870,000 contributions to Wikidata, over 19,000 to the English Wikipedia, around 16,500 to the Arabic Wikipedia, over 16,000 to Commons, over 5,000 to the Arabic Wiktionary, and nearly 800 to Meta-Wiki. 
Ziyad started editing Arabic Wikipedia in 2009, making over 20,000 edits to Wikidata, around 7,500 to Commons, about 6,500 to Arabic Wikipedia, and exactly 100 to English Wikipedia. As medical students, both were particularly involved in editing and translating medical topics in Wikipedia. The Wiki Project Med Foundation, a Wikimedia affiliate specialising in improving Wikimedia projects' coverage of medical topics, issued the following statement to The Signpost: 

Wiki Project Med appreciates the medical editing which Osama Khalid and Ziyad Alsufyani contributed to Wikipedia. They are both Wikimedia editors in good standing who have organized medical editing, training of physicians to edit Wikipedia's medical topics, and good community discussions about improving Wikipedia's coverage of medical topics for Arabic language. The arrest is shocking to us and beyond our understanding. We know nothing about this except that these two are friendly Wikipedia editors who have been highly engaged in our Wikimedia community activities.



Ziyad uploaded this picture of himself to Commons in 2015, with the description ""Arabic Wikipedian"".


Both attended Wikimedia conferences. Osama joined multiple Wikimania events in person, and participated in the medical meetups there (see images on Wikimedia Commons); he also organized the Translation task force, importing Wikipedia medical articles from English to Arabic (and from Arabic to English).

Wikimedia responses to press coverage
Responding to the media coverage, Wikimedia Foundation spokespeople highlighted ""material inaccuracies"" in the press release. According to Ars Technica, for example:

A Wikimedia spokesperson told Ars that there are ""material inaccuracies in the statement released by SMEX/DAWN"" and in a Guardian report. ""There was no finding in our investigation that the Saudi government 'infiltrated' or penetrated Wikipedia's highest ranks,"" Wikimedia's spokesperson told Ars. ""And there are in fact no 'ranks' among Wikipedia admins. There was also no reference to Saudis acting under the influence of the Saudi government in our investigation. While we do not know where these volunteers actually reside, the bans of any volunteers who may have been Saudi were part of a much broader action globally banning 16 editors across the MENA region.""
The Wikimedia Foundation also published a longer statement on the Wikimedia-l mailing list on 6 January, titled ""Recent press around December Office Action"": 

Hello everyone,
Over the last couple of days, there have been several media reports about
the Foundation‚Äôs most recent office action, taken on December 6.
More are certain to follow. These media reports are based on a release from
SMEX and Democracy for the Arab World Now (DAWN) that contains many
material inaccuracies. Some of the errors will be obvious to our community
‚Äì for perhaps the most obvious, the report states that the 16 users are all
based in Saudi Arabia. This is unlikely to be the case. While we do not
know where these volunteers actually reside, the bans of any volunteers who
may have been Saudi were part of a much broader action globally banning 16
editors across the MENA region. Indeed, many of them are not active in the
Arabic language projects. These organizations did not share the statement
with the Foundation, and ""sources of knowledge"" as cited in their release
can get things wrong. In addition, we do not have staff in the country
named and never have, contrary to a message put out by the same groups on
social media.
As we noted in December in our statement, we are unable to discuss
Foundation office actions in detail. The Foundation always lists accounts banned as a result of its investigations.
It is our goal to be as transparent as we can be within essential
protection policies, which is why we do not ban in secret, but instead
disclose accounts impacted and (when large numbers are involved) have
disclosed the rationale.
The roots of our December action stretch back over several years. We were
initially contacted by outside experts who made us aware about concerns
they had about Farsi Wikipedia. We can‚Äôt comment on that report right now,
but it will be published by that organization soon. This report not only
contributed to our August 23, 2021 modification of our non-disclosure agreement to make it harder for rights-holders to be coerced, but led to further
evaluation of issues across MENA. The December bans were the culmination of
those evaluations.
Wikimedia is, as mentioned above, an open knowledge platform, and it
thrives on open participation. Investigations and global bans are not
things that any of us take lightly, but the Foundation is committed to
supporting the knowledge-sharing models that have created so many valuable
information resources in hundreds of languages across the world. Our first
line of defense of our Terms of Use are our volunteers themselves. Where issues present a credible threat of
harm to our users and to the security of Wikimedia platforms, we will do
the best we can to protect both.
We trust and hope that our communities understand that misinformation about
this action has the potential to cause harm to the individuals involved. We
believe in the incredible value produced by our volunteers across the
globe, but even so we recognize that being found in contravention of a
website‚Äôs Terms of Use ‚Äî even in a manner that organization finds serious
enough to warrant a ban ‚Äî is not the equivalent of being convicted of any
crime. Accordingly, we ask you to please be conscious of the real people
involved, in the spirit of our long established respect for living people on our sites. We realize that it is tempting to speculate, but we do ask you all to
recall that people‚Äôs employment options, their relationships, and even
their physical safety may be compromised by speculation.
If anyone feels unsafe on Wikimedia projects, please use the local
community processes or contact us. The Foundation and community will work
together or in parallel to enhance the safety of all volunteers. To contact
the Trust & Safety team please email ca(a)wikimedia.org .
Best regards,
WMF Office/Trust and Safety
Analysis



Sarah Leah Whitson, the Executive Director of DAWN, is a former director of the Middle East and North Africa division of Human Rights Watch.


Notably, this statement does not contain any reference to the two imprisoned Wikipedians. On the other hand, it does express consideration for the people behind the accounts banned last month, whose role in Wikipedia has suddenly become international news, in a way the Wikimedia Foundation clearly had not intended during their initial listing of the bans.
Democracy for the Arab World Now (DAWN) Executive Director Sarah Leah Whitson, a Human Rights Watch veteran, responded to the WMF statements in an update to the Ars Technica article, added a few hours after publication: 

Whitson told Ars that Wikimedia is ""playing technical word games"" in its statement and that ""it's really important for Wikimedia to be transparent about what they have described as a conflict of interest among its editors."" She said that Wikimedia should ""provide more transparency about the 16 users that they banned"" and ""the safety precautions they're going to take to avoid further endangering Wikipedia editors in totalitarian states, because there's no denying that two of them are now languishing in Saudi prisons"" and the problem goes ""well beyond Saudi Arabia."" Whitson urges Wikimedia to reconsider its global model of relying on Wikipedia editors based in totalitarian states, not just because it can endanger the editors, but also because Wikipedia ""loses its credibility"" when information edited in these states cannot be trusted.
These are important points. The WMF is now widely reported to have ""denied claims the Saudi government infiltrated its team in the Middle East"" ‚Äì as a BBC article puts it ‚Äì but this does create some inconsistencies. A month ago, on December 6, the WMF's Trust & Safety office issued a confident assertion that ""we were able to confirm that a number of users with close connections with external parties were editing the platform in a coordinated fashion to advance the aim of those parties"". The post stated that ""these connections are a source of serious concern for the safety of our users that go beyond the capacity of the local language project communities targeted to address"" and emphasised that the Foundation had issued these bans ""to keep our users and the projects safe"". But it has provided no information on who these parties threatening users' safety are, if they are indeed unrelated to the Saudi government.
The WMF statement does mention that the roots of the December 2022 bans lie in concerns expressed to the WMF about the Farsi Wikipedia some years ago. There is a public record of concerns about state interference in the Farsi Wikipedia being voiced by Open Democracy, for example, in a September 2019 article titled ""Persian Wikipedia: an independent source or a tool of the Iranian state?"", and by Justice for Iran in an October 2019 Radio Farda article titled ""Critics Say Some Persian Wikipedia Content Manipulated By Iran's Government"".




Radio Farda, the Iranian branch of the U.S. government-funded Radio Free Europe/Radio Liberty, reported on alleged manipulation of Farsi Wikipedia content by Iran's government in 2019. The WMF says concerns expressed about the Farsi Wikipedia a few years ago eventually led to its 2022 investigation that resulted in 16 global bans in December 2022, including bans of seven Arabic Wikipedia administrators


The DAWN/SMEX press release and the many press reports based on it did contain errors. The press release referred to ""16 Saudi administrators""; as reported earlier this month in The Signpost, only seven of the ten banned Arabic Wikipedia users were administrators, and six of the 16 banned users were contributors to the Farsi Wikipedia rather than the Arabic Wikipedia. Moreover, Osama and Ziyad, the two imprisoned Wikipedians, were not administrators at the time of their arrest ‚Äì both had had their admin rights on Arabic Wikipedia withdrawn years before. The reason? They weren't using them, both having scaled down their Wikipedia activity considerably in recent years, presumably to focus on their medical studies. Ten years ago, however, Osama had uploaded pictures of a number of Saudi human rights activists to Commons; Ziyad uploaded Wikipedia's image of Loujain Alhathloul in 2016.
The headline of the article in The Guardian read: ""Saudi Arabia jails two Wikipedia staff in 'bid to control content'"". This will have left many readers once again with the false impression that Wikimedia Foundation staff administer Wikipedia's day-to-day content and community processes. (There is a reason headlines are not considered reliable sources in Wikipedia ‚Äì the body of The Guardian's article referred correctly to ""volunteer administrators"".)
The WMF's claim that admins have ""no ranks"", however, is less persuasive. Two of the banned users, for example, had bureaucrat and checkuser rights in addition to administrator privileges (elevated rights that reqire users to sign non-disclosure agreements). Moreover, the entire Arabic Wikipedia ‚Äì a project with 1.2 million articles ‚Äì only had a grand total of 26 administrators prior to the global bans (it is now down to 20). To a person in the street, surely that makes any of the 26 people administering the project ""high-ranking"". 
Even more significant is the fact that the banned Arabic Wikipedia administrators include three of the four people who founded the Saudi Wikimedia User Group, the Wikimedia Foundation's official affiliate in Saudi Arabia ‚Äì among them the affiliate's principal contact person. In total, seven of the ten banned Arabic users are listed as members of the Saudi user group. As for the other three, two, including one of the checkusers, say on their user pages that they are members of the Arabian Gulf Wikimedia User Group, which does not seem to be an officially recognised affiliate yet, and one (the other checkuser) says they're from Kuwait.
The Wikimedia Foundation made another statement on 8 January, saying, in part:

Our investigation and these bans are not connected to the arrest of these two users. The ban decision impacted 16 users, not all of whom were administrators, from Arabic and Farsi Wikipedia. As stated below, we have no reason to believe that these individuals are all residents of Saudi Arabia; on the contrary, this seems extremely unlikely. Further, we imagine you are all aware that editors are volunteers, not paid by the Foundation, and that the Foundation does not have offices or staff in Saudi Arabia.
While, as stated, the December office action is unrelated to the arrests of
two Wikimedians in Saudi Arabia, the safety of Wikimedia volunteers always
remains our utmost concern. We understand the desire to take action or
speak out. Know that we need to act in the interests of any volunteer whose
safety is under threat. As indicated in yesterday's message, additional
publicity around such cases can cause harm, as can speculation and
misinformation. We are confident that everyone values the safety of their
fellow volunteers and can understand the constraints this might create. 
Arabic Wikipedia community statement



The Arabic Wikipedia community has condemned the WMF action, arguing the bans are at odds with the model of decentralized governance that the Foundation always talks about.


The Arabic Wikipedia community has released a statement on the global bans, adopted with 38 in support, 2 opposed, and 0 neutral. What follows is an English translation of the community statement originally issued in Arabic:

Wikipedia: Statement regarding the events of December 6, 2022
This is a statement issued by the Arabic Wikipedia community to comment on the events of December 6, 2022, and the accompanying global ban that included ten user accounts on the Arabic Wikipedia, including seven administrators.
In the Arabic Wikipedia, we focus on a decentralized governance model in which all community members play roles in the decision-making process, oversight over the drafting of the encyclopedia's policies as well as guidelines, and their enforcement. This can be achieved through direct participation in the election of administrators, and in resolving conflicts and disagreements that occur in the encyclopedia. We do expect the Wikimedia Foundation, which has always supported this governance model, to follow it when dealing, not only with the Arabic community but with all other communities to ensure full transparency and mutual accountability.
We do condemn, in the strongest terms, the work model based on confidential complaints and non-public investigations, which creates a toxic work environment that is incompatible with the nature of volunteering and undermines the main Wikipedia principles of transparency and the assumption of good faith. At the same time, we call on the Foundation to adopt a transparent model in which it has no guardianship over communities, and where it accepts, without restrictions, mutual accountability from communities. The relationship should be based on the grounds that all parties, involved in a transparent governance process, are equal in all the stages of the process.
We also understand the existence of complications associated with attempts to manipulate the content of the Arabic Wikipedia, to polish or distort the image of certain parties; we condemn all these attempts without any reservations and stress the need for Wikipedia to be a platform that adopts a neutral point of view. At the same time, we call on the Foundation to involve local communities in the content protection process by sharing information with them in a way that does not harm the privacy of the users involved in the process and does not put them at risk.
If a user violates the policies, even if they hold administrator rights, they will be dealt with firmly in accordance with the local policies approved by our community. We do not tolerate the abuse of administrative powers nor the manipulation of encyclopedic content to serve third parties whatsoever, including directed editing, and we have policies governing these matters. They apply to all users equally without distinction. Therefore, we are surprised, in light of all this, that the institution imposes its supervision on our self-governing society without prior notice and issues irrevocable decisions without explanation.
We also point out the severe harm that the ban has done to our local community. We lost seven active administrators in one fell swoop! This represents 30% of the administrators in our community, including two bot operators. This has set our community back years and does not, surely, contribute to encyclopedia growth. Mainly, we have suffered the consequences of this ban at the technical level in the encyclopedia, and we appeal to the technical team in the Foundation and the open-source communities to provide the necessary technical assistance to maintain the continuity of the project as much as possible.
The Arabic community has chosen a committee of four people to follow up with the Wikimedia Foundation on the basis of mutual accountability on the issue of the above bans. We are waiting, and we hope, for the Wikimedia Foundation to cooperate with this committee, facilitate its work and share with it the information in its possession without harming the privacy of any user on the Arabic Wikipedia or its sister projects.
Wikimedia Foundation reply posted on the Arabic Wikipedia



Vinicius Siqueira, Osama Khalid, Netha Hussain, Emily Temple-Wood, Anthony Cole, Jake Orlowitz, Daniel Mietchen, Lane Rasberry, James Heilman and Peter Coti (clockwise starting front left) at a WikiProject Med meetup at the 2013 Hong Kong Wikimania conference


On 10 January, the Wikimedia Foundation replied to the Arabic Wikipedia community statement on the associated talk page. It is the first Foundation statement to actually use the imprisoned Wikipedians' names. The reply was posted in Arabic; a machine-aided (Google/Bing) translation follows below:

Update from the Wikimedia Foundation
Hello all
We know the past few weeks have been difficult for the community. We also realize that this situation remains confusing and worrying in light of the media reports that have emerged. As an organization, we regret the distress and concern this situation has caused the community. While we know we can't answer all of your questions, we want to make sure you understand our processes and the rationale behind them. We also want to ensure that our actions are in the best interests of the community to the best of our ability and with the tools available to us. As mentioned, the measures were not linked in any way to the recent media reports that are currently circulating, nor in any way to the arrests. The Foundation has learned of the arrest of Osama and Ziyad, and is actively following up on their situations.
As we know that not everyone will have read all of the data, we would like to reiterate that the process of reaching the decision to take action in December 2022 was not easy or rushed. The investigation into violations of the Terms of Use took a long time starting with the Persian Wikipedia and moving on as new information emerged, and the final decision was guided by multiple levels of review by several employees across different functions. After consideration, it was unanimously agreed that the action is necessary to keep the community and platforms safe. Proper implementation of this measure was equally important in keeping the community and platforms safe, and thus adhering to established policies and procedures.
We realize that media reports and recent actions in December 2022 make many of you skeptical and perhaps even apprehensive about participating in the projects. We want you to know that the projects are owned by everyone, and most of all, that you are the creators and curators of the content. Foundation interventions in content or management issues on the sites are rare and limited to exceptionally problematic circumstances. No one should fear that the Foundation will take action on unintentional mistakes made while participating as editors in good faith.
As many of you already know, the Foundation fully supports community autonomy and the principle of subsidiarity as part of our commitment to respecting and promoting community autonomy. Not only do we feel this is the right approach to our shared values, but it is the only approach that can make these amazing projects work. To ensure we maintain this commitment, we do not deal with general community or community member disputes that might otherwise be addressed through existing community actions, nor do we act as a means of appealing community policies and decisions. If such situations arise, we look forward to working to help the community members who need help, but most of the time, this assistance will consist of guiding the community members to find the right community avenue that will solve their problem.
On some occasions, the Foundation considers cases of abuse. This only occurs when it has been brought to our attention that the local community lacks the necessary processes to effectively address the situation, or when the organization has a legal obligation as a platform provider to act in the interests of the safety of users and the platform. When we intervene, we are limited in the course of action we can take. Our procedures are guided by the Office's work policies, which allow us to issue global bans, event bans, issue warnings, interaction bans, and advanced permission removal. While this responsibility rests with us, we do not take our interventions lightly; these investigations take a lot of time and effort and require multiple staff members across different departments to ensure that we provide a comprehensive understanding of the matter before we take any action. For the size of our communities, we have issued very few centralized global bans. Collective global bans like the one we issued in December 2022 are only put in place in the most exceptional circumstances, when the evidence strongly supports a serious threat to the organization's Terms of Use that all contributors must agree to abide by when editing the projects.
Our December 6 Office action was the result of the Foundation's multiple, long-term investigations undertaken as part of our duties as a platform provider. It was not related to the media reports currently circulating. While there are still limits to what we can disclose in order to protect the safety and privacy of our users, we truly understand and sympathize with the fact that this continues to be an upsetting situation and would like you to know that we would not have taken this action if it were not necessary.
We also want to acknowledge that the media reports have created significant doubt in people's minds about the safety of participating in Wikimedia projects, because of their direct linkage to cases of volunteers being arrested. It is unfortunate that many organizations relied on incomplete facts and indirect sources in their coverage, which directly contradicts our principles. Regardless of the current situation, the Foundation is well aware that such risks exist globally, and we want our community members to be aware too - and work with us to take precautions to stay safe. Six months ago, the United Nations published an article describing the rise of disinformation as a ""global disease"".
In late May 2020, the Board included protecting projects and communities from ""misinformation and bad actors"" in its Statement on Community Culture. On August 23, 2021, we amended our Non-Disclosure Agreement to make it more difficult to coerce rights holders, by restricting access in certain high-risk regions where individuals may be particularly vulnerable to threats to themselves and their families. We continue to work to secure the safety of those combating this ""global disease"" ‚Äì disinformation ‚Äì not just through Office actions but in terms of proactively encouraging safe practices, as in our recent blog post on protecting online anonymity. This assessment by external experts has identified a number of areas to support our approach, the Board has issued a policy symbolizing our commitment to this improvement, and our Human Rights Team continues to work to provide resources of information and support to users on the ground. We are also working on making additional digital security resources available to community members who feel unsafe online, which we will finalize soon.
We respect and realize that this action represents a major setback for the community and that is why we are open to providing the community with the support needed and what help we can provide. If there is anything we can do to help the community during this time, please do not hesitate to let us know via ca@wikimedia.org. As mentioned earlier, we are ready to provide you with the required support to the best of our ability.
Best Regards,
Wikimedia Foundation Office WMFOffice (talk) 09:09, 10 January 2023 (UTC)
Much to ponder
The WMF mentioned a change to the Non-Disclosure Agreement in the statements above. This concerns a document VRT volunteers, CheckUsers, Oversighters and Stewards are required to sign. The change, made on 23 August 2021, added the following words to the relevant page on Meta-Wiki:

The Foundation shall not grant Foundation volunteer NDA recognition to applicant(s) for volunteer roles if the applicants live in jurisdictions that block(ed) access to Wikimedia projects AND there is reason to believe that their domicile is known to others than the individual applicant(s) and the Foundation. Exemptions may be granted in individual cases following a request for review by the Legal department. Granting such NDAs would put the applicant(s) as well as other volunteers relying on the Foundation‚Äôs platform at undue risk. All NDA-based access rights granted to users fulfilling both criteria in the proposed adjustment shall be revoked at the point of policy adjustment.
This still seems weak, given the risk of decade-long prison sentences served in high-security facilities. Even if an editor's place of residence is only known to them and the Foundation today, there is no guarantee at all that others won't discover it at some point in the future. A checkuser whose identity becomes known to a present (or future) authoritarian government would not just be at risk personally, but could also be compelled ‚Äì legally or otherwise ‚Äì to collect user data and pass these on to state organs, putting other users at risk of prosecution.
There is much to ponder here about project governance, government influence on Wikimedia projects, and the vulnerability of editors and administrators to coercion and imprisonment. But the most pressing question is perhaps what we, as a movement, can do to help Osama and Ziyad. 
The Wikimedia Foundation, DAWN and SMEX clearly got off on the wrong foot ‚Äì it would be good to see them engage in constructive dialogue now, and pool their resources, at least inasmuch as our fellow Wikimedians are concerned. According to DAWN Executive Director Sarah Leah Whitson, who discussed the case with The Signpost, campaigning for their release at this point, over two years into their sentences, is very unlikely to do them harm, and may do some good.

External links
""Foundation Trust & Safety action in the MENA Region"", Wikimedia-l mailing list thread, 6 December 2022 onwards
""Saudi Arabia: Government Agents Infiltrate Wikipedia, Sentence Independent Wikipedia Administrators to Prison"", DAWN press release, 5 January 2023, also published on the SMEX website
""Saudi Arabia jails two Wikipedia staff in 'bid to control content'"", The Guardian, 5 January 2023
""Saudi Arabia 'infiltrated' Wikipedia to control content, activists say"", Middle East Eye, 5 January 2023
""Wikipedia admin jailed for 32 years after alleged Saudi spy infiltration"", Ars Technica, 6 January 2023
""Recent press around December Office Action"", Wikimedia-l mailing list thread, 6 January 2023 onwards
""Wikipedia operator denies Saudi infiltration claim"", BBC, 7 January 2023, edited 10 January 2023
""Saudi Government Narrative Control Efforts Now Include The Jailing Of Wikipedia Administrators"", TechDirt, 10 January 2023






‚Üê Previous ""Special report""
In this issue16 January 2023From the team
Special report
News and notes
In the media
Technology report
In focus
Serendipity
Gallery
Humour
Opinion
Featured content
Traffic report
From the archives


+ Add a commentDiscuss this story
These comments are automatically transcluded from this article's talk page.¬†To follow comments, add the page to your watchlist. If your comment has not appeared here, you can try purging the cache.

From what I remember reading on the Arabic Wikipedia discussion about the bans, there were a significant number of other editors there making blatantly pro-SA government statements and were angry at the editor accounts being banned in relation to that. I have concerns that the Arabic (and possibly Persian) language Wikipedia communities are entirely subsumed by blatantly biased pro-government accounts. Because the reason for the bans was never a mystery to anyone, not seriously. Even if the WMF has been trying to be vague about it all. Even this very Signpost article is quite clear and direct on the fact that we all know that the banned accounts were people working directly for the SA government in order to push their own personal views of events and to downplay the ongoing human rights atrocities that Saudi Arabia's administration is committing. With our unfortunate two editors discussed above being only a single example among many. SilverserenC 05:43, 16 January 2023 (UTC)Reply[reply]

That is an absolute monarchy for you.  scope_creepTalk 13:38, 16 January 2023 (UTC)Reply[reply]
I've said this before, but I believe that if there's any way for the WMF to use its considerable funds and influence to promote the spread of free knowledge in autocratic nations, then that should be one of its highest priorities. Free knowledge is why we're here. We as the Wikipedia communities, regardless of language, should be some of Khalid and Alsufyani's strongest advocates. Thebiguglyalien (talk) 17:38, 16 January 2023 (UTC)
Reply[reply]






The Signpost needs your help putting together the next issue.


Home
About
Archives
Newsroom
Subscribe
Suggestions





Retrieved from ""https://en.wikipedia.org/w/index.php?title=Wikipedia:Wikipedia_Signpost/2023-01-16/Special_report&oldid=1134032349""
Categories: Wikipedia Signpost archives 2023-01Wikipedia Signpost RSS feed



Navigation menu



Personal tools


Not logged inTalkContributionsCreate accountLog in





Namespaces


Project pageTalk





English









Views


ReadEditView history





More

























Navigation


Main pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate




Contribute


HelpLearn to editCommunity portalRecent changesUpload file




Tools


What links hereRelated changesUpload fileSpecial pagesPermanent linkPage information




Print/export


Download as PDFPrintable version




Languages



Add links






 This page was last edited on 16 January 2023, at 17:59¬†(UTC).
Text is available under the Creative Commons Attribution-ShareAlike License 3.0;
additional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia¬Æ is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.


Privacy policy
About Wikipedia
Disclaimers
Contact Wikipedia
Mobile view
Developers
Statistics
Cookie statement








"
https://news.ycombinator.com/rss,Rendering like it's 1996 ‚Äì Bitmap fonts and DOS,https://marioslab.io/posts/rendering-like-its-1996/dos-nostalgia/,Comments,"













Mario's Lab





Mario's Lab
Mastodon
Twitter
Github
RSS



Rendering like it's 1996 - Bitmap fonts and DOS
December 07, 2022




This screen has burned itself into my retina.



To follow along this blog post with running code, make sure you've installed the prerequisites. Then:

git clone https://github.com/badlogic/r96
cd r96
git checkout 04-dos-nostalgia
./tools/download-tools.sh
code .

Last time we learned about loading images and blitting. That was over 3 weeks ago, making me miss my target of posting one series entry a week. But there's a reason for it! I was rather busy in those two weeks.
After using Hopper to generate control flow graphs to discuss performance optimization, I got a little sick of the workflow and built my own assembly CFG viewer. Just paste some x86 or ARM assembly generated by MSVC, Clang, or GCC into the left panel, and view the control flow graph of each function on the right. I also made it a re-usable NPM package. Going forward, I can embed those fancy CFGs directly.
Then I drifted off into yet another rabbit hole. Spurred by a mean comment on Reddit about how the r96 code doesn't even run in DOS, I made the code of the series run in DOS.
First, I built a DOS backend for MiniFB. Then, I forked an old GDB version which is capable of remotely debugging 32-bit protected mode DOS programs as produced by DJGPP, the GCC fork I use to build C/C++ DOS programs. I also forked DOSBox-x to fix it up so my forked GDB can actually connect to DOS programs via the serial port/TCP emulation.
Finally, I took the barely functional GDB stub that comes with DJGPP, rewrote it and added a ton of functionality to it, so I can now debug DOS programs running in DOSBox-x from the comforts of Visual Studio Code.
All of that work culminated in a VS Code extension, which lets you go from 0 to debugging a simple DOS mode 13h demo app in VS code in about 80 seconds:

With all of that out of my system, I built some shell scripts that will help you install (almost) all the tools to compile, run, and debug the r96 project for desktop, web, and DOS. And I added some VS Code magic so you can comfortably start debugging sessions on each platform.
And to round it all off, I cleaned up the Git repo, so each blog post maps to exactly one commit. And I rewrote the first 3 blog posts in the series. So yeah.
I can now happily continue writing the series. Promise. Unless I'll add Android and iOS support in the future. I currently don't feel that specific masochism piling up inside of me.
Today, we're looking at DOS support, and then load and draw some bitmap fonts.
Demo: Hello DOS
Alright, go get the latest and greatest from the r96 repository. Follow the README.md to install the tools, including the new DOS tools. The README.md will also get you up to speed on how to build and debug everything in VS Code or on the command line. Or, if you want a detailed run-down of the project and its build and IDE support, read the first entry of the series.
To celebrate DOS support, I've added a new demo called 12_hello_dos.c:

#include <MiniFB.h>
#include <stdio.h>
#include ""r96/r96.h""
#include ""stdlib.h""
#include <math.h>

#define GDB_IMPLEMENTATION
#include ""dos/gdbstub.h""

#define num_grunts 100

typedef struct grunt {
	int x, y, vx, vy;
} grunt;

int main(void) {
	gdb_start();
	r96_image image;
	if (!r96_image_init_from_file(‚Ñë, ""assets/grunt.png"")) {
		printf(""Couldn't load file 'assets/grunt.png'\n"");
		return -1;
	}

	r96_image output;
	r96_image_init(&output, 320, 240);
	struct mfb_window *window = mfb_open(""12_hello_dos"", output.width, output.height);

	grunt grunts[num_grunts];
	for (int i = 0; i < num_grunts; i++) {
		grunt *grunt = &grunts[i];
		grunt->x = rand() % 320;
		grunt->y = rand() % 200;
		grunt->vx = 1;
		grunt->vy = 1;
	}
	do {
		r96_clear_with_color(&output, 0xff222222);
		for (int i = 0; i < num_grunts; i++) {
			grunt *grunt = &grunts[i];
			if (grunt->x < 0) {
				grunt->x = 0;
				grunt->vx = -grunt->vx;
			}
			if (grunt->x > 320 - 64) {
				grunt->x = 320 - 64;
				grunt->vx = -grunt->vx;
			}
			if (grunt->y < 0) {
				grunt->y = 0;
				grunt->vy = -grunt->vy;
			}
			if (grunt->y > 240 - 64) {
				grunt->y = 240 - 64;
				grunt->vy = -grunt->vy;
			}
			grunt->x += grunt->vx;
			grunt->y += grunt->vy;
			r96_blit_keyed(&output, ‚Ñë, grunt->x, grunt->y, 0x00000000);
		}
		if (mfb_update_ex(window, output.pixels, output.width, output.height) != STATE_OK) break;
		gdb_checkpoint();
	} while (mfb_wait_sync(window));

	r96_image_dispose(‚Ñë);
	r96_image_dispose(&output);
	return 0;
}

This is our first animated demo!
The demo draws 100 moving grunts, that bounce off of the screen boundaries. Each grunt is stored in a simple grunt struct, which in turn stores the grunt's position (x, y) and velocity on the x- and y-axis (vx, vy) in pixels per frame. During initialization, we give each grunt a random position within the screen boundaries and set its velocity on each axis to 1 (lines 29-35).
What's a frame you may ask? A frame can be many things, but in our case, a frame is simply one iteration of the main loop of your program (lines 36-62). In each frame, we check whether each grunt is still inside the screen boundaries. If a grunt is outside the screen boundaries on the x- or y-axis (or both), we move them back inside the bounds and negate their velocity on the axis they left the screen on.
E.g. a grunt moving to the right (vx = 1), leaving the screen on the x-axis (x > 320 - 64), will be moved back inside the screen boundaries (x = 320 - 64), and its velocity on the x-axis will become -1. Starting in the next frame, the grunt will then move to the left, until it exits the screen boundaries on the left side of the screen. The same happens on the y-axis.
Once all the checks are complete, we add the grunt's velocity to its position. Each frame, the grunt's position thus changes by vx pixels on the x-axis, and vy pixels on the y-axis. Hence why vx and vy are given as pixels per frame.

Note: This is a very basic form of explicit Euler integration. It's much less scary than it sounds! Go learn your fundamentals.

Now, there's one big problem with this type of moving objects: it depends on the speed of execution.
We call mfb_wait_sync(), which waits for a vertical refresh, effectively limiting the number of frames per second to the screen refresh rate, so 60Hz, 90Hz, 120Hz, or whatever other wonky screen refresh rate the display has.
On a 60Hz screen a grunt will thus move 60 pixels per second, on a 120Hz it will move 120 pixels.
For a game, that's not great: different players will experience the game at different speeds, depending on their hardware. We'll look into this issue in a future series entry.

Note: Many old DOS games actually did have this problem: they would not take into account how much time has passed since the last frame, but instead update game object positions at a fixed rate each frame. There's a reason Wikipedia has an entry on the notorious PC turbo button.

Here's the little demo on the web:





And here it is running in DOSBox-x, telling DOSBox-x to go full speed.

DOSBox-x on my system syncs to 60Hz in windowed mode, while Chrome runs the web demo at the full 120Hz of my display. In the video above, there is some smearing and artifacts. That's mostly due to the MP4 encoding and doesn't look like that when actually running the demo in DOSBox-x on your system.
Is the DOSBox-x performance indicative of performance on old systems? No. DOSBox-x is going full speed, which is way faster than what my old 486 could do. However, you can modify the emulation speed via the DOSBox-x menu CPU > Emulated CPU speed. In the following video, I've set the emulated CPU speed to be equivalent to a 486DX2 with 66Mhz:

While that's more accurate, it's still not quite the same as real hardware. To get a more accurate sense of how the program would perform on a real 486, we can use 86Box. 86Box is as cycle accurate emulator for various old x86 systems.

Looks like DOSBox-x isn't far off with its emulation. So why is it so slow?

Note: Setting up virtual machine images for 86Box is a bit terrible. I've created 2 images you can download, a 486 image and a Pentium image, pre-installed with MS-DOS 6.22, a mouse driver, and a CD-ROM driver. You can run them via 86box -c 486/86box.conf and 86box -c pentium/86box.conf. The images also include QBasic 1.1. And NIBBLES.BAS and GORILLA.BAS. Just saying.

Why is it so slow on a 486?
The MiniFB DOS backend sets up a video mode with either 24-bit or 32-bit color depth through VESA. MiniFB assumes 32-bit color depth, so we have to abide by that and go VESA.
This works pretty well from Pentium class machines onwards, if the (emulated) video card supports VESA. Here's the demo on Pentium class hardware in 86Box:

A 486 may support 24-bit and 32-bit color depth video modes, depending on the graphics card. Mine did. However, that doesn't mean the system is fast enough to actually deal with that amount of data. A run of the mill 486 would have memory throughput somewhere in the range of 10-25MB/s. You read that right.
In our demo above, we render to a 320x240 output r96_image. The call to r96_clear_with_color() has to touch 0.3MB worth of pixels. Rendering a single grunt means reading 64x64x4 bytes from the grunt image and writing them to a 64x64x4 bytes big region in the output r96_image. For 100 grunts, that's reading 1.6MB and writing 1.6MB. Finally, the output r96_image is transferred to the VESA linear buffer, a memory mapped region from which the graphics card will read what it should output to the display. That's another 320x240x4 bytes, or 0.3MB. Each frame we thus touch 0.3 + 1.6 + 1.6 + 0.3 = 3.8MB of memory. And while this simple analysis doesn't account for memory caches, it does align with what we experience when running the demo on a (emulated) 486. We do indeed only get something like 3-5 frames per second, which is 11.4-19MB of data pushed by the demo per second.
That's one of the reasons pretty much all older DOS games targeting 386 or 486 would use mode 13h or derivatives like Mode X. Both of these video modes use 8 bits to encode a pixel's color. But instead of directly encoding the color's red, green and blue component, the 8-bit value is an index into a palette with a total of 256 colors. That cuts down on memory and bandwidth needs considerably.
If we went mode 13h in our demo, we'd go from 3.8MB to 0.95MB of data per frame. That translates to 12-20 frames per second, which is still not great, but often playable enough. That's about the frame rate I got when playing MicroProse's Formula One Grand Prix on my 486.
So what's the solution? Draw less each frame! DOOM and Quake relied on various techniques like binary space partitioning to avoid drawing things that are invisible or occluded. Drawing less means touching less memory. Consider that 100 grunts are about 5.3 screens worth of pixels. That's a lot of overdraw.
Yes, we could probably squeeze a lot of cycles out of the blitting functions if we handcrafted some 32-bit x86 assembly. But DJGPP actually does a pretty good job at producing fast machine code. And I don't want to drop down into assembly land.

Note: modern hardware won't save you from these issues either sometimes. When NVIDIA sent me a prototype Tegra board in the early 2010s, I soon found out that you could only render about 2 full-screen alpha blended rectangles through OpenGL ES before the frame-rate takes a heavy hit.

Excursion: DOS debugging support
When we debug the demo on the desktop, the debugger will spawn the demo process and use system APIs to stop, resume, inspect, and otherwise manipulate the process.
For DOS applications running in DOSBox-x or on a real machine, we do not have the luxury of a debugger. Instead, we use a piece of code called GDB stub that we integrate in our program. Here's how that works in 12_hello_dos.c.
Of note are 3 pieces of code in the demo above, which do nothing on any platform other than DOS. In lines 7-8 we have:
#define GDB_IMPLEMENTATION
#include ""dos/gdbstub.h""

This pulls in my GDB stub implementation for DJGPP/DOS, which is a single header file library.
The stub's task is it to communicate with the debugger over the serial port, and tell it when the program has stopped due to a breakpoint, or segfault, or other reason. The stub then waits for commands from the debugger to execute, like setting breakpoints, inspecting memory and CPU registers, stepping, continuing, etc.
This GDB stub type of debugging is a cooperative debugging approach. The stub needs to be integrated with the program itself. This explains the other two GDB related lines of code in the demo.
The gdb_start() function is called at the beginning of main(). It waits for the debugger to connect on the serial port. When the debugger tells the stub to continue execution of the program, the stub stops communicating with the debugger for the time being, and gives back control to the program.
The stub then waits for a system level signal to be raised, like a breakpoint or segfault, for which the stub has registered handlers. If such a signal happens, the stub takes over control from the program again, tells the debugger about the program being stopped, and waits for debugger commands to execute.
The final GDB related line is gdb_checkpoint() in line 61. It is placed at the end of our main loop. This is required so the stub can check if the debugger asked to interrupt the program, in which case the stub will take control of the program again and talk to the debugger.
The GDB stub expects all communication to happen through serial port COM1. Some emulators and virtual machines, like DOSBox-x or VirtualBox, can expose the emulated serial port as a TCP port to programs on the host OS. That's what's happening when we debug a demo in DOSBox-x. DOSBox-x exposes the serial port on TCP port 5123, to which GDB connects via TCP. DOSBox-x will then translate TCP packages to writes to the serial port, which the GDB stub reads from COM1. If the GDB stub writes to COM1, then DOSBox-x will forward the data through TCP to GDB.
In theory, the GDB stub should also work on real-hardware. Sadly, I do not have my 486 anymore, nor a serial cable or a serial port on my MacBook.
If you want to debug any of the demos in DOS, you'll have to add the 3 pieces of GDB stub related code to the demo's sources as outlined above. Only the 12_hello_dos.c demo is currently set-up for DOS debugging. Since our code is cross-platform, there won't be a need to debug in DOS a lot though.

Note: when debugging the demos compiled for DOS, we'll be using DOSBox-x instead of 86Box. Two reasons: getting data into and out of 86Box is very annoying. And there is no serial port over TCP emulation in 86Box, so the debugger couldn't even connect. It should be possible to hook the debugger up with a program running in MS-DOS or FreeDOS in VirtualBox though.

Bitmap fonts
Rendering text these days is really, really hard. When we go zooming around documents or web pages via mouse wheel or touch zoom, we expect text to scale seamlessly and stay crisp. If we want to get fancy, we add kerning and hinting to the mix.
It gets even harder when non-latin scripts like arabic script or CJK script need to get put on a screen. Now you have to deal with (more) ligatures, mixed left-to-right and right-to-left layouting, and various other complexities.
And to top it all off, what you get out of a font file is usually a vector representation of not a character, but a glyph, which can be a character, or a part of a character, and oh my, this is all very complicated.
Thankfully, there are various libraries that can help us draw text. For translating a text string to a set of glyphs, or shaping as it's usually called, you can use HarfBuzz. If you want to rasterize those glyphs, which are usually given in vector form, you can use FreeType. If you  want to use your GPU to do most of that, you can use Slug. Your operating system usually also comes with APIs to draw text.
We aren't going to do any of that though. We'll be going somewhat old school and draw inspiration from VGA text mode fonts, but with a 2022 spirit (aka being wasteful).
Before we can look at font pixels, we need to talk about how text is stored in the tubes of our computerers.
Character encodings
Text is composed of characters. When we store text digitally, those characters need to be stored as a sequence of (binary) numbers. When we read characters from a file to draw them to the screen, or translate key strokes to characters, we need to map numbers back to characters. Similarly, when the C compiler encounters a string literal like const char *text = ""Hello world"", it will convert the characters in the string to a sequence of numbers that gets embedded in the final executable.
Mapping those sequences of numbers to characters and vice versa is what character encodings are for.
One of the oldest character encodings is ASCII. Each character is encoded in 1 byte. Well, actually, ASCII only uses the first 7-bits, so it encodes a total of 128 characters. Well, that's not quite true either. Only 95 of these characters are printable. The other 33 ""characters"" are what's called control codes. Notable ones are \t or 9, which indicates a tab, and \n or 10, the line feed. See, it's already complicated!
Here are all the printable characters and non-printable control codes contained in ASCII with their (hexa-)decimal codes.

> ascii -d
Dec Hex    Dec Hex    Dec Hex  Dec Hex  Dec Hex  Dec Hex   Dec Hex   Dec Hex
  0 00 NUL  16 10 DLE  32 20    48 30 0  64 40 @  80 50 P   96 60 \`  112 70 p
  1 01 SOH  17 11 DC1  33 21 !  49 31 1  65 41 A  81 51 Q   97 61 a  113 71 q
  2 02 STX  18 12 DC2  34 22 ""  50 32 2  66 42 B  82 52 R   98 62 b  114 72 r
  3 03 ETX  19 13 DC3  35 23 #  51 33 3  67 43 C  83 53 S   99 63 c  115 73 s
  4 04 EOT  20 14 DC4  36 24 $  52 34 4  68 44 D  84 54 T  100 64 d  116 74 t
  5 05 ENQ  21 15 NAK  37 25 %  53 35 5  69 45 E  85 55 U  101 65 e  117 75 u
  6 06 ACK  22 16 SYN  38 26 &  54 36 6  70 46 F  86 56 V  102 66 f  118 76 v
  7 07 BEL  23 17 ETB  39 27 '  55 37 7  71 47 G  87 57 W  103 67 g  119 77 w
  8 08 BS   24 18 CAN  40 28 (  56 38 8  72 48 H  88 58 X  104 68 h  120 78 x
  9 09 HT   25 19 EM   41 29 )  57 39 9  73 49 I  89 59 Y  105 69 i  121 79 y
 10 0A LF   26 1A SUB  42 2A *  58 3A :  74 4A J  90 5A Z  106 6A j  122 7A z
 11 0B VT   27 1B ESC  43 2B +  59 3B ;  75 4B K  91 5B [  107 6B k  123 7B {
 12 0C FF   28 1C FS   44 2C ,  60 3C <  76 4C L  92 5C \  108 6C l  124 7C |
 13 0D CR   29 1D GS   45 2D -  61 3D =  77 4D M  93 5D ]  109 6D m  125 7D }
 14 0E SO   30 1E RS   46 2E .  62 3E >  78 4E N  94 5E ^  110 6E n  126 7E ~
 15 0F SI   31 1F US   47 2F /  63 3F ?  79 4F O  95 5F _  111 6F o  127 7F DEL

The codes 0-31 are control codes, including the \t (9) and \n (10) codes we discussed above. Printable characters start at code 32 (  or space) and go to code 126. The final code 127 is another control code.
ASCII is short for ""American Standard Code for Information Interchange"". Unsurprisingly, the ASCII encoding really only contains characters used in US English, and by coincidence, some other western scripts.
Now, I'm not 'merican. And based on my server logs, chances are good you aren't 'merican either. What about other fancy characters, like '√∂' or '√™'? Or characters from the arabic or CJK scripts? Well, that's a lot more complicated and historically involves something called code pages, which was and still is an utter mess.
The alternative to code pages is Unicode. Unicode defines codes (or code points in Unicode parlance) for almost 150,000 characters used in scripts from all around the world, including historic ones. It also includes emojis, for better or worse. Your parents' brains have probably also switched to emoji only instant messaging communication. And they said computers would make us kids dumb. Thanks, Unicode.
Unicode has multiple encodings, like UTF-8, UTF-16, and so on. Thankfully, the world has now mostly standardized on UTF-8, for good reasons. UTF-8 is a multi-byte encoding. Depending on the character, we may need 1 to 4 bytes to store it.
For our demos, we'll store text either in C source code as literals ala const char *text = ""Hello world"", or in text files in the assets/ folder of the r96 project. Both the C sources and text files will be encoded using UTF-8. Anything else would be pain. This means we have to deal with UTF-8 when rendering text.
But as I said earlier, we do not want to go full Unicode text rendering, as that'd require us to integrate all the fancy libraries mentioned above. We want a simpler solution. Enter Unicode's first 256 code points. These code points are split up into 2 blocks.
The first block from code point 0-127 is called the Basic Latin Unicode block. The code points are the exact same codes as used in ASCII, including both non-printable control codes (0-31 and 127) and printable characters (32-126). When encoding text with UTF-8, the resulting sequence of bytes is backwards compatible with ASCII: the first 128 Unicode code points get encoded as a single byte in UTF-8.
The second block from code point 128-255 is called the Latin 1 Supplement block. It contains another set of non-printable control codes (128-159) called C1 controls, which we can safely ignore for the purpose of rendering text. The remaining code points in the block (160-255) include additional characters used in some western scripts. These Unicode code points are encoded with 2 bytes in UTF-8.
Surprise! Those first 256 Unicode code points map directly onto an old code page, namely, the  ISO-8859-1 character set. It is sometimes incorrectly referred to as extended ASCII. Here are the characters contained in the set.


The ISO-8859-1 character set Source: Wikipedia

E.g. √∂ is encoded as 0xF6 or 246 in decimal. The gray blocks are the control codes.
Alright, we've decided to use the first 2 Unicode blocks spanning code points 0-255. All our C source code containing string literals will be stored UTF-8 encoded. And any text files we put into assets/ to be read by our demos will also be UTF-8 encoded. There are two minor complications.
The first complication is how C compilers handle string literals. When the compiler encounters something like const char *text = ""Hello world"", it will use a character encoding to turn the literal ""Hello world"" into a sequence of bytes embedded in the executable. Which encoding is chosen, depends on the compiler. By default, Clang and GCC convert the string literal to UTF-8 and embed the corresponding byte sequence. Clang even assumes that the source file encoding is UTF-8 and refuses to compile anything else. MSVC is ... different. Luckily, we do not care for MSVC in this series. If you do care for some reason, just make sure to pass /utf8 as a compiler flag to ensure MSVC embeds string literals as UTF-8 as well.
The second complication is actually reading the code points of a UTF-8 encoded text string, whether it comes from a C string literal or a UTF-8 encoded file read from disk. We have to deal with the multi-byte nature of the UTF-8 encoding, as code points above 127 are encoded as two bytes. Luckily, I've taken care of that with the function r96_next_utf8_character():

uint32_t r96_next_utf8_code_point(const char *data, uint32_t *index, uint32_t end) {
	static const uint32_t utf8_offsets[6] = {
			0x00000000UL, 0x00003080UL, 0x000E2080UL,
			0x03C82080UL, 0xFA082080UL, 0x82082080UL};

	uint32_t character = 0;
	const unsigned char *bytes = (const unsigned char *) data;
	int num_bytes = 0;
	do {
		character <<= 6;
		character += bytes[(*index)++];
		num_bytes++;
	} while (*index != end && ((bytes[*index]) & 0xC0) == 0x80);
	character -= utf8_offsets[num_bytes - 1];

	return character;
}

This function takes a sequence of bytes (data) encoding a UTF-8 string, an index into the byte sequence, and the last valid index (end). Both indices are byte offsets, not character offsets!
The function then reads the next UTF-8 character, which may be 1 to 4 bytes long, and returns its code point. Additionally, it increments the index accordingly, so we know at what byte offset the next character starts.

Note: I stole the original of this function many years ago from ... somewhere. I can not remember anymore. I've since modified it to my needs. To the original author: I'm deeply sorry I forgot who you are.

We can use this function to iterate all UTF-8 characters in a byte sequence and get their code points:

const char *utf8_text = ""¬°√Ñ√ñ$\n\t"";
uint32_t index = 0;
uint32_t end = strlen(utf8_text);
while (index != end) {
	uint32_t code_point = r96_next_utf8_code_point(utf8_text, &index, end);
	printf(""code point: %i/%x\n"", code_point, code_point);
}

Which prints the code point of each character in decimal and hexadecimal.
code point: 161/a1
code point: 196/c4
code point: 214/d6
code point: 36/24
code point: 10/a
code point: 9/9

As expected. Compare the output to the ISO-8859-1 chart above for validation.
This function can deal with any valid UTF-8 byte sequence and returns code points as a 32-bit unsigned integer. For our purposes, we are only interested in code points 0-255 and will ignore any other code points.
The glyph atlas
Alright, we have all our encoding bases covered. The next question is: how do we turn a code point like 64 (0x41) into the corresponding glyph image for the character A from a font, so we can blit it onto the screen?
To make things easy for us, we'll define some limits:

We'll only render the printable Unicode code points between 0-255 as described above.
We'll only use fixed-width or monospaced fonts. Each glyph in such a font has the same width. We can entirely ignore things like kerning this way.
The font size is fixed.

With these limits in place, the basic idea of a glyph atlas goes like this:

Pick a monospaced font, like the original IBM VGA 8x16 font.
Use a glyph rendering library like FreeType to load the font and render out a glyph image for each printable Unicode code point between 0-255.
Pack those glyph images into a single image called the glyph atlas in some order which makes mapping from a code point to the glyph image coordinates inside the glyph atlas trivial.

Here's an example of what such a glyph atlas could look like.




I've super-imposed a red grid de-marking each glyph's boundaries. An atlas we can use would not have that grid on it. The pixels of the glyph are fully opaque white (0xffffffff), while the background pixels are transparent (0x00000000);
The atlas above contains glyph images from the IBM VGA 8x16 font for the Unicode code points 0-255. Each glyph is 8x16 pixels in size. Each row consists of 16 glyphs. There are 16 rows in total, so 256 glyphs in total, one for each code point.
The glyphs in the first row map to code points 0-15, the glyphs in the second row map to code points 16-31, and so on. The first, second, ninth, and tenth row are empty, as these are the glyphs for non-printable control characters. The other rows contain the glyphs for all printable characters.
If you compare this glyph atlas with the ISO-8859-1 table above, you'll see that they are equivalent, except that the last glyph in the bottom right corner is missing from the atlas. The IBM VGA 8x16 font simply does not have a glyph for that code point.
So how do we generate this atlas? We don't. At least we won't write code for that as part of this series. I've already written a web tool based on FreeType that does exactly what we need. It's called Mario's (B)it(m)ap (F)ont (G)enerator (I'm a a dad, I'm allowed to name it like that) and you can run it in your browser here.
The tool lets you load a monospaced TrueType font, set the pixel height of the glyphs you want, and spits out a 16x14 grid of glyph images for the code points 32-255. It omits the code points 0-31 and thus the first two rows of the atlas as those are non-printable control codes anyways. The above atlas thus becomes this:




We're still wasting two rows in the middle for the second set of control codes. But keeping them around makes converting code points to glyph image coordinates easier.
We can store the generated glyph atlas as a .png file in the assets/ folder. I did just that using the file name assets/ibmvga.png. The generator also tells us that each glyph has a size of 8x16 pixels. We'll need to remember that for when we actually draw text later. Since the glyph atlas is a plain old image, we can load it via r96_image_init_from_file().
We're almost ready to render a text string. We need two more things:
* Being able to map a Unicode code point to a region in the glyph atlas image, where a region is defined by its top-left corner x- and y- pixel coordinates in the glyph atlas, and its width and height in pixels.
* Being able to not just blit an entire r96_image to another, but also blit regions of an r96_image to another r96_image.
Let's start with the mapping problem.

Note: We could put both the atlas and the glyph size information into some custom file format. I decided that's not worth it, so we'll go with a .png and some hard coded glyph sizes in the code.

Mapping code points to glyph atlas pixel coordinates
How can we map a code point to the pixel coordinates of the top left corner of a glyph image in the atlas?
Before we resolve pixel coordinates for a code point, it's actually easier to use a different coordinate system. Let's give each glyph in the atlas an x- and y-coordinate.


For our example glyph atlas in the last section above, each cell represents a glyph image of size 8x16 pixels. In the diagram, the cell shows both the glyph and its code point.
The top-left glyph image has coordinate (0, 0) and the bottom-right glyph image has coordinate (15, 13). We can define a simple equation that goes from glyph coordinates to code point, just like we did for pixel coordinates to pixel address:
code_point = glyph_x + glyph_y * glyphs_per_row + 32

Why the + 32? Because the first glyph has code point 32 (space). Without it, we'd get 0 for glyph_x = 0 and glyph_y = 0.
We can reverse this glyph coordinates to code point mapping as follows:
glyph_x = (code_point - 32) % glyphs_per_row;
glyph_y = (code_point - 32 - glyph_x) / glyphs_per_row;

The % glyphs_per_row basically strips the glyph_y * glyphs_per_row component from the original equation above, leaving us with the glyph x-coordinate.
To calculate glyph_y, we can then subtract the just calculated glyph_x, which gives us the code point of the first glyph in the row, and divide by glyphs_per_row to arrive at the glyph_y coordinate.
All that's left to get the pixel coordinate of the top left corner of a glyph is to multiply the glyph coordinates by the glyph pixel width and height of the font, 8 and 16 in the example above.
glyph_pixel_x = glyph_x * glyph_width;
glyph_pixel_y = glyph_x * glyph_height;

Blitting regions
Alright, we can generate glyph atlases for the first 255 Unicode code points, and we can calculate the pixel coordinates of a glyph image in the atlas corresponding to a code point. We also know the size of each glyph in pixels, as we specified that when generating the glyph atlas.
But we have one more problem: our current blitting functions can only blit an entire r96_image. What we need is blitting functions that blit just a region from a r96_image. Luckily, that's trivial, given our existing blitting functions! Here's a blitting function that blits a region from one r96_image to another.

void r96_blit_region(r96_image *dst, r96_image *src, int32_t dst_x, int32_t dst_y, int32_t src_x, int32_t src_y, int32_t src_width, int32_t src_height) {
	assert(src_x + src_width - 1 < src->width);
	assert(src_y + src_height - 1 < src->height);

	int32_t dst_x1 = dst_x;
	int32_t dst_y1 = dst_y;
	int32_t dst_x2 = dst_x + src_width - 1;
	int32_t dst_y2 = dst_y + src_height - 1;
	int32_t src_x1 = src_x;
	int32_t src_y1 = src_y;

	if (dst_x1 >= dst->width) return;
	if (dst_x2 < 0) return;
	if (dst_y1 >= dst->height) return;
	if (dst_y2 < 0) return;

	if (dst_x1 < 0) {
		src_x1 -= dst_x1;
		dst_x1 = 0;
	}
	if (dst_y1 < 0) {
		src_y1 -= dst_y1;
		dst_y1 = 0;
	}
	if (dst_x2 >= dst->width) dst_x2 = dst->width - 1;
	if (dst_y2 >= dst->height) dst_y2 = dst->height - 1;

	int32_t clipped_width = dst_x2 - dst_x1 + 1;
	int32_t dst_next_row = dst->width - clipped_width;
	int32_t src_next_row = src->width - clipped_width;
	uint32_t *dst_pixel = dst->pixels + dst_y1 * dst->width + dst_x1;
	uint32_t *src_pixel = src->pixels + src_y1 * src->width + src_x1;
	for (int32_t y = dst_y1; y <= dst_y2; y++) {
		for (int32_t i = 0; i < clipped_width; i++) {
			*dst_pixel++ = *src_pixel++;
		}
		dst_pixel += dst_next_row;
		src_pixel += src_next_row;
	}
}

This is basically our old r96_blit() function with additional arguments. We sepcify the destination (dst) and source (src) image as before. We also specify the coordinates (dst_x, dst_y) at which the source image should be blitted in the destination image. Those used to be called x and y. Finally, we specify the region from the source image we want to blit, given as its top-left corner (src_x, src_y) and width and height (src_width, src_height).
The implementation itself then only has three minor modifications compared to r96_blit().
The function starts with two asserts that ensure that the source region is valid. Next, dst_x2 and dst_y2 are calculated using the source region width and height instead of the source image width and height. Finally, src_x1 and src_y1 aren't initialized to 0, but to src_x and src_y.
That's it! The rest, including the clipping, is exactly the same as r96_blit(). We can already use this function to blit glyph images from the glyph atlas. And for some use cases, that'd be good enough.
However, if we only want to blit the white pixels of a glyph and ignore it's background pixels, we need color keying.
Easy, just copy r96_blit_keyed() and apply the same modifications.

void r96_blit_region_keyed(r96_image *dst, r96_image *src, int32_t dst_x, int32_t dst_y, int32_t src_x, int32_t src_y, int32_t src_width, int32_t src_height, uint32_t color_key) {
	assert(src_x + src_width - 1 < src->width);
	assert(src_y + src_height - 1 < src->height);

	int32_t dst_x1 = dst_x;
	int32_t dst_y1 = dst_y;
	int32_t dst_x2 = dst_x + src_width - 1;
	int32_t dst_y2 = dst_y + src_height - 1;
	int32_t src_x1 = src_x;
	int32_t src_y1 = src_y;

	if (dst_x1 >= dst->width) return;
	if (dst_x2 < 0) return;
	if (dst_y1 >= dst->height) return;
	if (dst_y2 < 0) return;

	if (dst_x1 < 0) {
		src_x1 -= dst_x1;
		dst_x1 = 0;
	}
	if (dst_y1 < 0) {
		src_y1 -= dst_y1;
		dst_y1 = 0;
	}
	if (dst_x2 >= dst->width) dst_x2 = dst->width - 1;
	if (dst_y2 >= dst->height) dst_y2 = dst->height - 1;

	int32_t clipped_width = dst_x2 - dst_x1 + 1;
	int32_t dst_next_row = dst->width - clipped_width;
	int32_t src_next_row = src->width - clipped_width;
	uint32_t *dst_pixel = dst->pixels + dst_y1 * dst->width + dst_x1;
	uint32_t *src_pixel = src->pixels + src_y1 * src->width + src_x1;
	for (dst_y = dst_y1; dst_y <= dst_y2; dst_y++) {
		for (int32_t i = 0; i < clipped_width; i++) {
			uint32_t src_color = *src_pixel;
			uint32_t dst_color = *dst_pixel;
			*dst_pixel = src_color != color_key ? src_color : dst_color;
			src_pixel++;
			dst_pixel++;
		}
		dst_pixel += dst_next_row;
		src_pixel += src_next_row;
	}
}

But we can do even better. No text rendering engine is complete without support for colored text! As is stands, we can only draw white text, as that's the color the glyph atlas generator spits out. On-top of color keying, we can also apply what's usually known as tinting.
We'll implement tinting in the simplest possible way: multiply the red, green, and blue color component of the source pixel with the red, green, and blue color component of the specified tinting color. That result of the multiplication is then normalized back to the 0-255 range for each component by dividing by 255. This effectively mixes the two colors.
tinted_red = ((source_red * tint_red) >> 8) & 0xff;
tinted_green = ((source_green * tint_green) >> 8) & 0xff;
tinted_blue = ((source_blue * tint_blue) >> 8) & 0xff;


Note: for the case of tinting glyphs images as generated by the generator, we could just write the tint color to the destination if the source pixel color doesn't match the color key. However, this approach above also works for tinting arbitrary source pixel colors. We'll see why that's useful in a later demo.

Here's the final region blitting routine, which takes both a color key and a tinting color:

void r96_blit_region_keyed_tinted(r96_image *dst, r96_image *src, int32_t dst_x, int32_t dst_y, int32_t src_x, int32_t src_y, int32_t src_width, int32_t src_height, uint32_t color_key, uint32_t tint) {
	assert(src_x + src_width - 1 < src->width);
	assert(src_y + src_height - 1 < src->height);

	int32_t dst_x1 = dst_x;
	int32_t dst_y1 = dst_y;
	int32_t dst_x2 = dst_x + src_width - 1;
	int32_t dst_y2 = dst_y + src_height - 1;
	int32_t src_x1 = src_x;
	int32_t src_y1 = src_y;

	if (dst_x1 >= dst->width) return;
	if (dst_x2 < 0) return;
	if (dst_y1 >= dst->height) return;
	if (dst_y2 < 0) return;

	if (dst_x1 < 0) {
		src_x1 -= dst_x1;
		dst_x1 = 0;
	}
	if (dst_y1 < 0) {
		src_y1 -= dst_y1;
		dst_y1 = 0;
	}
	if (dst_x2 >= dst->width) dst_x2 = dst->width - 1;
	if (dst_y2 >= dst->height) dst_y2 = dst->height - 1;

	uint32_t tint_r = R96_R(tint);
	uint32_t tint_g = R96_G(tint);
	uint32_t tint_b = R96_B(tint);

	int32_t clipped_width = dst_x2 - dst_x1 + 1;
	int32_t dst_next_row = dst->width - clipped_width;
	int32_t src_next_row = src->width - clipped_width;
	uint32_t *dst_pixel = dst->pixels + dst_y1 * dst->width + dst_x1;
	uint32_t *src_pixel = src->pixels + src_y1 * src->width + src_x1;
	for (dst_y = dst_y1; dst_y <= dst_y2; dst_y++) {
		for (int32_t i = 0; i < clipped_width; i++) {
			uint32_t src_color = *src_pixel;
			uint32_t dst_color = *dst_pixel;
			*dst_pixel = src_color != color_key ? R96_ARGB(
														  R96_A(src_color),
														  ((R96_R(src_color) * tint_r) >> 8) & 0xff,
														  ((R96_G(src_color) * tint_g) >> 8) & 0xff,
														  ((R96_B(src_color) * tint_b) >> 8) & 0xff)
												: dst_color;
			src_pixel++;
			dst_pixel++;
		}
		dst_pixel += dst_next_row;
		src_pixel += src_next_row;
	}
}

Since we've already extensively benchmarked and optimized the original blitter functions, and since these new functions only change some setup code, we have no need to do another optimization pass. Whew.
Alright, let's put everything we learned into a little demo.
Demo: Blitting regions
In this demo, we are going to blit the glyphs for the string ""Hello world!"" sourced from the glyph atlas in assets/ibmvga.png, which I generated via Mario's BMFG. We'll apply what we learned and created above, from iterating UTF-8 encoded characters, calculating pixel coordinates for glyphs from code points, to blitting regions in various ways.
Here's 13_blit_region.c:

#include <MiniFB.h>
#include <stdlib.h>
#include <string.h>
#include ""r96/r96.h""

int main(void) {
	const int window_width = 320, window_height = 240;
	struct mfb_window *window = mfb_open(""13_blit_region"", window_width, window_height);
	r96_image output;
	r96_image_init(&output, window_width, window_height);

	r96_image glyph_atlas;
	int32_t glyph_width = 8;
	int32_t glyph_height = 16;
	int32_t glyphs_per_row = 16;
	r96_image_init_from_file(&glyph_atlas, ""assets/ibmvga.png"");

	do {
		r96_clear_with_color(&output, R96_ARGB(0xff, 0x22, 0x22, 0x22));

		const char *text = ""Hello world!"";
		uint32_t text_length = strlen(text);
		uint32_t char_index = 0;
		uint32_t x_offset = 100;
		while (char_index < text_length) {
			uint32_t code_point = r96_next_utf8_code_point(text, &char_index, text_length);
			int32_t glyph_x = (code_point - 32) % glyphs_per_row;
			int32_t glyph_y = (code_point - 32 - glyph_x) / glyphs_per_row;
			int32_t glyph_pixel_x = glyph_x * glyph_width;
			int32_t glyph_pixel_y = glyph_y * glyph_height;

			r96_blit_region(&output, &glyph_atlas, x_offset, 50, glyph_pixel_x, glyph_pixel_y, glyph_width, glyph_height);
			r96_blit_region_keyed(&output, &glyph_atlas, x_offset, 100, glyph_pixel_x, glyph_pixel_y, glyph_width, glyph_height, 0x0);
			r96_blit_region_keyed_tinted(&output, &glyph_atlas, x_offset, 150, glyph_pixel_x, glyph_pixel_y, glyph_width, glyph_height, 0x0, 0xffff00ff);
			x_offset += glyph_width;
		}

		if (mfb_update_ex(window, output.pixels, window_width, window_height) != STATE_OK) break;
	} while (mfb_wait_sync(window));
	return 0;
}

As usual, we start out by creating a window and an output r96_image to which we draw, which gets later drawn to the window.
Next, we define the properties of our glyph atlas and the glyphs contained there-in, and load the glyph atlas image.
In the main loop, we clear the output image, then iterate through the characters in the text string via r96_next_utf8_code_point(). We then calculate the glyph pixel coordinates for the code point in the glyph atlas and use that information to blit the glyph to the screen three times, using the normal blit, keyed blit, and keyed and tinted blit functions.
Take special note of x_offset. It specifies at what x-coordinate the next glyph will be blitted in the output image. As our font is monospaced, we can easily advance the drawing position on the x-axis by glyph_width. All glyphs have the same width. Variable width fonts are quite a bit more complex to get right in that regard.
And here is the web version.





Let's pack all of this up into re-useable code.
r96_font
Looking at the last demo, we can almost see a struct for fonts plop out:

r96_image glyph_atlas;
int32_t glyph_width = 8;
int32_t glyph_height = 16;
int32_t glyphs_per_row = 16;

This is the minimum information we need to store for a font to draw text with it, which translates to the following struct:

typedef struct r96_font {
	r96_image glyph_atlas;
	int32_t glyph_width, glyph_height;
	int32_t glyphs_per_row;
	int32_t tab_size;
} r96_font;

We load the glyph_atlas from an image file. glyph_width and glyph_height are parameters we'll need to specify when initializing the r96_image font. glyphs_per_row we can actually automatically deduce from the glyph atlas width and the glyph width, reducing the amount of parameters we need to specify when initializing a font. tab_size will make sense in a minute! Here's r96_font_init():

bool r96_font_init(r96_font *font, const char *path, int32_t glyph_width, int32_t glyph_height) {
	if (!r96_image_init_from_file(&font->glyph_atlas, path)) return false;
	font->glyph_width = glyph_width;
	font->glyph_height = glyph_height;
	font->glyphs_per_row = font->glyph_atlas.width / glyph_width;
	font->tab_size = 3;
	return true;
}

Unremarkable. And the corresponding r96_font_dispose():

void r96_font_dispose(r96_font *font) {
	r96_image_dispose(&font->glyph_atlas);
}

The rendering logic from the last example can be directly translated to a re-usable function. But we'll add two more features. We'll interpret \n and \t and adjust the rendering position for the next glyph accordingly.

void r96_text(r96_image *image, r96_font *font, const char *text, int32_t x, int32_t y, uint32_t tint) {
	int32_t cursor_x = x;
	int32_t cursor_y = y;
	uint32_t text_length = strlen(text);
	uint32_t index = 0;
	while (index < text_length) {
		uint32_t c = r96_next_utf8_code_point(text, &index, text_length);
		if (c == '\t') {
			cursor_x += font->tab_size * font->glyph_width;
			continue;
		}
		if (c == '\n') {
			cursor_x = x;
			cursor_y += font->glyph_height;			
			continue;
		}
		if (c < 32 || c > 255) {
			cursor_x += font->glyph_width;
			continue;
		}

		int32_t glyph_index = c - 32;
		int32_t glyph_x = (glyph_index % font->glyphs_per_row);
		int32_t glyph_y = (glyph_index - glyph_x) / font->glyphs_per_row;
		glyph_x *= font->glyph_width;
		glyph_y *= font->glyph_height;

		r96_blit_region_keyed_tinted(image, &font->glyph_atlas, cursor_x, cursor_y, glyph_x, glyph_y, font->glyph_width, font->glyph_height, 0x0, tint);

		cursor_x += font->glyph_width;
	}
}

The function takes the image we want to render the text to, the font to render with, the text as a null-terminated UTF-8 string, and the x and y position to start rendering the first glyph at in the image. It's final parameter is the tint color.
Inside the function, we keep track of the position to render the next glyph at in cursor_x and cursor_y. We also keep track of the text length in bytes and the byte index from which we'll read the next Unicode code point from the text.
The loop then iterates over all code points in the text via r96_next_utf8_code_point(). In case we encounter \t, we advance the cursor position by font->tab_size * font->glyph_width and continue on to the next glyph. In case of \n, we reset cursor_x to the original x, essentially moving the cursor to the beginning of the text line. We then increase cursor_y by the glyph height to move it to the next line below. Yay, multi-line rendering!
Before we actually render the glyph for the current code point, we also check that the code point is within 32-255, so we don't try to draw a glyph that's not inside the glyph atlas.
The remainder of the function maps the code point to the glyph in the glyph atlas and uses r96_blit_region_keyed_tinted() to draw the glyph to the current cursor position. Finally, we advance the cursor by the glyph width.
Not counting the region blitting functions, the entire text rendering code code is about 70 LOC now. Let's add a few more lines of code.
In the previous demo, we positioned the glyphs at hard coded coordinates. If we wanted to center the text on the screen, or apply other alignments, we need to know the width and height of the text, also known as its bounds.
Let's write a little function that calculates exactly that.

void r96_font_get_text_bounds(r96_font *font, const char *text, int32_t *width, int32_t *height) {
	*width = 0;
	*height = font->glyph_height;
	int32_t current_line_width = 0;
	uint32_t text_length = strlen(text);
	uint32_t index = 0;
	while (index < text_length) {
		uint32_t c = r96_next_utf8_code_point(text, &index, text_length);
		if (c == '\t') {
			current_line_width += font->tab_size * font->glyph_width;
			continue;
		}
		if (c == '\n') {
			*width = current_line_width > *width ? current_line_width : *width;
			*height += font->glyph_height;
			current_line_width = 0;
			continue;
		}
		current_line_width += font->glyph_width;
	}
	*width = current_line_width > *width ? current_line_width : *width;
}

The function takes the font that the text will be rendered with, as well as pointers width and height to which we write the calculated bounds.
The function then mirrors parts of the rendering logic in r96_text(), calculating the maximum line width, as well as how many lines there actually are.
Alright, let's use all this in a little demo.
Demo: using r96_font and friends
Here's 14_fonts.c, our cute font demo:

#include <MiniFB.h>
#include <stdlib.h>
#include ""r96/r96.h""

int main(void) {
	const int window_width = 320, window_height = 240;
	struct mfb_window *window = mfb_open(""14_fonts"", window_width, window_height);
	r96_image output;
	r96_image_init(&output, window_width, window_height);
	r96_font font;
	r96_font_init(&font, ""assets/ibmvga.png"", 8, 16);

	do {
		r96_clear_with_color(&output, R96_ARGB(0xff, 0x22, 0x22, 0x22));

		const char *text = ""The quick brown fox jumps\nover the lazy dog\n""
						   ""¬°¬¢¬£¬§¬•¬¶¬ß¬®¬©¬™¬´¬¨\n""
						   ""√Ä√Å√Ç√É√Ñ√Ö√Ü√á√à√â√ä√ã√å√ç√é√è"";

		int32_t text_x, text_y, text_width, text_height;
		r96_font_get_text_bounds(&font, text, &text_width, &text_height);
		text_x = window_width / 2 - text_width / 2;
		text_y = window_height / 2 - text_height / 2;

		r96_rect(&output, text_x, text_y, text_width, text_height, R96_ARGB(0xff, 0xff, 0x0, 0xff));
		r96_text(&output, &font, text, text_x + 1, text_y + 1, 0x00000000);
		r96_text(&output, &font, text, text_x, text_y, 0xffffffff);

		if (mfb_update_ex(window, output.pixels, window_width, window_height) != STATE_OK) break;
	} while (mfb_wait_sync(window));
	return 0;
}

We start off by loading the font in line 11, specifying the glyph atlas image path, the glyph width, and the glyph height. r96_font_init loads the glyph atlas image and sets up all the fields of the font as we saw earlier.
In the main loop, we clear the output image, then define the text we want to render. The text consists of 3 lines, using characters from the code point range we support.
The next block of code calculates the bounds of the text via r96_font_get_text_bounds(), which we use to calculate the text's top-left corner position in such a way, that the text is centered in the middle of the screen.
In the final block, we render a background rectangle using the text bounds, followed by rendering the text offset by 1 pixel on both axes with a black tint. Finally, we render the text at the calculated position with a white tint. Rendering the text twice this way gives us a simple shadow effect. Here's the demo running on the web.





Great success.
Demo: fun with fonts
While the original IBM VGA font is nice, it's also a bit of an outdated, and dare I say boring look.
I've added two more glyph atlases to the assets/ folder. The first one is derived from the awesome Tamzen font (assets/tamzen.png).




It has a lighter, more modern appearance and is well suited to display stats, like performance counters.
The other font was ripped from some old demo from the 90ies by Ian Hanschen. He's put up a GitHub repo with a gargantuan amount of ripped fonts. Most of them do not have attribution. This is the one I picked (assets/demofont.png).




Each font is basically just a glyph atlas. However, the atlas layout doesn't match the one generated by BMFG.
For the font I picked, we see that it only contains glyphs for the first few code points. Instead of 16 glyphs, it contains 20 glyphs per row. Thankfully, r96_init_font() can deal with this by calculating the number of glyphs per row based on the glyph atlas width and glyph width. The only thing we need to watch out for is to not use any code points that go above Z in our text strings.
This demo doesn't come with an explanation. Consider it to be a puzzle for your brain noggins! Can you figure out how it works? 15_font_fun.c:

#include <MiniFB.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>
#include ""r96/r96.h""

int main(void) {
	const int window_width = 320, window_height = 240;
	struct mfb_window *window = mfb_open(""15_font_fun"", window_width, window_height);
	r96_image output;
	r96_image_init(&output, window_width, window_height);
	r96_font font;
	r96_font_init(&font, ""assets/demofont.png"", 16, 16);
	float counter = 0;
	struct mfb_timer *timer = mfb_timer_create();
	do {
		r96_clear_with_color(&output, R96_ARGB(0xff, 0x22, 0x22, 0x22));

		const char *text = ""--(2022 DEMO CREW)--"";
		int32_t text_x = 0;
		uint32_t text_length = strlen(text);
		uint32_t char_index = 0;
		while (char_index < text_length) {
			char character[] = {0, 0};
			character[0] = (char) r96_next_utf8_code_point(text, &char_index, text_length);
			int32_t text_y = output.height / 2 - font.glyph_width / 2 + (int32_t) (sinf(counter + char_index / 10.0f) * output.height / 4);
			r96_text(&output, &font, character, text_x, text_y, 0xffffffff);
			text_x += font.glyph_width;
		}

		counter += M_1_PI * mfb_timer_delta(timer) * 12;
		mfb_timer_reset(timer);

		if (mfb_update_ex(window, output.pixels, window_width, window_height) != STATE_OK) break;
	} while (mfb_wait_sync(window));
	return 0;
}

And here it is in action.





Next time on ""Mario writes a lot of words""
Our little code base is shaping up to be kinda useful. Next time, we're going to look into drawing lines. Possibly with sub-pixel precision. Unless I can't figure that out.
Discuss this post on Twitter or Mastodon.




"
https://news.ycombinator.com/rss,The IAB loves tracking users. But it hates users tracking them,https://shkspr.mobi/blog/2023/01/the-iab-loves-tracking-users-but-it-hates-users-tracking-them/,Comments,"The IAB loves tracking users. But it hates users tracking them.By 
@edent

 on 
2023-01-16
advertising email privacy12¬†comments550¬†words
The Interactive Advertising Bureau (IAB) is a standards development group for the advertising industry. Their members love tracking users. They want to know where you are, who you're with, what you're buying, and what you think. All so they can convince you to spend slightly more on toothpaste.  Or change your political opinions. Either way, they are your adversaries.The IAB's tech lab is working on a system called UID2. It's a more advanced way to track you no matter what you do and no matter what steps you take to avoid it.
UID2 is a framework that enables deterministic identity for advertising opportunities on the open internet for many participants across the advertising ecosystem. The UID2 framework enables logged-in experiences from publisher websites, mobile apps, and Connected TV (CTV) apps to monetize through programmatic workflows.Basically, they tie your email address to everything you do. Signed in to watch a TV show? Better sell that info to the advertisers so when you sign in to a different site they can send you targetted messages. Yuck.One of the ways privacy conscious users normally avoid this is by subtly altering their email addresses for each service they use.  For example, GMail ignores any dots in your username. So if you are Han.Solo@gmail.com you can also use H.ansolo@gmail.com or ha.ns.ol.o@gmail.com.  A user might sign up to a service and use a specifically ""dotted"" email address.  If they later start receiving spam to that address, they know the service has leaked or sold their info.You can go one step further and use plus addressing.  For example han.solo+amazon@gmail.com and han.solo+github@gmail.com. They both will appear in your normal inbox, but are unique for every service you use. Again, this is great for making sure that someone hasn't sold your email address to spammers.The IAB hates this.As part of the UID2 API they specifically describe how an advertiser must ""normalise"" their users' email addresses.This means h.a.n.solo+iab@gmail.com becomes plain old hansolo@gmail.comI think this is pretty shitty behaviour. If someone has deliberately set their email address in this form it is because the user does not want their identities to be commingled.Last year, I asked them to respect users' privacy and reverse this change.  They finally responded:
Thank you for your input, we thought long about this update and ultimately as it stands today it is not a change we would like to add.So, there you have it. If you want to take even the smallest step to preserve your privacy - tough.
If you want to track which IAB members are using your data - tough.
If you want to track users even if they don't want to be tracked - the IAB is happy to help.If you want to opt out of this - and you trust the IAB to handle your data safely - you can submit your email address and phone number to https://transparentadvertising.org/.Personally, I recommend installing the uBlock advert blocker on all devices which support it.Share the love:MastodonTwitterFacebookLinkedInRedditHackerNewsLobstersEmailPocketWhatsAppTelegramMore posts from around the site:
12 thoughts on ‚ÄúThe IAB loves tracking users. But it hates users tracking them.‚Äù

2023-01-16 12:38

 Ian Betteridge says:@Edent I‚Äôve noticed several brands now blocking services like iCloud‚Äôs relay, which lets you sign up with a random email address that‚Äôs not related to yours. Firefox relays ducks around that by letting you use your own domain, which makes it much harder for them to block sign-ups, but that‚Äôs obviously only applicable to a few users.Reply

2023-01-16 12:55

 Gabor says:I've been loving fastmail's masked email functionality, which gives you a random email alias like ""salty.hotdog8233@fastmail.com"", plus it has 1password integration, so signing up to places is fairly straightforward if you use 1p.Reply

2023-01-16 13:00

 That Privacy Guy says:I just read this and the solution I use is my own instance of AnonAddy - and I create a new and unique email address for every site/service I use. If you don't want to run it yourself there is a SaaS version - plus it is FOSS.


Reply

2023-01-16 13:40

 HackerNewsTop10 says:The IAB loves tracking users. But it hates users tracking them
Link: shkspr.mobi/blog/2023/01/t‚Ä¶
Comments: news.ycombinator.com/item?id=344000‚Ä¶Reply

2023-01-16 13:42

 Kazaii says:@Edent wow, that's rather unsettling. Thanks for shedding light on this.Reply

2023-01-16 13:49

 That Privacy Guy says:I have been using my own installation of AnonAddy for a couple of years now. I used to just have a catchall in my mail server which would forward anything which was sent to a non existing email address to a delegated account



Reply

2023-01-16 13:55

 Fazal Majid says:The plus convention is not specific to GMail (Sendmail, MS Exchange, Postfix and other email software have it), but they only require stripping it for @gmail.com domains. I have my own dedicated domain for vendors so I won't be impacted, and Apple's email masking feature will do the same, along with competing offerings from DuckDuckGo et al.Hashing PII like an email is also PII and this proposal is a blatant violation of GDPR, of course.Reply

2023-01-16 13:55

 Nikki says:Personally my opinion of anyone involved in advertising is so poor that I'd probably not be allowed to express it here. I can easily imagine a world without advertising as the web allows you to find anything you want without having someone trying to force it down your throat. Also the idea that many parts of the web could not exist without advertising support is facile. It's a bit like saying that free and open parks cannot exist without employing pick pockets to gather funds to pay for maintenance. If there are any parts of the web that really can not exist without advertising, they must be so bankrupt of alternatives ideas that their services could not be trusted to be useful.Reply

2023-01-16 15:09

 Anonymous says:A link says uBlock but points to uBlock Origin. uBlock is different from uBlock Origin: https://github.com/gorhill/uBlock/wiki/uBlock-Origin-is-completely-unrelated-to-the-web-site-ublock.orgReply

2023-01-16 15:21

 Oli says:I‚Äôm a big fan of Fastmail‚Äôs masked addresses for this reason.Word dot word four digit number at my own domain, goes in the password manager, never thought about again!Reply

2023-01-16 15:44

 Privacy Matters says:Hi @IABTechLab  What is the legal basis relied on  to alter the email identities of individuals who will be targeted by those using UID2?Oh, & I note domain reg details for transparentadvertising.org are redacted for privacy reasons. Who owns the domain pls?

Reply

2023-01-16 15:56

 trinity says:I own my name dot [tld] so I can do slingshit@me.com. Looks like I'm still gonna be doing alright. Cloudflare's mail forwarding works well for this, before that I used ImprovMX. Both just point the proper DNS records from your site to someone's mail server for quick relay+disposal. I imagine having all mail filter through a magic box is technically A Bit Troublesome but it's still better than Google Mail!ReplyLeave a Reply Cancel replyYour email address will not be published. Required fields are marked *Comment *Name * Email * Website  Notify me of follow-up comments by email. Notify me of new posts by email. 
Œî
To respond on your own website, enter the URL of your response which should contain a link to this post's permalink URL. Your response will then appear (possibly after moderation) on this page. Want to update or remove your response? Update or delete your post and re-enter your post's URL again. (Learn More)



"
https://news.ycombinator.com/rss,Using paleogenomics to elucidate 10k years of immune system evolution,https://www.pasteur.fr/en/press-area/press-documents/using-paleogenomics-elucidate-10000-years-immune-system-evolution,Comments,"



You are hereHomePress areaPress documentsUsing paleogenomics to elucidate 10,000 years of immune system evolution








Using paleogenomics to elucidate 10,000 years of immune system evolution 



¬© Adobe Stock








  
      Press release  




2023.01.13




Print
|

Share
   





Scientists from the Institut Pasteur, Universit√© Paris Cit√©, the CNRS and the Coll√®ge de France have used paleogenomics to trace 10,000 years of human immune system evolution. They analyzed the genomes of more than 2,800 individuals who lived in Europe over the past ten millennia. They were able to date the increase in frequency of most of the mutations that are advantageous in defending against pathogens to after the Bronze Age, 4,500 years ago. The scientists also observed that mutations conferring a higher risk of developing inflammatory disorders have become more frequent over the past 10,000 years. These enlightening results on the effects of natural selection on immunity genes were published in the journal Cell Genomics on January 13, 2023. 
In the 1950s, the geneticist J.B.S. Haldane attributed the maintenance or persistence of the mutation responsible for anomalies in red blood cells commonly observed in Africa to the protection these anomalies provided against malaria, an endemic infection that claims millions of lives. This theory suggested that pathogens are among the strongest selective pressures faced by humans. Several population genetics studies subsequently confirmed the theory. But major questions remained, especially regarding the specific epochs during which the selective pressures exerted by pathogens on human populations were strongest and their impact on the present-day risk of developing inflammatory or autoimmune disorders.
To address these questions, scientists from the Institut Pasteur, Universit√© Paris Cit√©, the CNRS and the Coll√®ge de France, in collaboration with the Imagine Institute and The Rockefeller University (United States), adopted an approach based on paleogenomics. This discipline, which studies the DNA from fossil remains, has led to major discoveries about the history and evolution of humans and human diseases, as illustrated by the decision to award the 2022 Nobel Prize in Physiology or Medicine to the paleogeneticist Svante P√§√§bo. In the study led by the Institut Pasteur, published on January 13 in the journal Cell Genomics, the scientists analyzed the variability of the genomes of more than 2,800 individuals who lived in Europe over the past ten millennia ‚Äì a period covering the Neolithic, the Bronze Age, the Iron Age, the Middle Ages and the present.
By reconstituting the evolution over time of hundreds of thousands of genetic mutations, the scientists initially identified mutations that rapidly increased in frequency in Europe, indicating that they were advantageous. These mutations that evolved under ""positive"" natural selection are mainly located in 89 genes enriched in functions relating to the innate immune response, including especially the OAS genes ‚Äì which are responsible for antiviral activity ‚Äì and the gene responsible for the ABO blood group system. Surprisingly, most of these positive selection events, which demonstrate a genetic adaptation to the pathogenic environment, began recently, from the start of the Bronze Age, around 4,500 years ago. The scientists explain this ""acceleration"" in adaptation by the growth in the human population during this period and/or by strong selective pressures exerted by pathogens in the Bronze Age, probably linked to the spread of severe infectious diseases such as plague.
At the same time, the scientists also looked at the opposite situation, in other words, mutations whose frequency fell significantly over the past ten millennia. These mutations are probably subject to ""negative"" selection because they increase the risk of disease. They noted that once again, these selection events mainly began in the Bronze Age. Many of these disadvantageous mutations were also located in genes associated with the innate immune response, such as TYK2, LPB, TLR3 and IL23R, and have been confirmed in experimental research to have a deleterious effect in terms of infectious disease risk. The results emphasize the value of adopting an evolutionary approach in research on genetic susceptibility to infectious diseases.
Finally, the scientists explored the theory that the selection exerted by pathogens in the past gave an advantage to alleles conferring resistance to infectious diseases, but that in turn these alleles have increased the present-day risk of autoimmune or inflammatory disorders. They investigated the few thousand mutations known to increase susceptibility firstly to tuberculosis, hepatitis, HIV or COVID-19, and secondly to rheumatoid arthritis, systemic lupus erythematosus or inflammatory bowel disease. By looking at the evolution of these mutations over time, they observed that those associated with an increased risk of inflammatory disorders ‚Äì including Crohn's disease ‚Äì became more frequent over the past 10,000 years, while the frequency of those associated with a risk of developing infectious diseases decreased. ""These results suggest that the risk of inflammatory disorders has increased in Europeans since the Neolithic period because of a positive selection of mutations improving resistance to infectious diseases,"" explains Lluis Quintana-Murci, director of the study and Head of the Human Evolutionary Genetics Unit (Institut Pasteur/CNRS Evolutionary Genomics, Modeling and Health Unit/Universit√© Paris Cit√©).
The results of the study, which harnessed the huge potential of paleogenomics, show that natural selection has targeted human immunity genes over the past ten millennia in Europe, especially since the start of the Bronze Age, and contributed to present-day disparities in terms of the risk of infectious and inflammatory diseases.
As well as the institutions mentioned above, this research was supported by the French Foundation for Medical Research (FRM), the Allianz-Institut de France Foundation and the Fondation de France. 





Explanatory diagram. ¬© Gaspard Kerner, Institut Pasteur
Source
Genetic adaptation to pathogens and increased risk of inflammatory disorders in post-Neolithic Europe, Cell Genomics, January 13, 2023
Gaspard Kerner,1* Anna-Lena Neehus,2,3 Quentin Philippot,2,3 Jonathan Bohlen,2,3 Darawan Rinchai,4 Nacim Kerrouche,4 Anne Puel,2,3 Shen-Ying Zhang,2,3,4 St√©phanie Boisson-Dupuis,2,3,4 Laurent Abel,2,3,4 Jean-Laurent Casanova,2,3,4,5,6 Etienne Patin,1,8 Guillaume Laval,1,8 and Lluis Quintana-Murci,1,7,8,9,*
1Institut Pasteur, Universit√© Paris Cit√©, CNRS UMR2000, Human Evolutionary Genetics Unit, F-75015 Paris, France
2Laboratory of Human Genetics of Infectious Diseases, INSERM UMR 1163, Necker Hospital for Sick Children, 75015 Paris, France.
3University Paris Cit√©, Imagine Institute, 75015 Paris, France.
4St. Giles Laboratory of Human Genetics of Infectious Diseases, The Rockefeller University, New York, NY 10065, United States.5Howard Hughes Medical Institute, New York, NY 10065, United States
6Department of Pediatrics, Necker Hospital for Sick Children, 75015 Paris, France
7Coll√®ge de France, Chair of Human Genomics and Evolution, F-75005 Paris, France
8Senior author
9Lead contact
*Corresponding author
¬†









"
https://news.ycombinator.com/rss,Intro to GCC bootstrap in RISC-V,https://ekaitz.elenq.tech/bootstrapGcc0.html,Comments,"


Ekaitz's tech blog


















Home
Series



Feed
About

 





Ekaitz's tech blog:I make stuff at ElenQ Technology and I talk about it



Intro to GCC bootstrap in RISC-V



      Mon 14 February 2022
    

      By           Ekaitz Z√°rraga



You probably already know about how I spent more than a year having fun with
RISC-V and software bootstrapping from¬†source.
As some may know from my FOSDEM talk, NLNet / NGI-Assure put the
funds to make me spend more time on this for this year and I decided
to work on GCC‚Äôs bootstrapping process for RISC-V.
Why GCC
GCC is probably the most used compiler collection, period.  With GCC we can
compile the world and have a proper distribution directly from source, but who
compiles the compiler?1
Well, someone has¬†to.
The¬†bootstrap
Bootstrapping a compiler with a long history like GCC for a new architecture
like RISC-V involves some complications, starting on the fact that the first
version of GCC that supports RISC-V needs a C++98 capable compiler in order to
build. C++98 is a really complex standard, so there‚Äôs no way we can bootstrap a
C++98 compiler at the moment for RISC-V. The easiest way we can think of at
this point is to use an older version of GCC for that, one of those that are
able to build C++98 programs but they only require a C compiler to build. Older
versions of GCC, of course, don‚Äôt have RISC-V support so‚Ä¶ We need a
backport2.
So that‚Äôs what I‚Äôm doing right now. I‚Äôm taking an old version of GCC that only
depends on C89 and is able to compile C++98 code and I‚Äôm porting it to RISC-V
so we can build newer GCCs with¬†it.
Only needing C to compile it‚Äôs a huge improvement because there are Tiny C
Compilers out there that can compile C to RISC-V, and those are written using
simple C that we can bootstrap with simpler tools of a more civilized¬†world.
In¬†summary:

C++98 is too complex, but C89 is¬†fine.
GCC is the problem and also the¬†solution.

What about GNU¬†Mes?
When we3 started with this effort we wanted to prepare GNU Mes, a small C
compiler that is able to compile a Tiny C Compiler, to work with RISC-V so we
could start to work in this bootstrap process from the¬†bottom.
Some random events, like someone else working on that part, made us rethink our
strategy so we decided to start from the top and try to combine both efforts at
the end. We share the same goal: full source bootstrap for RISC-V.
Tiny C¬†Compilers?
There are many small C compilers out there that are written in simple C and are
able to compile an old GCC that is written in C. Our favorite is TinyCC (Tiny C¬†Compiler).
GNU Mes is able to build a patched version of TinyCC, which already supports
RISC-V (RV64 only), and we can use that TinyCC to compile the GCC version I‚Äôm¬†backporting.
We‚Äôd probably need to patch some things in both projects to make everything
work smoothly but that‚Äôs also included in the project¬†plan.
Binutils
Binutils is also a problem mostly because GCC, as we will talk about in the
future, does not compile to binary directly. GCC generates assembly code and
coordinates calls to as and ld (the GNU Assembler and Linker) to generate
the final binaries. Thankfully, TinyCC can act as an assembler and a linker,
and there‚Äôs also the chance to compile a modern binutils version because it is
written in¬†C.
In any case, the binary file generation and support must be taken in account,
because GCC is not the only actor in this film and RISC-V has some weird things
on the assembly and the binaries that have to be supported¬†correctly.
Conclusion
This is a very interesting project, where I need to dig in BIG stuff, which
is cool, but also has a huge level of uncertainty, which scares the hell out of
me. I hope everything goes¬†well‚Ä¶
In any case, I‚Äôll share all I learn here in the blog and I keep you all posted
with the news we¬†have.
That‚Äôs all for this time. If you have any question or comment or want to share
your thoughts and feelings with me5 you can find my
contact information here.


PS: Big up to NlNet / NGI-Assure for the¬†money.










wHo wATcHes tHE wAtchMEN?¬†‚Ü©


Insert ‚ÄúBack to the Future‚Äù music here.¬†‚Ü©


‚ÄúWe‚Äù means I shared my thoughts and plans with other people who have a
  much better understanding of this than myself.¬†‚Ü©


But there are some others that are really interesting (see
cproc, for example)¬†‚Ü©


Or even hire me for some freelance IT stuff ü§ì¬†‚Ü©








          Supported by:
        











 



"
https://news.ycombinator.com/rss,"New Sony Walkman music players feature good looks, Android 12",https://arstechnica.com/gadgets/2023/01/new-sony-walkman-music-players-feature-stunning-good-looks-android-12/,Comments,"






      Where do you put the cassette tape?    ‚Äî

New Sony Walkman music players feature stunning good looks, Android 12
Sony holds onto the beautiful dream of standalone portable audio players. 


Ron Amadeo
    -  Jan 13, 2023 7:53 pm UTC

 




reader comments
238
 with 0 posters participating


Share this story

Share on Facebook
Share on Twitter
Share on Reddit












                    The Sony Walkman NW-A300. It's a shame Sony never became a force in smartphones, because, wow, their product designs are still so good.                  


                                          Sony                                      









                    Yep, that's regular Android.                   


                                          Sony                                      









                    The bottom. From left to right we've got a headphone jack, lanyard hole, USB-C port, and a microSD slot.                   


                                          Sony                                      









                    Music buttons! So many music buttons!                  


                                          Sony                                      









                    The back has this nice scallop texture.                   


                                          Sony                                      









                    The frame is aluminum.                   


                                          Sony                                      









                    It comes in colors. That gray one really hits me in the nostalgic Sony sweet spot.                   


                                          Sony                                      









                    There are little folio cases! They are so cute.                  


                                          Sony                                      









                    The folio case lets it stand up!                  


                                          Sony                                      





Sony has a pair of new Android Walkmans out, the NW-A300 and NW-ZX700. Yes, that's right, Walkmans, Sony's legendary music player brand from the 1980s. Apple may have given up on the idea of a smartphone-adjacent music player when it killed the iPod Touch line recently, but Sony still makes Android-powered Walkmans and has for a while. The first was in 2012 with the Android 2.3 Gingerbread-powered NWZ-Z1000, which looked like Sony just stripped the modem out of an Xperia phone and shoved it onto the market as a music player. Since then, Sony has made designs with more purpose-built hardware, and today there are a whole series of Android-powered Walkman music players out there. Sadly these new ones seem to only be for sale in Japan, the UK, and Europe, for now.
We'll start with the most consumer-friendly of the two, the NW-A300. This basic design debuted in 2019 with the NW-A105, but that shipped with Android 9. This is an upgraded version of that device with a less-ancient version of Android, a new SoC, and a scalloped back design. In Sony's home of Japan, the 32GB version is 46,000 yen (about $360), while in Europe, it's 399 euro (about $430).
The NW-A300 is a tiny little device that measures 56.6√ó98.5√ó12 mm, so pretty close to a deck of playing cards. And really, just look¬†at these pictures. Sony might not be the consumer electronics juggernaut it used to be, but it still has an incredible product design department. I have no use for a standalone music player, but both of these Walkmans are so pretty that I just want to hold one. 
Advertisement 


The front is dominated by a 3.6-inch, 60 Hz, 1280√ó720 touchscreen LCD. There's 32GB of storage, and the device supports Wi-Fi 802.11AC and Bluetooth 5. That's about all Sony wants to talk about for official specs. It touts ""longer battery life"" but won't say how big the battery is, promising only ""36 hours* of 44.1 KHz FLAC playback, up to 32 hours* of 96 KHz FLAC High-Resolution Audio playback."" Presumably, that's all with the screen off.
For more specs, we can visit The Walkman Blog, a wonderful site that is very serious about these little music players. In October, the site found documentation for the A300 listing a 1500 mAh battery. The system-on-a-chip in the older NW-A100 model was the NXP i.MX8M-Mini, a wildly slow 28 nm SoC that has just four Arm Cortex-A53 CPUs and 4GB of RAM. You can say, ""This is just a music player,"" but that's not really true since it still runs full Android with an app store and everything. Geekbench scores show this has a new quad-core Qualcomm chip of some kind with 4GB of RAM, but we can't be sure of the model number. A newer chip with smaller transistors would probably account for a lot of that ""better battery life"" promise.
This is a music player, so of course, there's a headphone jack on the bottom of the unit. You'll also find a spot for a lanyard, a speedy USB-C 3.2 Gen1 port for quick music transfers, and a MicroSD slot for storing all your music. Buttons along the side of the device also give you every music control you could want, like a hold switch, previous, play/pause, next, volume controls, and power.

Page: 1 2 Next ‚Üí













reader comments
238
 with 0 posters participating


Share this story

Share on Facebook
Share on Twitter
Share on Reddit







Ron Amadeo
      Ron is the Reviews Editor at Ars Technica, where he specializes in Android OS and Google products. He is always on the hunt for a new gadget and loves to rip things apart to see how they work.    

Email ron@arstechnica.com
//
Twitter @RonAmadeo








Advertisement 





















Channel Ars Technica




‚Üê Previous story Next story ‚Üí




Related Stories









Today on Ars







"
https://news.ycombinator.com/rss,Interactive Music Theory Cheat Sheet,https://muted.io/cheat-sheet/,Comments,"







                Music Theory Cheat Sheet: Keys, Scales, Chords, Notes & Intervals
              


üíñ share it ‚Üí






























  ‚ú®üéµ‚ú® An interactive music theory cheat sheet to get all you need at a
  glance:
  keys, scales, modes, notes, chords and
    intervals. 
  Just select a major or minor key and you'll get the notes of
  the scale, scale formula, the relative major or minor, modal scales for that
  key, scale degrees/intervals, the key signature, the diatonic chords, the
  diatonic 7th chords, the chord functions and the relationship with other keys
  on the Circle of Fifths (aka circle of
  fourth, when going counter-clockwise). 
  ‚Üí For more reference on chords and scales, you may like this
  scale formula chart,
  chord formula chart and this
  list of chords.














      C
    

      C‚ôØ


      D‚ô≠


      D
    

      D‚ôØ


      E‚ô≠


      E
    

      F
    

      F‚ôØ


      G‚ô≠


      G
    

      G‚ôØ


      A‚ô≠


      A
    

      A‚ôØ


      B‚ô≠


      B
    



      Major
    

      Minor
    



key:


C
C‚ôØ
D‚ô≠
D
D‚ôØ
E‚ô≠
E
F
F‚ôØ
G‚ô≠
G
G‚ôØ
A‚ô≠
A
A‚ôØ
B‚ô≠
B




      major
    

      minor
    









C‚ôØD‚ô≠


D


D‚ôØE‚ô≠


E


F


F‚ôØG‚ô≠


G


G‚ôØA‚ô≠


A


A‚ôØB‚ô≠


B





C‚ôØD‚ô≠


D


D‚ôØE‚ô≠


E


F


F‚ôØG‚ô≠


G


G‚ôØA‚ô≠


A


A‚ôØB‚ô≠


B








C
Major




C
Major
      Scale
    







formula:
1 2 3 4 5 6 7
1 2 ‚ô≠3 4 5 ‚ô≠6 ‚ô≠7
steps:
whole whole half
        whole whole whole half

whole half whole whole half
        whole whole




        relative minor ‚Üí
        A Minor












C
          Harmonic Minor Scale
        







formula:
1 2 ‚ô≠3 4 5 ‚ô≠6 7




C
          Melodic Minor Scale
        







formula:
1 2 ‚ô≠3 4 5 6 7





        relative major ‚Üí
        A Major










Modes of the Major Scale






C
          Major Pentatonic Scale
        







formula:
1 2 3 ¬† 5 6 ¬†




C
          Major Blues Scale
        







formula:
1 2 ‚ô≠3 3 5 ¬† 6 ¬†






C
          Minor Pentatonic Scale
        







formula:
1 ¬† ‚ô≠3 4 5 ¬† ‚ô≠7




C
          Minor Blues Scale
        







formula:
1 ¬† ‚ô≠3 4 ‚ô≠5 5 ¬† ‚ô≠7





C
Major
      Scale Degrees & Intervals
    


        1- Tonic:
        
          C
        
        ‚Üí Unison
      

        2- Supertonic:
        
          D
        
        ‚Üí Major 2nd
      

        3- Mediant:
        
          E
        
        ‚Üí
        Major 3rd
      

        4- Subdominant:
        
          F
        
        ‚Üí Perfect 4th
      

        5- Dominant:
        
          G
        
        ‚Üí Perfect 5th
      

        6- Submediant:
        
          A
        
        ‚Üí
        Major 6th
      

        7-
        Leading Tone:
        
          B
        
        ‚Üí
        Major 7th
      

        8/1- Octave/Tonic:
        
          C
        
        ‚Üí Perfect 8th
      





C
Major
        Key Signature & Notation
      



Theoretical Scale

        The
        

 scale
        
        is a theoretical scale that contains double accidentals. For this
        reason, that scale is not used often. The enharmonic equivalent scale is
        used instead most of the time.
      



C
Major
      Diatonic Chords
    




I
ii
iii
IV
V
vi
vii¬∞





C

C E G






Dm

D F A






Em

E G B






F








G








Am








B¬∞












C
      Major Diatonic 7th Chords
    




IM7
iim7
iiim7
IVM7
V7
vim7
vii√∏7





C

C E G B






Dm7

D F A C






Em

E G B D






F

F A C E






G








Am7








B√∏7












      In functional harmony for a major key:
      

          the tonic chords are chords
          I, iii & vi
        

          the subdominant chords are chords
          IV & ii
        

          the dominant chords are chords
          V & vii¬∞
        






i
ii¬∞
III
iv
v
VI
VII





C

C Eb G






D¬∞

D F Ab






Eb

Eb G Bb






Fm








Gm








A








B












C
      Natural Minor Diatonic 7th Chords
    




im7
ii√∏7
IIIM7
ivm7
vm7
VIM7
vii7





C

C Eb G Bb






Dm7

D F Ab C






Em

E G B D






F

F A C E






G








AM7








B7












      In functional harmony for a minor key:
      

          the tonic chords are chords
          i & III
        

          the subdominant chords are chords
          iv, VI & ii¬∞
        

          the dominant chords are chords
          V, v, VII & vii¬∞
        


        The harmonic minor scale has a
        raised 7th scale degree compared to the natural minor
        scale, which makes that 7th scale degree into a
        leading tone and makes the V chord a
        major chord. In functional harmony, that V chord from
        the harmonic minor scale is used most often because the leading tone
        gives a stronger sense of wanting to be resolved to the tonic.
      



C
Major
      on the Circle of Fifths
    













      Common
      C
      Chords
    

click to hear the different chords









Order of sharps
F C G D A E B


Order of flats
B E A D G C F


Chromatic Scale

C-D‚ô≠-D-E‚ô≠-E-F-G‚ô≠-G-A‚ô≠-A-B‚ô≠-B
alternative enharmonic spelling:
C-C‚ôØ-D-D‚ôØ-E-F-F‚ôØ-G-G‚ôØ-A-A‚ôØ-B



Solf√®ge syllables

Do Re Mi Fa So(l) La Ti Do



Accidentals

      Double Sharp: ùÑ™
      Sharp: ‚ôØ
      Natural: ‚ôÆ
      Flat: ‚ô≠
      Double Flat: ‚ô≠‚ô≠



Chord Symbols

      Major: M, maj, ‚ñ≥
      Minor: m, min, -
      Dominant 7th: 7, dom7
      Diminished: dim, ¬∞
      Half-diminished: m7b5, √∏
      Augmented: aug, +





I hope this music theory cheat sheet is useful! üòé
  
  You can get in touch with me here if you think I
  should add something else to this page.



Piano Samples

    The piano samples used for this music theory cheat sheet are from ‚Äú
    Salamander Grand Piano V3
    ‚Äù by Alexander Holm, licensed under
    CC BY 3.0.
  












That's me, Seb, I'm creating muted.io. üòÑ

      Consider supporting this site by
      making a small donation via ko-fi here. Your support means so much and goes directly towards allowing me to
      spend more time creating fun and useful things for muted.io. üôè
    
- Seb, ‚úåÔ∏è + ‚ù§Ô∏è




      Stay in the Loop
    



üòé Subscribe to be updated when I add something cool to the
            site:













"
https://news.ycombinator.com/rss,"Selfie ‚Äì A tiny RISC-V C compiler, emulator and hypervisor",http://selfie.cs.uni-salzburg.at/,Comments,"






selfie | An educational software system of a tiny self-compiling C compiler, a tiny self-executing RISC-V emulator, and a tiny self-hosting RISC-V hypervisor.

























selfie
An educational software system of a tiny self-compiling C compiler, a tiny self-executing RISC-V emulator, and a tiny self-hosting RISC-V hypervisor.
View the Project on GitHub cksystemsteaching/selfie

Download ZIP File
Download TAR Ball
View On GitHub



Selfie is a project of the Computational Systems Group at the Department of Computer Sciences of the University of Salzburg in Austria.
The Selfie Project provides an educational platform for teaching undergraduate and graduate students the design and implementation of programming languages and runtime systems. The focus is on the construction of compilers, libraries, operating systems, and even virtual machine monitors. The common theme is to identify and resolve self-reference in systems code which is seen as the key challenge when teaching systems engineering, hence the name.
README for an overview of the system and all available resources.


This project is maintained by cksystemsteaching
Hosted on GitHub Pages ‚Äî Theme by orderedlist





"
https://news.ycombinator.com/rss,Wasavi ‚Äì Vi editor for any webpage,http://appsweets.net/wasavi/,Comments,"








wasavi - appsweets akahuku labs.











wasavi (VI editor for any web page)

Tweet 


#

wasavi is an extension for Chrome, Opera and Firefox. wasavi transforms TEXTAREA element of any page into a VI editor, so you can edit the text in VI.  wasavi supports almost all VI commands and some ex commands.
wasavi is under development. Any bug report or feature request is welcome.
And we also welcome a donation to continue development:


Êó•Êú¨Ë™ûÁâà„ÅÆREADME




A Quick Walkthrough

Here is a native TEXTAREA.  Focus the TEXTAREA, and press Ctrl+Enter to launch wasavi


Salient Features

wasavi supports some ex commands. This is the output of :set all

Vim's incremental search

wasavi online app. Open this link on a browser that has wasavi extension. wasavi will launch automatically. Then you can read and write files at your Dropbox/Google Drive/OneDrive account or local files.






How to install
Currently, wasavi is available for following browsers only. Select your browser and click the link. Standard extension installation procedure of your browser will follow. These extensions are hosted at the addons store of their respective browser.

Google Chrome extension
Opera addon
Firefox addon

Source code and latest development releases are hosted at Github:

Latest and unstable version of wasavi for Chrome
Latest and unstable version of wasavi for Blink Opera
Latest and unstable version of wasavi for Firefox

A note for Chrome users
Chrome has reserved some fundamental shortcuts, such as Ctrl+T, Ctrl+W and Ctrl+N. Although these keys cannot be used in wasavi, you can use Alt+T, Alt+W and Alt+N.




Frequently Asked Questions
How to launch wasavi
Focus TEXTAREA and press Ctrl+Enter.
How to quit wasavi
To quit wasavi press ZZ or :q or :wq or any other VI quit command.
Which options are accepted by the :set command?
See this table.
Note: there are also options which are accepted but don't have any effect yet.
How to modify initial settings:
Open preference wasavi extension (or enter :options on wasavi),
and edit ""exrc"" textbox.
How to control beep
Add set noerrorbells to your exrc to disable beep sound.  If you prefer a visual bell, add set visualbell instead.
Also, a chime at wasavi startup can be disabled with set nolaunchbell.
The volume of any beeps can be controlled with set bellvolume=N.  Range of value N is 1 to 100.
How to access local files
See document.
How to use wasavi with Vimperator/Keysnail/VimFx on Firefox
Vimperator
Put wasavi_mediator.js in your Vimperator plugin directory, for example,  ~/.vimperator/plugin or %HOME%\vimperator\plugin.
This plugin will control the pass-through mode of Vimperator according to the state of wasavi.
Keysnail
Put wasavi_mediator.ks.js in your Keysnail plugin directory.
This plugin will control suspend mode of Keysnail according to the state of wasavi.
VimFx
Latest VimFx recognizes wasavi as editable element.  While wasavi is running, VimFx suspends temporarily.
To use VimFx's key binding while wasavi is running, click outside area of wasavi or enter :set esctoblur and press <esc> in normal mode.  Then keyboard focus would be removed from wasavi, and you can use VimFx's key binding.
How to use wasavi as an independent text editor
Install the wasavi extension and open the link to wasavi online app. wasavi will start automatically. You can use ex commands :read, :write, :edit or :file to access your Dropbox/Google Drive/OneDrive files or local files. You will have to authorize wasavi via OAuth to access these storages.
About automatic setting override
The :set commands which you input while wasavi is running are stored to extension's persistent storage, and those are regenerated when you launch wasavi next time.
This setting override mechanism works each independent URLs (max 30). If you think this is unnecessary, put :set nooverride in your exrc. Then overriding will be skipped.
How to cooperate with Migemo
wasavi for Chrome can Migemo search.  Install Migemo Server, then input a special meta character \M in search query of / or ? command.  If \M included in search query, these search commands are executed via migemo.
I have noticed a bug
Please create an issue on wasavi issue tracker
Tips and Tricks

to maximize the wasavi: :set fullscreen or :set fs
to restore the wasavi: :set nofullscreen or :set nofs
to change a color theme: :set theme=blight or :set theme=charcoal or :set theme=matrix or :set theme=solarized or :set theme=solarized_dark
abbreviate syntax is


:abbreviate displays all the abbreviations currently registered.
:abbreviate [clear] clears all the abbreviations.
:abbreviate lhs displays the abbreviation corresponding to lhs.
:abbreviate lhs rhs registers a abbreviation which expands lhs to rhs.
:abbreviate [noremap] lhs rhs also registers, but it is not effected remap mechanism.

map syntax is


:map displays all the mappings currently registered.
:map [clear] clears all the mappings.
:map lhs rhs registers a rule which translates lhs to rhs. Its translation is recursive. About syntax of key stroke descriptor like <esc> in the lhs and rhs, see this page.
:map [noremap] lhs rhs also registers, but it is non-recursive.
:map targets the normal mode mappings. On the other hand,
:map! targets the insert mode. This is equivalent to vim's :imap.
For more detailed information, see Syntax of map command.

j k ^ $ moves cursor by physical row, on the other hand,
gj gk g^ g$ moves by wrapped row. To swap the behavior: :set jkdenotative
f F t T extension for Japanese: these commands recognizes reading (ro-ma ji
expression) of hiragana, katakana, and kanji. For example, fk will place
a cursor on '„Åã', '„Ç´', 'Êº¢' and so on.
f F t T extension for Latin script: these commands recognizes the base alphabet
of diacritical marked letter. For example, fa will place a cursor on
'√•', '√§', '√†', '√¢', 'ƒÅ' and so on. Also see mapping table.
use a online storage as file system:


:filesystem status shows all file systems currently available.
:filesystem default shows default file system. You can set default file system
via :filesystem default dropbox or :filesystem default gdrive or :filesystem default onedrive.
:filesystem reset discards the access token for online storage.
You can place the file system name at the head of a file name explicitly:
for instance, :read dropbox:/hello.txt.

When you read from the register of A to Z, some registers returns special content:


B register: user agent string
D register: current date time string (formatted by using datetime option as template of strftime(3))
T register: title string
U register: URL string
W register: version string of wasavi

To return a setting to default state:


:set <option-name>& or :set <option-name>&default

To return all settings to default state:


:set all& or :set all&default

To return a setting to the state just after evaluation of exrc:


:set <option-name>&exrc

To return all settings to the state just after evaluation of exrc:


:set all&exrc

To submit a form automatically after writing text and closing wasavi:


:wqs
:submit (this can be shortened to :sub )


Commands implemented

[count] operation [count] motion
[count] operation [count] range-symbol
[count] surround-operation [count] motion surround-string
[count] surround-operation [count] range-symbol surround-string
[count] de-surround-operation [count] surround-identifier
[count] re-surround-operation [count] surround-identifier surround-string
[count] operation-alias
[count] surround-operation-alias surround-string
[count] motion
[count] scroll-command
[count] edit-command
[count] : ex-command

Operations
c y d > < gq gu gU
Operation Aliases
cc yy dd >> << C Y D gqq guu gUU yss ySS
A counter can be inserted in front of the last 1 character.
Surround Operations

to surround: ys yS
to remove a surround: ds
to change a surround: cs

Motions
- + ^ <home> $ <end> % | , ;
_ / ? ' ` ( ) { } [[ ]] <enter> 0
j k h l ^N ^P ^H
<down> <up> <left> <right> <space>
w W b B e E gg gj gk g^ g$ G H M L f F t T n N
Range symbols (Vim text objects)

a"" a' a` a[ a] a{ a} aB a< a> a( a) ab aw aW ap as at
i"" i' i` i[ i] i{ i} iB i< i> i( i) ib iw iW ip is it

Scroll commands
^U ^D ^Y ^E ^B ^F <pageup> <pagedown> z<enter> z. zz z-
Edit commands
x X <delete> p P J . u ^R ~ ^L ^G ga gv m @ q r R a A i I o O & s S v V ZZ gi ^A ^X
ex commands
abbreviate cd chdir copy delete edit file filesystem global join k map mark marks move options print put pwd quit read redo s & ~ set sort submit registers to unabbreviate undo unmap version v write wq wqs xit yank > < @ *
The addressing in ex command is fully supported:

whole buffer: %s/re/rep/
current line: .p
the last line of buffer: $p
absolute line number: 1,2p
relative line number: +1,+2p
regal expression: /re/p ?re?p
mark referencing: 'a,'bp

In addition to this wasavi also accepts offset, for example: /re/+1p.
Two addresses are usually connected by a ,, wasavi also supports ;.
Input mode commands

^@ input the most recently input text, and exit input mode. this key stroke is actually Ctrl+Space.
^D unshift. but if the last input character is 0 or ^, delete all indentation
^H delete a character
^R paste register's content
^T shift
^U delete all the characters entered in the current input session
^V literal input
^W delete a word

Line input mode commands

^A move cursor to top of line
^B back
^E move cursor to end of line
^F forward
^H delete a character
^N next history
^P previous history
^R paste register's content
^U delete whole line
^V literal input
^W delete a word
tab complete ex command name, set option name, file name argument of read/edit/write/file

Bound mode commands
Bound mode is similar to vim's visual mode.

c delete the bound, and switch to insert mode
d delete the bound
y yank the bound
< unshift the bound
> shift the bound
C delete the line-wise bound, and switch to insert mode
S surround the bound
R same as C
D delete the line-wise bound
X same as D
Y yank the line-wise bound
g prefix commands
a, i prefix range symbols
~ swap lower case and upper case in the bound
: switch to line input mode
J join the bound
p delete the bound, and paste a register's content
P same as p
r fill the bound up with inputted letter
s same as c
u lower-ize the bound
U upper-ize the bound
v character wise bound mode
V line wise bound mode
x same as d
^A add the counter to all numeric strings within the bound
^X subtract the counter to all numeric strings within the bound

Surrounding identifiers

quotations: one of !#$%&*+,\-.:;=?@^_|~""'`
brackets: one of abBrt[]{}()

Surrounding string

quotations: one of !#$%&*+,\-.:;=?@^_|~""'`
brackets: one of abBr[]{}()
tags: one of ^T ,<Tt

Vim features in wasavi

multiple level undo/redo
incremental search
range symbols (aka, Vim text objects)
following registers


"" unnamed register
: last executed ex command
* reading from and writing to the system clipboard
/ last searched string
= evaluate math expression. supported operators are: + - * / %. supported numeric expressions are: integer, float (including exponential form), binary (with leading 0b), octal (with leading 0), hex (with leading 0x)

auto-reformat in input mode, and reformat operator (gq command) on the state of textwidth > 0
bound mode (aka, Vim visual mode)
options: iskeyword, incsearch, smartcase, undolevels, quoteescape, relativenumber, textwidth, expandtab, cursorline, cursorcolumn, nrformats
writing to the register of A to Z
gu / gU + motion: lowerize or upperize a region
partial functionality of Surround.vim
partial functionality of :sort (regex pattern, r and i options)
^A to increase a numeric string. ^X to decrease a numeric string.







"
https://news.ycombinator.com/rss,The peculiar event sourced deadlock,https://jappie.me/the-peculiar-event-sourced-deadlock.html,Comments,"The peculiar event sourced¬†deadlock / JappieJappie


<

About üìÇ
About me

>




<

Hire üêß
Jappie for hire

>




<

Raster üöÄ
Easy rosters for restaurants startup

>




<

Email ‚úâ
Contact me

>


  The peculiar event sourced¬†deadlock  published: 15Êó• 01Êúà 2023Âπ¥ One thing that always surprises me is how casually serious problems are phrased by business people in their blissful ignorance. ‚ÄúHey why am I seeing the down for maintenance screen?‚Äù ‚ÄúOh try it now, the pack uploading has finished‚Äù, Said the QA engineer to the product manager. Once I saw this on slack, I grew really suspicious and started asking questions. After all, isn‚Äôt it a bit odd we‚Äôre seeing a down for maintenance screen in one part of the system, simply because another part is being¬†used?Initially we thought this was caused by high CPU usage. The graphs showed high CPU load while processing packs, so maybe the rest of the system was being deprioritized somehow. Before assuming that was the cause however, I decided to reproduce the issue first. Here I noticed I could for example load the risk index easily (a read operation), but connecting a risk to a pack (a write operation), would hang forever. This made me suspect that the issue wasn‚Äôt CPU usage at all, so I asked Postgres to list it‚Äôs locks. Which showed several locks in progress. This lead me to the event source system. The event source system is at the core of all our business logic. In essence, it provides a ledger of all important business write activities that can happen. This is useful for auditing purposes for¬†example.Welcome to an after action report of a complicated system level bug. It took me a week to find a satisfying solution. To start I need to sketch context. I‚Äôll only use raw SQL because this entire story is related to the database and how we use it for event sourcing. So consider the tables of an event source¬†system:CREATE TABLE event (
    id serial PRIMARY KEY NOT NULL,
    payload jsonb NOT NULL,
    type character varying NOT NULL,
    created timestamp with time zone NOT NULL
);

CREATE TABLE event_last_applied (
    id serial PRIMARY KEY NOT NULL,
    event_id bigint NOT NULL REFERENCES event (id)
);
In here the type and payload fields contains the information to (re)apply that event. The type will indicate what business logic or queries to execute, and the payload holds information for that logic. As we‚Äôll see later, these queries will involve modifying other normal tables within a transaction. This application of events, or re-application through business logic or queries is called projecting. A type can for example be create-user and the payload would contain the data required for creating said user, for example {email:'hi@jappie.me'}. The id provides a unique global ordering, and the created field contains a timestamp of when the event was created, which is used for database administration purposes. Finally, the event_last_applied table is used to indicate whichever event was last applied, so the system can figure out if additional events need to be re-projected from the event table.Inserting an event works by projecting an event to normal Postgres tables in a transaction. Once this operation is not rejected by foreign keys, type errors or program exceptions, the event gets recorded in the ledger, also known as the event table. For¬†example:begin;

/* left out projection code, insert user into tables here,
or do other projection stuff, as dictated by the event type*/

INSERT INTO event (payload, type, created)
    VALUES ('{""email"":""hi@jappie.me""}', 'create-user', now());
INSERT INTO event_last_applied (id, event_id)
SELECT 1, max(id) FROM event
ON CONFLICT (id)
    DO UPDATE SET
        event_id = lastval();
commit;
If the projection fails the entire event gets rejected, which means all changes within the transaction get rolled back by Postgres. This applies relational guarantees, to a non-relational system trough a transaction. We also weave this transaction trough business logic code, so that in case of an exception, we rollback. Quite an elegant solution, which I didnot invent.On system boot we figure out if we need to reproject or not, the query is rather¬†simple:SELECT type, payload FROM event
WHERE
    id > (
        SELECT event_id FROM event_last_applied
        WHERE id = 1)
ORDER BY
    id ASC;
which returns something like this, telling the system what to¬†do:    type     |          payload          
-------------+---------------------------
 create-user | {""email"": ""hi@jappie.me""}
With that, we can reproject, also known as replaying history. Replaying history involves truncating all tables that are event sourced. And then truncating the event_last_applied table, which in this case just removes the one row. Then the system will notice it needs to replay events on boot for example. This is a rather dangerous operation, because if any event fails, you may have potentially lost data. A lot of things can go wrong with a large history, foreign keys, exceptions, serialization mismatches, events out of order etc. Transactions can help here as well, and make this re-projection¬†safe.DeadlockThere is one more important piece of context: An event maybe composed with other events into larger transactions. For example, if we create a user, we may also assign him to a company within the same transaction. In SQL that looks like¬†this:BEGIN;

/* left out projection code, insert user into tables here */

INSERT INTO event (payload, type, created)
    VALUES (
        /* whatever event source data*/
        '{""email"":""hi@jappie.me""}', 'create-user', now());
INSERT INTO event_last_applied (id, event_id)
SELECT 1, max(id) FROM event
ON CONFLICT (id)
    DO UPDATE SET
        event_id = lastval();

/* left out projection code, connect user to company */

INSERT INTO event (payload, type, created)
    VALUES (
        /* whatever event source data*/
        '{""company-id"":2, ""user-id"": 1}', 'connect-company', now());
INSERT INTO event_last_applied (id, event_id)
SELECT 1, max(id) FROM event
ON CONFLICT (id)
    DO UPDATE SET
        event_id = lastval();
COMMIT;
Transactions form proper monoids, and they can grow arbitrarily large. This is good because even for large chuncks of business logic we always gaurantee our event log remains in a valid state. We‚Äôd expect our re-projections to always work, because only correct ones get recorded. Where does this go wrong¬†then?The issue is concurrency, consider connection A and B:A opens a transaction and inserts a user, but has to do other projections and event insertions as¬†wellB opens a transaction and wants to insert an event, B has to wait until A completes. This is because A made an update to the event_last_applied on row number 1, as part of the insert event logic. This row is locked until A completes, so B has to¬†wait.A completes and releases the lock on row 1.B can now complete as¬†well.This is not a deadlock as long as A completes. B can wait a long time because our transactions can grow arbitrarily large. For example when we‚Äôre inserting millions of rows of data, taking up half an hour. Which is far beyond the HTTP session length of 30 seconds, or whatever length a user finds acceptable. This was indeed the production bug encountered at supercede. One user was doing pack ingestion, which involves reading millions of excell file rows, and the rest of the system became unusable because of¬†that.Now¬†what?At first I started with the most obvious solution. I re-grouped how event sourcing took place. I put the event sourcing code at the end of the transaction in pack ingestion, so that the event source table remained available for other transactions up till that point. Because event sourcing is only a small part of normal transactions, this created a small locking window. Thus this worked! However it only worked for this transaction with pack ingestation, I didn‚Äôt know if there were any other transactions like this in our code base. Furthermore, I had to bypass parts of the event sourcing interface to make this work. For example, I had to project events by hand, and insert events by hand, rather then using the internal library. I decided this was a bad precedence to set. I was afraid other engineers would copy this approach when it wasn‚Äôt necessary. So I went looking for other¬†solutions.Another idea is that instead of doing the large transaction, we could split it up into smaller ones. Allowing other events to clear while this bigger one was in progress. I didn‚Äôt like this either. For one this code was old, tried and tested, making a rather large modification like splitting the transaction could introduce many unintended bugs. For example when cleanup doesn‚Äôt happen correctly on failure. I thought this was likely because this transaction was large, and covered many tables. Also our normal tools such as types and integration tests wouldn‚Äôt help a lot with guaranteeing cleanup. So this would become difficult to maintain fast. Which is problematic for a piece of code which is the ‚Äúmoney maker‚Äù, and needs to change often. Furthermore I had a much more simple but thorough solution in¬†mind.I decided to redesign the event source tables. Naturally my colleagues exclaimed shouts of joy when I decided to modify an even older system. The event source system described above is almost as old as supercede. But I believed it was easier to modify, and more importantly, easier to test for correctness. Furthermore this would also solve the problem for other, possibly unknown, or future, large transactions. This change would keep our code easy to maintain and solve a bug. The new schema looks almost identical to the old¬†one:CREATE TABLE event (
    id serial PRIMARY KEY NOT NULL,
    payload jsonb NOT NULL,
    type character varying NOT NULL,
    created timestamp with time zone NOT NULL
);

CREATE TABLE event_applied (
    id serial PRIMARY KEY NOT NULL,
    event_id bigint NOT NULL REFERENCES event (id),
    created timestamp with time zone NOT NULL
);
The big difference is that we renamed event_last_applied to event_applied and added a created field. With this change, inserting events is also quite similar to the initial¬†system:BEGIN;
INSERT INTO event (payload, type, created)
    VALUES ('{""email"":""hi@jappie.me""}', 'create-user', now());
INSERT INTO event_applied (event_id, created)
SELECT last_value, now() FROM event_id_seq;
COMMIT;
The big difference is that instead of modifying always row number 1 to be the latest ID, we insert a new row into event_applied with the latest id. This avoids locking of row number 1. For re-projection we truncate the event_applied table, allowing the code to rerun all those events. The big difference is in figuring out which events haven‚Äôt been applied¬†yet:SELECT type, payload FROM event AS e
WHERE
    NOT EXISTS (
        SELECT 1 FROM event_applied
        WHERE event_id = e.id)
ORDER BY
    id ASC;
We compare the event table to the event_applied table, and return any events that don‚Äôt exist in that. We‚Äôre still ordering by id to ensure the correct order. Is this correct? Let‚Äôs consider concurrency once more with connection A and B:A opens a transaction and inserts a user, but has to do other event source queries as¬†well.B opens a transaction does it‚Äôs projection work and wants to insert an event, B creates a new row in the even_applied table and completes. There is no need to wait since there is no single row lock. So B finishes.A finishes it‚Äôs other event sourcing¬†completes.This doesn‚Äôt deadlock. However it‚Äôs not completely correct in that A get‚Äôs id 1. and B get‚Äôs id 2, but A‚Äòs transaction finishes after B by inserting another event with id 3. So on reprojection one of A‚Äòs events get‚Äôs applied before B. But in the initial projection, all of A‚Äòs event happened after B. So the first event of A is out of order. This may cause issues. This problem was also present in the original implementation, since an id is acquired before the lock waiting happens. I think a solution would be to group the events by transaction id, and then order by last created event. In this case all events created before B in A‚Äòs transaction would be pushed behind it by an event happening after B finishes. If we do that, the event table gets an extra¬†field:CREATE TABLE event (
    id serial PRIMARY KEY NOT NULL,
    payload jsonb NOT NULL,
    type character varying NOT NULL,
    created timestamp with time zone NOT NULL,
    transaction_id bigint NOT NULL
);
Our insert function retrieves the transaction id with txid_current:BEGIN;
INSERT INTO event (payload, type, created, transaction_id)
    VALUES ('{""email"":""hi@jappie.me""}'
           , 'create-user'
           , now()
           , txid_current());
INSERT INTO event_applied (event_id, created)
SELECT last_value, now() FROM event_id_seq;
COMMIT;
And our unnaplied events query now¬†groups:SELECT
    array_agg(type) AS types,
    array_agg(payload) AS payloads
FROM event AS e
WHERE NOT EXISTS (
      SELECT 1 FROM event_applied WHERE event_id = e.id
    )
GROUP BY transaction_id
ORDER BY max(id) ASC;
If we run that unnaplied events query on an event table like¬†this:id |        payload        |      type       | created    | transaction_id 
---+-----------------------+-----------------+------------+----------------
 6 | {email: hi@jappie.me} | delete-user     | 2023-01-15 | 77958
 7 | {email: hi@jappie.me} | create-user     | 2023-01-15 | 77959
 8 | {company-id: 2}       | delete-company  | 2023-01-15 | 77958
We‚Äôd get a result¬†like:             types             |              payloads
-------------------------------+-----------------------------------------
 {create-user}                 | {{email: 'hi@jappie.me'}}
 {delete-user,delete-company}  | {{email: 'hi@jappie.me'},{company-id: 2}}
Which is what we want. Even though the create user event happened while the delete user event was happening, the delete user event was part of a larger transaction. So the create user even should come first when re-projecting. This allows arbitrary sized transactions to project alongside each-other and provides better ordering guarantees then the original¬†implementation.Closing¬†thoughtsPhew, that was a lot. I didn‚Äôt think this would become such a large post. Designing an event source system on Postgres transactions is rather hard. All I wanted to do is clear my thoughts on the matter, but that grouping issue is another bug I just found by writing about this¬†üòÖ.I think the biggest lesson I‚Äôve (re)learned from the deadlock bug itself is to make sure you reproduce an issue first before diving into solutions. Even nasty business threatening system level bugs like these can sometimes be solved with some minor modifications to the system. If we had skipped this small step of reproducing the issue, we may have focused on the CPU observation and moved pack ingestation to a separate machine, which would‚Äôve taken weeks to implement and not solve¬†anything.Furthermore, it‚Äôs humbling to see that even after having used relational databases for more then a decade, I still can learn new things about them. For example Postgres‚Äô auto increment sidesteps the transaction, which was quite shocking to me. A rather important detail to keep in mind when reasoning about these¬†systems.I made a github repository for playing around with the queries more easily. I hope you enjoyed this article, please leave a comment if you have any questions or suggestions¬†below.Resources
The code in this blogpost
Postgres Lock¬†monitoring
Blogs on event¬†sourcing
Presentation on event¬†sourcing


        Posted by Jappie J. T. Klooster
        in 

 reflection


  published: 
  15Êó• 01Êúà 2023Âπ¥ 


#postgres
#deadlock
#programming
#sql
#database

Recent stuff




                The peculiar event sourced¬†deadlock
            





                Summerhouse Paradis¬†Aruba
            





                Why do I still write this¬†blog?
            





                Zurich hack 2022 Denotational¬†Design
            





                Restoring mysql innodb on¬†windows.
            





                Failing in¬†Haskell
            





                Installing a NixOS desktop tracked with¬†git
            





                A brief intro to MTL
            

Tagsaustraliabuild-toolscssdatabasedevopsfrphaskellindonesiajakartajoblinuxnixnixosopinionpainpragmatic-haskellprogrammingreflexservantstacktesttimetoolstraveltutorialvirtualizationwebsitework
Linkedin
Twitch
Youtube
Github
Penguin
Raster
Facebook
Twitter
Reddit
Discord
 Those who know do not speak. Those who speak do not know.  Powered by Pelican. Source code, licensed under GPLv3. "
https://news.ycombinator.com/rss,Ask HN: When to make the jump to freelance/consultant?,https://news.ycombinator.com/item?id=34400435,Comments,"

Ask HN: When to make the jump to freelance/consultant? | Hacker News

Hacker News
new | past | comments | ask | show | jobs | submit 
login




 Ask HN: When to make the jump to freelance/consultant?
67 points by mxmpawn 4 hours ago  | hide | past | favorite | 54¬†comments 

I'm working full time as a data engineer/scientist but I also have one ongoing customer (a previous employer).Another previous employer is launching a startup and has recently pinged me because they need to build a series of data pipelines and ML models for their product.I've to talk to them about specifics but I don't see myselft having enough available time to make it work.I've been thinking about starting my own data/ml services company for a while but I don't really know when to make the jump. I think (is a guess for the time being) that the income from this new job, in addition to the income of my current client, could be enough for my living expenses of this year, so I'm thinking if this is a good time to make the jump or not.The problem that I see is that this new lead is from a previous partner of my current client, so both jobs are related to my previous employer, I don't have a pipeline of possible prospects for my service, so I'm not sure if I'll be able to generate a pool of prospects while doing the work for this customers.My guess is that I should wait until there is a sign that I could probably get a stream of clients to keep the wheel going, and try to find the time to take this new job, maybe negotiating terms to make it possible.What do you think?Edit: I've savings already as I plan to buy a new home (I'm in Argentina, we buy it cash, no mortgage). I need three more months of salary to accomplish the home budget. 
 
  
 
wpietri 2 minutes ago  
             | next [‚Äì] 

My general answer for people asking this question is: when you think you can sustain yourself. And it sounds like you're almost there.It sounds like the question for you is whether you can find new clients at a rate fast enough to replace old ones. This is a question you'll never be able to answer fully as an employee, because employers generally don't like you putting out an ""open for business"" sign. So in your shoes I'd put together a marketing/sales plan, take the new customer, and devote some time over the next N months to seeing if you can build up enough interest and leads that you will have plenty of work down the road.It sounds like the worst case here is that you get to the end of your contracts and have to go get another job again. Which is not a terrible outcome as long as you don't burn your bridges. And it's worth noting that after a period of freelancing you may decide you'd rather have a job anyhow, so you can look at the next months/years as an experiment not just on prospects, but on whether or not you will be happy with it.
 
reply



  
 
dadro 2 hours ago  
             | prev | next [‚Äì] 

Every scenario is going to be different, I took the plunge as a software consultant and can provide some datapoints.I was laid off from my job as a software engineer about 5 years ago. I had previously worked in software consulting and knew the operating model and had a handful of potential clients. I had some savings and my wife works full time so I decided to give it a go for 6 months to see how it would go. I partnered with a colleague who was also laid off and had same appetite for risk as I did.  * The first year was a grind, especially doing the non-technical tasks like networking/business development/invoicing/etc. 
  * We ended up being profitable on year 1, I made less than my previous gig as a lead engineer. We grew from 2 of us to having 1 FTE and 3-4 dev contractors in year 1. 
  * Keep in touch with engineers you liked working with, hiring is WAY harder than I expected. If you decide to grow, you will need a team for larger contracts. 
  * Business development is largely a numbers game, you have to get out of your comfort zone and talk to a lot of people/companies and get on their radar. 
  * One of our first non-technical hires was business development. We did this when we hit $1mm/yr rev. 
  * Being in a niche can be helpful if you are able to explain your value prop AND to differentiate yourself.
  * Don't view other consulting firms as competition. We've formed some great relationships with other companies that align with our engineering process and refer work when we have too much and get work when they have too much.

Over the last 5 years we grew from 2 ""founders"" (along with some former colleagues as contractors) to about ~40 employees (80% FTE's/20% contractors) all remote, US based. In hindsight, I think my favorite size was when we were ~8 people. It was big enough to take on 1-2 large-ish contracts, but less stress in keeping pipeline full. The risk tolerance for having a 6 figure payroll every 2 weeks is not for everyone!(edit formatting)
 
reply



  
 
eddsh1994 1 hour ago  
             | parent | next [‚Äì] 

How many years experience did you have? :)
 
reply



  
 
dadro 9 minutes ago  
             | root | parent | next [‚Äì] 

I had about 15 years professional experience as a developer.
 
reply



  
 
PragmaticPulp 1 hour ago  
             | prev | next [‚Äì] 

> Edit: I've savings already as I plan to buy a new home (I'm in Argentina, we buy it cash, no mortgage). I need three more months of salary to accomplish the home budget.This is a significant last-minute edit. There's a lot of good advice throughout this thread, but I would suggest waiting until you've completed the home purchase and settled in before considering the jumping to freelance. It's only a few more months and you'll have a much better understanding of any issues and unexpected expenses of the new home.Beyond that, you need to make sure that you can do the process of networking, selling your services, cultivating a pipeline of clients, and collecting from clients who don't pay on time. Doing the work is only half of the battle when you're a freelancer. If you don't excel at the business side, you might not enjoy it after you run out of immediate contacts with work for you to do.
 
reply



  
 
ljm 44 minutes ago  
             | parent | next [‚Äì] 

This is true. I can't speak to the process of buying a home in Argentina but buying a house and moving is a significant change, and leaving your job to go self-employed is another significant change.Finish the home project before you commit to the self-employment project. Your full-time job is a safety net you won't have when you first go contract.No harm in putting feelers out meanwhile though, networking and making yourself known in relevant circles. Worst case is that you end up with more full-time job prospects and not freelance ones.
 
reply



  
 
ernestipark 10 minutes ago  
             | prev | next [‚Äì] 

How much work do you think the new work would take? Depending on the nature of the engagement, it doesn't have to be a 'jump' at all. If possible, an option would be to make it a more reduced hours engagement that you can moonlight. Then you can get the consulting experience, maintain the income of your full-time job, and see how it goes. Once you have one engagement under your belt, then it also becomes much easier to get more through WOM and very basic marketing/promotion through LinkedIn on what your skills are and what you can offer.As others have stated in the comments also, a lot of consultants never have to do marketing or sales, they just get it word of mouth through their networks as they continue to do good work. I think doing that first job well, but in a way that's not as scary as jumping away from your full-time job is a good choice if you have it.
 
reply



  
 
nocubicles 3 hours ago  
             | prev | next [‚Äì] 

I just started this today actually. Today is the first day where I am no longer employeed by any company and will need to find my own customers, invoice them etc. My field is ERP development and consultation.I have 10+ years experience in the field and I was working for a consultation company. But on the same time I would always get messages on Linkedin from recruiters and at some point I thought I should give it a go and try to work on the projects during the nights and weekends.Did that for like 6 months and felt I could do it full time and then I just kinda did it and will be doing it in the future.
 
reply



  
 
cableshaft 2 hours ago  
             | parent | next [‚Äì] 

Sounds like you got freelance work from recruiters contacting you for full-time job opportunities. How did you ask them about that, out of curiosity?
 
reply



  
 
NiagaraThistle 2 hours ago  
             | root | parent | next [‚Äì] 

I've done this - with Web Development, but still got projects this way. I just responded to the recruiter or directly to the company if I had their info, and stated my background, my rate, and asked if they were interested in working with my in a contractor capacity. It's gone very well, and I have several ongoing contracts from this process.Basically just state that you are interested in the work, but not the current agreement and see if the company is open to hiring you as a contractor. If your experience is good and viewable/provable, they probably will be. And Bonus points if you are a good communicator and timely with such and delivering deadlines - many contractors are not and companies/recruiters get burned by them and those who ARE dependable are worth their weight in gold to companies.
 
reply



  
 
nocubicles 2 hours ago  
             | root | parent | prev | next [‚Äì] 

I always told them that i'm not looking full time but only part time but that only did work once I think. Most success came from building a small persona online, participating in the discussions, networking on Discords/Twitter and then the opportunities came.
 
reply



  
 
MuffinFlavored 47 minutes ago  
             | parent | prev | next [‚Äì] 

how different are WMS and ERP?
 
reply



  
 
janetacarr 1 hour ago  
             | prev | next [‚Äì] 

Personally, as a freelancer/consultant, I never think there is a right time for anything in my life. Of course, you might feel differently (and it probably is different). I'm offering advice from my perspective only, and I don't have a home to make, or children to worry about. I've been freelance/consulting/whatever for about 2 years, so make of this what you will, but I'm still early stages having just been where you're at.First I want to say, the risk might not be as big as you might think it is. You've a pretty in-demand skill set right now, more so than most SWEs. If things don't pan out as you expect, you can always get another full-time position despite the 'looming recession'.That said, here is some unsolicited advice. Rebuttal as necessary :)Regarding leads/prospects, if you do decide to make the jump, chances are you'll be tapping your professional network for leads, or pitching strangers if you happen to get on a call with them via cold email. This can work for a while, maybe get your first recurring clients, but I don't recommend working with a matchmaker like Toptal, Fiverr, Upwork, or an agency.The platforms tend to have poor pay and bad clients. Agencies will limit your ability to build a direct relationship with the clients. I know people have built successful businesses using both of them, but for me having a direct relationship with high-value clients seems to have paid off doubly as I can set my own terms (fixed rate / value based) rather than the typical hourly model. If you can/want to build such a relationship, you should *get on the phone with a decision maker* (a huge unlock for closing work). Regular dev/engineer interview channels will yield regular dev work, pay, and circumstances (maybe that's a feature for you).After a few sales calls for clients, You may realize getting leads to come to you is best, or at minimum people should have a reason to answer your emails like having some kind of branding or marketing, so start writing, coding, tweeting, or whatever regularly to get attention. Keep at it. It's hard work.On top of everything, you will fuck up, and that's okay, so give yourself some breathing room financially and mentally.
 
reply



  
 
xeromal 1 hour ago  
             | prev | next [‚Äì] 

One element required is to have a network big enough to sustain itself off recommendations. I think that's absolutely necessary at least for 80% of your business revenue. If you're just hopping from one client to the next, you're not going to be in a strong decision to make good choices for your company when it comes to negotiations.
 
reply



  
 
sirsinsalot 1 hour ago  
             | parent | next [‚Äì] 

I've been a consultant through my own company for 15 years and never needed to do this.I simply apply for contract roles.My day rate is 150+% of the average for my role and area and my contract terms are ridiculously weighted in my favor.You can learn to negotiate going from one client to the next.And you mainly have to be able to negotiate better than the client. That's pretty easy usually.
 
reply



  
 
moneywoes 1 hour ago  
             | root | parent | next [‚Äì] 

Where do you find these roles
 
reply



  
 
Nextgrid 1 hour ago  
             | root | parent | next [‚Äì] 

Seconded.The vast majority of contract roles I see here in the UK are brokered by recruiters who will enforce their own standard contract terms & rates on a take-it-or-leave-it basis.This kind of approach seems like it has no chance of working as the recruiter would rather place someone at an ""okay"" rate rather than having to risk submitting a higher-rate candidate and having the client balk and go away altogether.
 
reply



  
 
sirsinsalot 13 minutes ago  
             | root | parent | next [‚Äì] 

Yes recruiters, and outside IR35.It isn't true that they set rates and dictate terms. Push back, negotiate with them.If you have recruiters who know you deliver, which drives more business for them and makes them look good, they'll listen to you and break their backs to place you even at rates higher than other people. They become your marketing team.They're salespeople. Make their job easy and make yourself a tool that generates more long term commission for them. They'll bank on you and you'll be first in line.All they care about is an easy win and their commission and sales targets. If you're their easy win, you're golden. The higher the rate they can place you at the more it works for them because the commission is percentile.I interview really well. I'm a salesman too. They know if they can get me in the door I'll get the gig and they can get their cut of 50% above market rate.I get to strike terms from contracts, set my notice period ... whatever I want really.Build the relationships.
 
reply



  
 
sirsinsalot 1 hour ago  
             | prev | next [‚Äì] 

15 year+ consultant through my own company with recurring clients and more work than I can handle (and no interest in delegating or growing)Never needed to network. Don't have to market myself. Never had or needed a full time position and never been short of work.Get to know good recruiters who have streams of contract work with goal based outcomes.Learn how the contracts are managed by middle men and understand why consultants and contractors are needed and what risk profiles they serve.I'm used when times are tough, deadlines are tight or goals absolutely have to be hit.My day rate is higher than my peers.I'd say do it, find your niche and be ome the goto person for a specific kind of work.
 
reply



  
 
aantix 1 hour ago  
             | parent | next [‚Äì] 

Why work with recruiters at all?They‚Äôll charge 30-50% over your rate. They provide zero value besides the initial contact.Their overhead impacts your negotiation leverage for a higher rate.
 
reply



  
 
sirsinsalot 18 minutes ago  
             | root | parent | next [‚Äì] 

Recruiters here typically take 10-15% and I don't care as long as I'm getting what I want in revenue.Most recruiters are absolute snakes. They can be very useful and you don't have to let them negotiate for you.At the end of the day, as long as they get their cut they don't much care.Saves me endless hours at $X/hr searching myself. It's more cost effective for me to bill a client for those hours than market myself.If you know the industry and find good recruiters they'll break their back to place you.
 
reply



  
 
benjaminwootton 1 hour ago  
             | root | parent | prev | next [‚Äì] 

Recruiters typically charge approximately 10% in the markets I am familiar with.They also act as a free sales force and have supplier agreements with end clients.  These are very hard to secure directly for one man bands.I would argue that it's not really consulting or running your own business if you are working through a recruiter.  It's more akin to short term employment.  That may be fine for your aims however.
 
reply



  
 
sirsinsalot 10 minutes ago  
             | root | parent | next [‚Äì] 

Recruiters are also an insurance policy for clients. They mitigate some risk.
 
reply



  
 
sjducb 3 hours ago  
             | prev | next [‚Äì] 

It sounds like the perfect time to jump to freelance. You've got 2 clients already.However... What happens if both clients back out and you suddenly get no work for a year? Do you have 1 year of savings runway? Will your family and living situation survive no income for a year? You need at least a year of runway because it's perfectly normal to go for 2 months with no income and if you've only got 3 months of savings then you'll start panicking.Also getting a mortgage as a freelancer is more complicated. Have you bought all of the houses you want for the next 2 years? (Freelancer mortgages require 2 years of company accounts, so you won't be able to get a mortgage for the next 2 years)
 
reply



  
 
angarg12 41 minutes ago  
             | prev | next [‚Äì] 

I'm in a similar boat (worse actually, since I'm on a visa) so I can't give specific advice, but @patio11 [1] greatly encouraged me to consider freelance/consulting as a career path.I am going through the grind of prepping for the tech interview all over again, and it just occurred to me that I might be approaching this from the wrong angle. If instead of spending all these hours every day solving leetcode problems or trying to ""grok"" the system design interview, I spent them networking and building a portfolio, it might result in a much better ROI.But alas, my visa status doesn't allow me to do anything either way. Maybe one day.[1] https://www.kalzumeus.com/2012/09/17/ramit-sethi-and-patrick...
 
reply



  
 
indymike 1 hour ago  
             | prev | next [‚Äì] 

> The problem that I see is that this new lead is from a previous partner of my current client, so both jobs are related to my previous employer, I don't have a pipeline of possible prospects for my service, so I'm not sure if I'll be able to generate a pool of prospects while doing the work for this customers.Work on building your pipeline, and having customers from launch day on.
 
reply



  
 
comprev 3 hours ago  
             | prev | next [‚Äì] 

When you have enough savings to take the plunge and survive until you either pick up work or return to a perm position.Many people love the idea of being their own boss but the reality can be quite different and they return to perm roles.
 
reply



  
 
brownrw8888 2 hours ago  
             | prev | next [‚Äì] 

Toptal is what made it easy for me.  The most exhausting thing about running your own consultancy is networking and maintaining a funnel of new clients.  Unfortunately this kept me away from freelancing for years :(I was in a similar situation like you (FTE + consultant) where I was looking for prospects and not able to find enough.  It's a full-time job in itself...  I vastly expanded my opportunities by tapping into a bigger talent network with Toptal.Please reach out and I'd be happy to share morehttps://www.toptal.com/qal80m/worlds-top-talent
 
reply



  
 
bigmanwalter 2 hours ago  
             | parent | next [‚Äì] 

What kind of hourly rates can you expect to find on Top Tal?
 
reply



  
 
pastacacioepepe 1 hour ago  
             | root | parent | next [‚Äì] 

Definitely a lot higher than on Upwork, on average.
 
reply



  
 
Nextgrid 1 hour ago  
             | root | parent | next [‚Äì] 

That's not a high bar though.
 
reply



  
 
pxue 1 hour ago  
             | parent | prev | next [‚Äì] 

Who sets the rates on Toptal?I was going to use lemon.io but they cap out at $100usd an hour.Not worth my time.
 
reply



  
 
bckygldstn 23 minutes ago  
             | root | parent | next [‚Äì] 

You (the consultant) sets the rate you get paid. Toptal adds a secret margin on top of that which is what the client pays.I haven't done Toptal in a while, but my rate was always higher than that. I got pushback from from Toptal's internal recruiters whenever I asked to increase my rate and a few of their clients did turn me down due to the rate. But I never backed down and it never took more than a few weeks between starting applying to jobs on Toptal to signing a contract.I wouldn't want to depend on Toptal for my income. But it's great as a way to fill in between other engagements if you're firm with your rate and the kind of work you want.
 
reply



  
 
moneywoes 1 hour ago  
             | parent | prev | next [‚Äì] 

Aren‚Äôt these sites just a race to the bottom for devs especially with global reach
 
reply



  
 
thegeomaster 2 hours ago  
             | parent | prev | next [‚Äì] 

Looks like they are not accepting new devs right now.
 
reply



  
 
akmittal 1 hour ago  
             | parent | prev | next [‚Äì] 

In last 2 years developer pool has increased a lot on Toptal. There are not enough jobs there now.
 
reply



  
 
physcab 3 hours ago  
             | prev | next [‚Äì] 

If you have enough connections to get you through your first 6 months or so then you can make the jump. Often when consulting your rate is double your normal take home so it balances out the period of searching for more work. But you highlighted the key anxiety in going freelance: you will always have to be selling your services. Its just like any startup except you are the product. Having to get new gigs will always be part of the job whether its now, 6 months from now, or 3 years from now
 
reply



  
 
anon223345 24 minutes ago  
             | prev | next [‚Äì] 

Freelance is a very different thing than actual consulting by the wayWhat I mean is working for a consulting firm is substantially different than what you do as a freelancer.
 
reply



  
 
collyw 21 minutes ago  
             | parent | next [‚Äì] 

That depends, it's like saying a software engineer is different from a programmer. Can be true, or it can just be a different term for the same type of thing.
 
reply



  
 
tptacek 1 hour ago  
             | prev | next [‚Äì] 

I left full time work for consulting after I did a project and discovered my bill rate was so high I could replicate my salary income while being less than 40% utilized. I wasn't doing something especially specialized; that's just what the market clearing rate for that contracting work was. I would not have guessed that rate before discovering it.So my somewhat tangential advice is: figure out your rate, and start with a rate that doesn't require you to constantly hustle for clients to make your nut. It's easier to figure out the right (high) rate when you've still got a salary to fall back on, and much harder when you're grinding it out as a full time contractor.
 
reply



  
 
simne 2 hours ago  
             | prev | next [‚Äì] 

You should consider two most important things (unfortunately, each other opposite):1. Yes, better to start own business when favorable environment, for example, when see macroeconomic grow (now recession, and high probability of crisis), or when You have some money accumulation.2. But business is by definition, PRACTICE of make stakes and earn profits on success.- You will not practice if not try. And best practice at crisis.Exist good solution of this contradiction. If You could afford it, look out at nearest to You business community (offline), and find experienced mentor, to mentor You and You'll pay him from Your current payment.Any way, early start business is much better then late. Mostly, because when You younger, You have more health, and could do things faster.
 
reply



  
 
kdazzle 1 hour ago  
             | parent | next [‚Äì] 

> better to start own business when favorable environment, for example, when see macroeconomic grow (now recession, and high probability of crisis),I could actually see the opposite being true. Lots of companies might not want to hire FTEs right now due to a maybe recession, but there's still a lot of work to be done, so they just use contractors instead.
 
reply



  
 
choult 2 hours ago  
             | prev | next [‚Äì] 

I started on my own at the end of September; I'd resigned my job at Datto after an acquisition proved itself disastrous (never work for Kaseya, or any Insight Partners portfolio company), and the position I had lined up fell through for one reason or another.I figured - I'm 40, I've always wanted to do my own thing, I've got runway... Why not? So I formed a company[0], started planning out a B2B product and networking like crazy; I'm fortunate to have a wide diaspora of former colleagues.As I want to bootstrap my own SaaS app, I needed to get revenue coming in, so I began to offer my services on a consultancy basis. I got my first small customer at the end of November - a charity needing hosting and maintenance - and then landed my first major consulting gig at the end of December 2022.Who knows what I'll be doing in a month's time, but I know that I can build a track record of helping others, and it's so varied! Every business or organization I talk to gives me more ideas for my app, so it's also a great way to collect more knowledge about the wants and needs of my potential customers.If you have the opportunity and runway to give it a shot, I'd recommend trying it - put a plan together for how you'll achieve it, how long you can last without a gig and what you'll offer others. And then execute on it.You'll never know unless you try.[0] https://xarma.co
 
reply



  
 
fhd2 3 hours ago  
             | prev | next [‚Äì] 

I personally took the plunge, with enough savings to make it several months until the first invoice is paid. Some clients pay on time, some don't, some go bankrupt or just drag it out infinitely, from what I've seen.Without that kind of savings (and being comfortable with watching them meld away for a while, taking the risk that you might not recover them), I would suggest to try to find a safe way to experiment with this. For example reducing your hours, or taking on a new main job with less hours, and taking on part time freelance work. Maybe there are things you can do for your potential clients with less hours than what you/they think is needed.
 
reply



  
 
nicolas_t 2 hours ago  
             | parent | next [‚Äì] 

With regards to clients not paying on time or going bankrupt, one data point, after being freenlance for 18 years, I have lost about 3% to unpaid work, conflicts with clients etc... Besides this, I've had quite a few clients who have been late (up to 3 months)When I first started, I remember researching a lot and reading that to expect 5% loss as a rule of thumb and have enough runway to last a year without income, I think that's a good rule to keep in mind.
 
reply



  
 
chrisa 2 hours ago  
             | prev | next [‚Äì] 

I did the same thing several years ago (left my job once I had 2 clients). I was also worried, but it turned out just fine. It's true that it will take a bit of work to get clients, but it becomes easier and easier as you go. Your current clients may know others, etc.I have two big pieces of advice:1. What other comments here say about money and runway is definitely true. It can be common to go a bit without clients - and even once you find a new one it might take 30 days for the project to start, then maybe you bill after the first 30 days, then it takes them 30 days to pay - that's 3 months from the time you found them to when you get the first money coming in! So make sure you account for that.2. Have something you can point to which says ""this is what I do, and why I'm good at it"". In my case it was an ebook, but it could be a white paper, or sample projects, etc - but you need something that ""tells a story"" to the clients that you can do the job.And good luck! It's scary to take the jump, but also very rewarding :)
 
reply



  
 
andjelam990 1 hour ago  
             | prev | next [‚Äì] 

I would advise you to find a partner who is also a data engineer/scientist and team up, it would be much easier also to share the workload, ideally even someone with network will bring in some new clients.
 
reply



  
 
misiti3780 3 hours ago  
             | prev | next [‚Äì] 

I could be another client as I need help with this, ping me at joseph dot misiti at mathandpencil.com
 
reply



  
 
davidw 2 hours ago  
             | prev | next [‚Äì] 

I've done contracting and it's ok, but it's best if you have something more to sell than just your time. ""Do you earn money while you're asleep?""
 
reply



  
 
ushercakes 2 hours ago  
             | prev | next [‚Äì] 

I would really advise heavily against just separating freelance/full time as black and white, one at a time.Really, it should be a slow transition - you work full time, you take up 1-2 freelance clients on the side. As you start to get more clients on the side, and you see a clear path to replacing your income, then you can make that jump.If you just make the jump as a clear break, it totally can work, it does all the time. But it's just a bit riskier, and it adds a lot more weight and pressure to get deals, which can lead to a situation where you charge less than you are actually worth.Btw, in my profile, the site I run is for freelancers to basically share their hourly rates. It's essentially levels.fyi for for consultants. May or may not be helpful to you at this stage of your journeyTLDR: 
- Keep your job, start taking clients on the side 
- Once you have enough clients and you see a clear path to replacing your FT income, quit and take the leap
 
reply



  
 
atemerev 2 hours ago  
             | prev | next [‚Äì] 

As a consultant, urgently looking for a full time job: not now. Most probably not now.
 
reply



  
 
moneywoes 1 hour ago  
             | parent | next [‚Äì] 

Wouldn‚Äôt contracts be more in demand during a recession?
 
reply



  
 
hocuspocus 1 hour ago  
             | root | parent | next [‚Äì] 

In places where layoffs are complicated, contractors are obviously the first to go.
 
reply



  
 
justsomehnguy 2 hours ago  
             | prev [‚Äì] 

Yesterday.
 
reply







Guidelines | FAQ | Lists | API | Security | Legal | Apply to YC | Contact
Search:  


"
https://news.ycombinator.com/rss,Heat pumps of the 1800s are becoming the technology of the future,https://knowablemagazine.org/article/technology/2023/heat-pumps-becoming-technology-future,Comments,"








CREDIT: DANA SMITH


Heat pumps offer a green, effective way to heat homes using electricity, not fossil fuels. New designs are making them more efficient and suitable for more conditions.





Technology

How heat pumps of the 1800s are becoming the technology of the future

          Innovative thinking has done away with problems that long dogged the electric devices ‚Äî and both scientists and environmentalists are excited about the possibilities
          

By Chris Baraniuk
01.11.2023

FacebookTwitterLinkedinRedditFlipboardEmailPrintRepublish




Support sound science and smart storiesHelp us make scientific knowledge accessible to all
Donate today





It was an engineering problem that had bugged Zhibin Yu for years ‚Äî but now he had the perfect chance to fix it. Stuck at home during the first UK lockdown of the Covid-19 pandemic, the thermal engineer suddenly had all the time he needed to refine the efficiency of heat pumps: electrical devices that, as their name implies, move heat from the outdoors into people‚Äôs homes.The pumps are much more efficient than gas heaters, but standard models that absorb heat from the air are prone to icing up, which greatly reduces their effectiveness.

YOU MAY ALSO LIKE









Food & Environment


How cities can fight climate change












Food & Environment


Now is the time to prepare for the economic shocks of battling climate change












Technology


How smart windows save energy




Yu, who works at the University of Glasgow, UK, pondered the problem for weeks. He read paper after paper. And then he had an idea. Most heat pumps waste some of the heat that they generate ‚Äî and if he could capture that waste heat and divert it, he realized, that could solve the defrosting issue and boost the pumps‚Äô overall performance. ‚ÄúI suddenly found a solution to recover the heat,‚Äù he recalls. ‚ÄúThat was really an amazing moment.‚ÄùYu‚Äôs idea is one of several recent innovations that aim to make 200-year-old heat pump technology even more efficient than it already is, potentially opening the door for much greater adoption of heat pumps worldwide. To date, only about 10 percent of space heating requirements around the world are met by heat pumps, according to the International Energy Agency (IEA). But due to the current energy crisis and growing pressure to reduce fossil fuel consumption in order to combat climate change, these devices are arguably more crucial than ever.Since his 2020 lockdown brainstorming, Yu and his colleagues have built a working prototype of a heat pump that stores leftover heat in a small water tank. In a paper published in the summer of 2022, they describe how their design¬†helps the heat pump to use less energy. Plus, by separately rerouting some of this residual warmth to part of the heat pump exposed to cold air, the device can defrost itself when required, without having to pause heat supply to the house.The idea relies on the very principle by which heat pumps operate: If you can seize heat, you can use it. What makes heat pumps special is the fact that instead of just generating heat, they also capture heat from the environment and move it into your house ‚Äî eventually transferring that heat to radiators or forced-air heating systems, for instance. This is possible thanks to the refrigerant that flows around inside a heat pump. When the refrigerant encounters heat ‚Äî even a tiny amount in the air on a cold day ‚Äî it absorbs that modicum of warmth.A compressor then forces the refrigerant to a higher pressure, which raises its temperature to the point where it can heat your house. It works because an increase of pressure pushes the refrigerant molecules closer together, increasing their motion. The refrigerant later expands again, cooling as it does so, and the cycle repeats. The entire cycle can run in reverse, too, allowing heat pumps to provide cooling when it‚Äôs hot in summer.





Air-source heat pumps, the most common design, capture heat from the outdoor air.


The magic of a heat pump is that it can move multiple kilowatt-hours of heat for each kWh of electricity it uses. Heat pump efficiencies are generally measured in terms of their coefficient of performance (COP). A COP of 3, for example, means 1 kWh of juice yields 3 kWh of warmth ‚Äî that‚Äôs effectively 300 percent efficiency. The COP you get from your device can vary depending on the weather and other factors.It‚Äôs a powerful concept, but also an old one. The British mathematician, physicist and engineer Lord Kelvin proposed using heat pump systems for space heating way back in 1852. The first heat pump was designed and built a few years later and used industrially to heat brine in order to extract salt from the fluid. In the 1950s, members of the British Parliament discussed heat pumps when coal stocks were running low. And in the years following the 1973-74 oil crisis, heat pumps were touted as an alternative to fossil fuels for heating. ‚ÄúHope rests with the future heat pump,‚Äù one commentator wrote in the 1977 Annual Review of Energy.Now the world faces yet another reckoning over energy supplies. When Russia, one of the world‚Äôs biggest sources of natural gas, invaded Ukraine in February 2022, the price of gas soared ‚Äî which in turn shoved heat pumps into the spotlight because with few exceptions they run on electricity, not gas. The same month, environmentalist Bill McKibben wrote a widely shared blog post titled ‚ÄúHeat pumps for peace and freedom‚Äù in which, referring to the Russian president, he argued that the US could ‚Äúpeacefully punch Putin in the kidneys‚Äù by rolling out heat pumps on a massive scale while lowering Americans‚Äô dependence on fossil fuels. Heat pumps can draw power from domestic solar panels, for instance, or a power grid supplied predominantly by renewables.Running the devices on green electricity can help to fight climate change, too, notes Karen Palmer, an economist and senior fellow at Resources for the Future, an independent research organization in Washington, DC, who coauthored an analysis of policies to enhance energy efficiency in the 2018 Annual Review of Resource Economics. ‚ÄúMoving towards greater use of electricity for energy needs in buildings is going to have to happen, absent a technology breakthrough in something else,‚Äù she says.




This video illustrates the principle behind heat pumps.
CREDIT: THIS OLD HOUSE

The IEA estimates that, globally, heat pumps have the potential to reduce carbon dioxide emissions by at least 500 million metric tons in 2030, equivalent to the annual CO2 emissions produced by all the cars in Europe today.Despite their long history and potential virtues, heat pumps have struggled to become commonplace in some countries. One reason is cost: The devices are substantially more expensive than gas heating units and, because natural gas has remained relatively cheap for decades, homeowners have had little incentive to switch.There has also long been a perception that heat pumps won‚Äôt work as well in cold climates, especially in poorly insulated houses that require a lot of heat. In the UK, for example, where houses tend to be rather drafty, some homeowners have long considered gas boilers a safer bet because they can supply hotter water (around 140 to 160 degrees Fahrenheit), to radiators, which makes it easier to heat up a room. By contrast, heat pumps tend to be most efficient when heating water to around 100 degrees Fahrenheit.The cold-climate problem is arguably less of an issue than some think, however, given that there are multiple modern air source devices on the market that work well even when outside temperatures drop as low as minus 10 degrees Fahrenheit. Norway, for example, is considered one of the world leaders in heat pump deployment. Palmer has a heat pump in her US home, along with a furnace as backup. ‚ÄúIf it gets really cold, we can rely on the furnace,‚Äù she says.Innovations in heat pump design are leading to units that are even more efficient, better suited to houses with low levels of insulation and ‚Äî potentially ‚Äî cheaper, too. For example, Yu says his and his colleagues‚Äô novel air source heat pump design could improve the COP by between 3 percent and 10 percent, while costing less than existing heat pump designs with comparable functionality. They are now looking to commercialize the technology.Yu‚Äôs work is innovative, says Rick Greenough, an energy systems engineer now retired from De Montfort University in the UK. ‚ÄúI must admit this is a method I hadn‚Äôt actually thought of,‚Äù he says.





This newer heat pump design, by thermal engineer Zhibin Yu of the University of Glasgow, stores residual heat that would otherwise be wasted and uses it to help heat the house or defrost part of the pump itself. This makes the system more efficient.


And there are plenty more ideas afoot. Greenough, for instance, has experimented with storing heat in the ground during warmer months, where it can be exploited by a heat pump when the weather turns cool. His design uses a circulating fluid to transfer excess heat from solar hot-water panels into shallow boreholes in the soil. That raises the temperature of the soil by around 22 degrees Fahrenheit, to a maximum of roughly 66 degrees Fahrenheit, he says. Then, in the winter, a heat pump can draw out some of this stored heat to run more efficiently when the air gets colder. This technology is already on the market, offered by some installers in the UK, notes Greenough.But most current heat pumps still only generate relatively low output temperatures, so owners of drafty homes may need to take on the added cost of insulation when installing a heat pump. Fortunately, a solution may be emerging: high-temperature heat pumps.‚ÄúWe said, ‚ÄòHey, why not make a heat pump that can actually one-on-one replace a gas boiler without having to really, really thoroughly insulate your house?‚Äô‚Äù says Wouter Wolfswinkel, program manager for business development at Swedish energy firm Vattenfall, which manufactures heat pumps. Vattenfall and its Dutch subsidiary Feenstra have teamed up to develop a high-temperature heat pump, expected to debut in 2023.





Like air conditioners running in reverse, heat pumps such as the one being installed here use refrigerants to capture heat from the outdoors and move it indoors to heat the house.
CREDIT: PHYXTER HOME SERVICES


In their design, they use CO2 as a refrigerant. But because the heat-pump system‚Äôs hot, high-pressure operating conditions prevent the gas from condensing or otherwise cooling down very easily, they had to find a way of reducing the refrigerant‚Äôs temperature in order for it to be able to absorb enough heat from the air once again when it returns to the start of the heat pump loop. To this end, they added a ‚Äúbuffer‚Äù to the system: a water tank where a layer of cooler water rests beneath hotter water above. The heat pump uses the lower layer of cooler water from the tank to adjust the temperature of the refrigerant as required. But it can also send the hotter water at the top of the tank out to radiators, at temperatures up to 185 degrees Fahrenheit.The device is slightly less efficient than a conventional, lower temperature heat pump, Wolfswinkel acknowledges, offering a COP of around 265 percent versus 300 percent, depending on conditions. But that‚Äôs still better than a gas boiler (no more than 95 percent efficient), and as long as electricity prices aren‚Äôt significantly higher than gas prices, the high temperature heat pump could still be cheaper to run. Moreover, the higher temperature means that homeowners needn‚Äôt upgrade their insulation or upsize radiators right away, Wolfswinkel notes. This could help people make the transition to electrified heating more quickly.A key test was whether Dutch homeowners would go for it. As part of a pilot trial, Vattenfall and Feenstra installed the heat pump in 20 households of different sizes in the town of Heemskerk, not far from Amsterdam. After a few years of testing, in June 2022 they gave homeowners the option of taking back their old gas boiler, which they had kept in their homes, or of using the high temperature heat pump on a permanent basis. ‚ÄúAll of them switched to the heat pump,‚Äù says Wolfswinkel.In some situations, home-by-home installations of heat pumps might be less efficient than building one large system to serve a whole neighborhood. For about a decade, Star Renewable Energy, based in Glasgow, has been building district systems that draw warmth from a nearby river or sea inlet, including a district heating system connected to a Norwegian fjord. A Scandinavian fjord might not be the first thing that comes to mind if you say the word ‚Äúheat‚Äù ‚Äî but the water deep in the fjord actually holds a fairly steady temperature of 46 degrees Fahrenheit, which heat pumps can exploit.





Ground-source and water-source heat pumps differ from air-source pumps by capturing heat from the ground or from bodies of water.


Via a very long pipe, the district heating system draws in this water and uses it to heat the refrigerant, in this case ammonia. A subsequent, serious increase of pressure for the refrigerant ‚Äî to 50 atmospheres ‚Äî raises its temperature to 250 degrees Fahrenheit. The hot refrigerant then passes its heat to water in the district heating loop, raising the temperature of that water to 195 degrees Fahrenheit. The sprawling system provides 85 percent of the hot water needed to heat buildings in the city of Drammen.‚ÄúThat type of thing is very exciting,‚Äù says Greenough.Not every home will be suitable for a heat pump. And not every budget can accommodate one, either. Yu himself says that the cost of replacing the gas boiler in his own home remains prohibitive. But it‚Äôs something he dreams of doing in the future. With ever-improving efficiencies, and rising sales in multiple countries, heat pumps are only getting harder for their detractors to dismiss. ‚ÄúEventually,‚Äù says Yu, ‚ÄúI think everyone will switch to heat pumps.‚Äù



10.1146/knowable-011123-2


Chris Baraniuk is a freelance science journalist and nature lover who lives in Belfast, Northern Ireland. His work has been published by the BBC, the Guardian, New Scientist, Scientific American and Hakai Magazine, among other publications.

Republish This Article



        Technology
      



          Climate Change
        





Share this article
FacebookTwitterLinkedinRedditFlipboardEmailPrintRepublish



Support Knowable Magazine
Help us make scientific knowledge accessible to all
      Donate
 





CloseExplore MoreANNUAL REVIEW OF RESOURCE ECONOMICSAdvances in Evaluating Energy Efficiency Policies and ProgramsTAKE A DEEPER DIVE| Explore Related Scholarly Articles
                ANNUAL REVIEW OF RESOURCE ECONOMICSAdvances in Evaluating Energy Efficiency Policies and ProgramsThere are many possible energy efficiency interventions available, including heat pumps. Some of the financial savings yielded by such interventions are smaller than utilities suggest ‚Äî but others are cost-effective.ANNUAL REVIEW OF ENVIRONMENT AND RESOURCESFrom Low- to Net-Zero Carbon Cities: The Next Global AgendaStudies suggest that cities can reach net-zero targets with the help of decarbonizing technologies, including heat pumps. Broad success requires systemic transformation of how cities and nearby areas consume energy and sequester carbon.ANNUAL REVIEW OF ENERGYThe Coming Age of ConservationIn 1977, greater understanding of global energy expenditure in various areas, from transportation to home heating, was leading to new thinking on energy consumption ‚Äî and a drive to improve efficiency. Heat pumps were seen as a key part of that effort.





Stay in the Know
Subscribe to the Knowable Magazine newsletter.




* indicates required

Email Address  *




Country  *


United States of America
Aaland Islands
Afghanistan
Albania
Algeria
American Samoa
Andorra
Angola
Anguilla
Antarctica
Antigua And Barbuda
Argentina
Armenia
Aruba
Australia
Austria
Azerbaijan
Bahamas
Bahrain
Bangladesh
Barbados
Belarus
Belgium
Belize
Benin
Bermuda
Bhutan
Bolivia
Bonaire, Saint Eustatius and Saba
Bosnia and Herzegovina
Botswana
Bouvet Island
Brazil
British Indian Ocean Territory
Brunei Darussalam
Bulgaria
Burkina Faso
Burundi
Cambodia
Cameroon
Canada
Cape Verde
Cayman Islands
Central African Republic
Chad
Chile
China
Christmas Island
Cocos (Keeling) Islands
Colombia
Comoros
Congo
Cook Islands
Costa Rica
Cote D'Ivoire
Croatia
Cuba
Curacao
Cyprus
Czech Republic
Democratic Republic of the Congo
Denmark
Djibouti
Dominica
Dominican Republic
Ecuador
Egypt
El Salvador
Equatorial Guinea
Eritrea
Estonia
Ethiopia
Falkland Islands
Faroe Islands
Fiji
Finland
France
French Guiana
French Polynesia
French Southern Territories
Gabon
Gambia
Georgia
Germany
Ghana
Gibraltar
Greece
Greenland
Grenada
Guadeloupe
Guam
Guatemala
Guernsey
Guinea
Guinea-Bissau
Guyana
Haiti
Heard and Mc Donald Islands
Honduras
Hong Kong
Hungary
Iceland
India
Indonesia
Iran
Iraq
Ireland
Isle of Man
Israel
Italy
Jamaica
Japan
Jersey  (Channel Islands)
Jordan
Kazakhstan
Kenya
Kiribati
Kuwait
Kyrgyzstan
Lao People's Democratic Republic
Latvia
Lebanon
Lesotho
Liberia
Libya
Liechtenstein
Lithuania
Luxembourg
Macau
Macedonia
Madagascar
Malawi
Malaysia
Maldives
Mali
Malta
Marshall Islands
Martinique
Mauritania
Mauritius
Mayotte
Mexico
Micronesia, Federated States of
Moldova, Republic of
Monaco
Mongolia
Montenegro
Montserrat
Morocco
Mozambique
Myanmar
Namibia
Nauru
Nepal
Netherlands
Netherlands Antilles
New Caledonia
New Zealand
Nicaragua
Niger
Nigeria
Niue
Norfolk Island
North Korea
Northern Mariana Islands
Norway
Oman
Pakistan
Palau
Palestine
Panama
Papua New Guinea
Paraguay
Peru
Philippines
Pitcairn
Poland
Portugal
Puerto Rico
Qatar
Republic of Kosovo
Reunion
Romania
Russia
Rwanda
Saint Kitts and Nevis
Saint Lucia
Saint Martin
Saint Vincent and the Grenadines
Samoa (Independent)
San Marino
Sao Tome and Principe
Saudi Arabia
Senegal
Serbia
Seychelles
Sierra Leone
Singapore
Sint Maarten
Slovakia
Slovenia
Solomon Islands
Somalia
South Africa
South Georgia and the South Sandwich Islands
South Korea
South Sudan
Spain
Sri Lanka
St. Helena
St. Pierre and Miquelon
Sudan
Suriname
Svalbard and Jan Mayen Islands
Swaziland
Sweden
Switzerland
Syria
Taiwan
Tajikistan
Tanzania
Thailand
Timor-Leste
Togo
Tokelau
Tonga
Trinidad and Tobago
Tunisia
Turkey
Turkmenistan
Turks & Caicos Islands
Turks and Caicos Islands
Tuvalu
Uganda
Ukraine
United Arab Emirates
United Kingdom
Uruguay
USA Minor Outlying Islands
Uzbekistan
Vanuatu
Vatican City State (Holy See)
Venezuela
Vietnam
Virgin Islands (British)
Virgin Islands (U.S.)
Wallis and Futuna Islands
Western Sahara
Yemen
Zambia
Zimbabwe




Send me *
Newsletter: The latest from Knowable Magazine, along with other curated readings and our favorite science-inspired art delivered weekly.
Events: Invitations to our free online event series, featuring leading scientists, scholars and stakeholders discussing frontiers of knowledge and key societal issues.













Close







DONATE: Keep Knowable free to read and share


More FromRethinking air conditioning amid climate changeThe dazzling history of solar powerThe road to low-carbon concrete
RepublishThank you for your interest in republishing! This HTML is pre-formatted to adhere to our guidelines, which include: Crediting both the author and Knowable Magazine; preserving all hyperlinks; including the canonical link to the original article in the article metadata. Article text (including the headline) may not be edited without prior permission from Knowable Magazine staff. Photographs and illustrations are not included in this license. Please see our full guidelines for more information.
    
How heat pumps of the 1800s are becoming the technology of the future
Innovative thinking has done away with problems that long dogged the electric devices ‚Äî and both scientists and environmentalists are excited about the possibilities

    By Chris Baraniuk 
    
  
1.11.2023

    It was an engineering problem that had bugged Zhibin Yu for years ‚Äî but now he had the perfect chance to fix it. Stuck at home during the first UK lockdown of the Covid-19 pandemic, the thermal engineer suddenly had all the time he needed to refine the efficiency of heat pumps: electrical devices that, as their name implies, move heat from the outdoors into people‚Äôs homes.The pumps are much more efficient than gas heaters, but standard models that absorb heat from the air are prone to icing up, which greatly reduces their effectiveness.Yu, who works at the University of Glasgow, UK, pondered the problem for weeks. He read paper after paper. And then he had an idea. Most heat pumps waste some of the heat that they generate ‚Äî and if he could capture that waste heat and divert it, he realized, that could solve the defrosting issue and boost the pumps‚Äô overall performance. ‚ÄúI suddenly found a solution to recover the heat,‚Äù he recalls. ‚ÄúThat was really an amazing moment.‚ÄùYu‚Äôs idea is one of several recent innovations that aim to make 200-year-old heat pump technology even more efficient than it already is, potentially opening the door for much greater adoption of heat pumps worldwide. To date, only about 10 percent of space heating requirements around the world are met by heat pumps, according to the International Energy Agency (IEA). But due to the current  energy crisis and growing pressure to reduce fossil fuel consumption in order to combat climate change, these devices are arguably more crucial than ever.Since his 2020 lockdown brainstorming, Yu and his colleagues have built a working prototype of a heat pump that stores leftover heat in a small water tank. In a paper published in the summer of 2022, they describe how their design¬†helps the heat pump to use less energy. Plus, by separately rerouting some of this residual warmth to part of the heat pump exposed to cold air, the device can defrost itself when required, without having to pause heat supply to the house.The idea relies on the very principle by which heat pumps operate: If you can seize heat, you can use it. What makes heat pumps special is the fact that instead of just generating heat, they also capture heat from the environment and move it into your house ‚Äî eventually transferring that heat to radiators or forced-air heating systems, for instance. This is possible thanks to the refrigerant that flows around inside a heat pump. When the refrigerant encounters heat ‚Äî even a tiny amount in the air on a cold day ‚Äî it absorbs that modicum of warmth.A compressor then forces the refrigerant to a higher pressure, which raises its temperature to the point where it can heat your house. It works because an increase of pressure pushes the refrigerant molecules closer together, increasing their motion. The refrigerant later expands again, cooling as it does so, and the cycle repeats. The entire cycle can run in reverse, too, allowing heat pumps to provide cooling when it‚Äôs hot in summer.The magic of a heat pump is that it can move multiple kilowatt-hours of heat for each kWh of electricity it uses. Heat pump efficiencies are generally measured in terms of their coefficient of performance (COP). A COP of 3, for example, means 1 kWh of juice yields 3 kWh of warmth ‚Äî that‚Äôs effectively 300 percent efficiency. The COP you get from your device can vary depending on the weather and other factors.It‚Äôs a powerful concept, but also an old one. The British mathematician, physicist and engineer Lord Kelvin proposed using heat pump systems for space heating way back in 1852. The first heat pump was designed and  built a few years later and used industrially to heat brine in order to extract salt from the fluid. In the 1950s, members of  the British Parliament discussed heat pumps when coal stocks were running low. And in the years following  the 1973-74 oil crisis, heat pumps were touted as an alternative to fossil fuels for heating. ‚Äú Hope rests with the future heat pump,‚Äù one commentator wrote in the 1977  Annual Review of Energy.Now the world faces yet another reckoning over energy supplies. When Russia, one of the world‚Äôs biggest sources of natural gas, invaded Ukraine in February 2022, the price of gas soared ‚Äî which in turn shoved heat pumps into the spotlight because with few exceptions they run on electricity, not gas. The same month, environmentalist Bill McKibben wrote a widely shared blog post titled ‚ÄúHeat pumps for peace and freedom‚Äù in which, referring to the Russian president, he argued that the US could ‚Äúpeacefully punch Putin in the kidneys‚Äù by rolling out heat pumps on a massive scale while lowering Americans‚Äô dependence on fossil fuels. Heat pumps can draw power from domestic  solar panels, for instance, or a power grid supplied predominantly by renewables.Running the devices on green electricity can help to fight climate change, too, notes Karen Palmer, an economist and senior fellow at Resources for the Future, an independent research organization in Washington, DC, who coauthored  an analysis of policies to enhance energy efficiency in the 2018  Annual Review of Resource Economics. ‚ÄúMoving towards greater use of electricity for energy needs in buildings is going to have to happen, absent a technology breakthrough in something else,‚Äù she says.The IEA estimates that, globally, heat pumps have the potential to reduce carbon dioxide emissions by at least 500 million metric tons in 2030, equivalent to the annual CO 2 emissions produced by all the cars in Europe today.Despite their long history and potential virtues, heat pumps have struggled to become commonplace in some countries. One reason is cost: The devices are substantially more expensive than gas heating units and, because natural gas has remained relatively cheap for decades, homeowners have had little incentive to switch.There has also long been a perception that heat pumps won‚Äôt work as well in cold climates, especially in poorly insulated houses that require a lot of heat. In the UK, for example, where houses  tend to be rather drafty, some homeowners have long considered gas boilers a safer bet because they can supply hotter water ( around 140 to 160 degrees Fahrenheit), to radiators, which makes it easier to heat up a room. By contrast, heat pumps tend to be most efficient when heating water  to around 100 degrees Fahrenheit.The cold-climate problem is arguably less of an issue than some think, however, given that there are multiple modern air source devices on the market that work well even when outside temperatures drop as low as minus 10 degrees Fahrenheit. Norway, for example, is considered one of the world leaders in heat pump deployment. Palmer has a heat pump in her US home, along with a furnace as backup. ‚ÄúIf it gets really cold, we can rely on the furnace,‚Äù she says.Innovations in heat pump design are leading to units that are even more efficient, better suited to houses with low levels of insulation and ‚Äî potentially ‚Äî cheaper, too. For example, Yu says his and his colleagues‚Äô novel air source heat pump design could improve the COP by between 3 percent and 10 percent, while costing less than existing heat pump designs with comparable functionality. They are now looking to commercialize the technology.Yu‚Äôs work is innovative, says Rick Greenough, an energy systems engineer now retired from De Montfort University in the UK. ‚ÄúI must admit this is a method I hadn‚Äôt actually thought of,‚Äù he says.And there are plenty more ideas afoot. Greenough, for instance, has experimented with storing heat in the ground during warmer months, where it can be exploited by a heat pump when the weather turns cool. His design uses a circulating fluid to transfer excess heat from solar hot-water panels into shallow boreholes in the soil. That raises the temperature of the soil by around 22 degrees Fahrenheit, to a maximum of roughly 66 degrees Fahrenheit, he says. Then, in the winter, a heat pump can draw out some of this stored heat to run more efficiently when the air gets colder. This technology is already on the market, offered by some installers in the UK, notes Greenough.But most current heat pumps still only generate relatively low output temperatures, so owners of drafty homes may need to take on the added cost of insulation when installing a heat pump. Fortunately, a solution may be emerging: high-temperature heat pumps.‚ÄúWe said, ‚ÄòHey, why not make a heat pump that can actually one-on-one replace a gas boiler without having to really, really thoroughly insulate your house?‚Äô‚Äù says Wouter Wolfswinkel, program manager for business development at Swedish energy firm Vattenfall, which manufactures heat pumps. Vattenfall and its Dutch subsidiary Feenstra have teamed up to develop a high-temperature heat pump, expected to debut in 2023.In their design, they use CO2 as a refrigerant. But because the heat-pump system‚Äôs hot, high-pressure operating conditions prevent the gas from condensing or otherwise cooling down very easily, they had to find a way of reducing the refrigerant‚Äôs temperature in order for it to be able to absorb enough heat from the air once again when it returns to the start of the heat pump loop. To this end, they added a ‚Äúbuffer‚Äù to the system: a water tank where a layer of cooler water rests beneath hotter water above. The heat pump uses the lower layer of cooler water from the tank to adjust the temperature of the refrigerant as required. But it can also send the hotter water at the top of the tank out to radiators, at temperatures up to 185 degrees Fahrenheit.The device is slightly less efficient than a conventional, lower temperature heat pump, Wolfswinkel acknowledges, offering a COP of around 265 percent versus 300 percent, depending on conditions. But that‚Äôs still better than a gas boiler (no more than 95 percent efficient), and as long as electricity prices aren‚Äôt significantly higher than gas prices, the high temperature heat pump could still be cheaper to run. Moreover, the higher temperature means that homeowners needn‚Äôt upgrade their insulation or upsize radiators right away, Wolfswinkel notes. This could help people make the transition to electrified heating more quickly.A key test was whether Dutch homeowners would go for it. As part of a pilot trial, Vattenfall and Feenstra installed the heat pump in 20 households of different sizes in the town of Heemskerk, not far from Amsterdam. After a few years of testing, in June 2022 they gave homeowners the option of taking back their old gas boiler, which they had kept in their homes, or of using the high temperature heat pump on a permanent basis. ‚ÄúAll of them switched to the heat pump,‚Äù says Wolfswinkel.In some situations, home-by-home installations of heat pumps might be less efficient than building one large system to serve a whole neighborhood. For about a decade, Star Renewable Energy, based in Glasgow, has been building district systems that draw warmth from a nearby river or sea inlet, including a district heating system connected to a Norwegian fjord. A Scandinavian fjord might not be the first thing that comes to mind if you say the word ‚Äúheat‚Äù ‚Äî but the water deep in the fjord actually holds a fairly steady temperature of 46 degrees Fahrenheit, which heat pumps can exploit.Via a very long pipe, the district heating system draws in this water and uses it to heat the refrigerant, in this case ammonia. A subsequent, serious increase of pressure for the refrigerant ‚Äî to 50 atmospheres ‚Äî raises its temperature to 250 degrees Fahrenheit. The hot refrigerant then passes its heat to water in the district heating loop, raising the temperature of that water to 195 degrees Fahrenheit. The sprawling system provides 85 percent of the hot water needed to heat buildings in the city of Drammen.‚ÄúThat type of thing is very exciting,‚Äù says Greenough.Not every home will be suitable for a heat pump. And not every budget can accommodate one, either. Yu himself says that the cost of replacing the gas boiler in his own home remains prohibitive. But it‚Äôs something he dreams of doing in the future. With ever-improving efficiencies, and rising sales in multiple countries, heat pumps are only getting harder for their detractors to dismiss. ‚ÄúEventually,‚Äù says Yu, ‚ÄúI think everyone will switch to heat pumps.‚Äù
    
    

10.1146/knowable-011123-2



Chris Baraniuk is a freelance science journalist and nature lover who lives in Belfast, Northern Ireland. His work has been published by the  BBC, the  Guardian,  New Scientist,  Scientific American and  Hakai Magazine, among other publications.

This article originally appeared in Knowable Magazine, an independent journalistic endeavor from Annual Reviews. Sign up for the newsletter.
  Copy htmlClose
"
https://news.ycombinator.com/rss,Rendering like it's 1996 ‚Äì Baby's first pixel,https://marioslab.io/posts/rendering-like-its-1996/babys-first-pixel/,Comments,"













Mario's Lab





Mario's Lab
Mastodon
Twitter
Github
RSS



Rendering like it's 1996 - Baby's first pixel
December 02, 2022




There's absolutely no chance we'll get to this level of quality.



	In 1996, I was a teen without a gaming console. While my friends enjoyed their Crash Bandicoots, Tekens, and Turoks, I had a beige 486 DX 2 with a turbo button, 16Mb of RAM, a 256Mb hard disk, and a 2x CD-ROM drive running DOS. And then I got a copy of Quake. Did it run great? No. But it did run! And to my young eyes, it was the most beautiful thing I've ever seen on my computer screen. Ok, the most beautiful brown thing.


	3D accelerator graphics cards were in their infancy. Most DOS PC games around that time would render their glorious pixels via the CPU to a dedicated area in RAM, e.g. starting at segment address 0xa000. The (pretty dumb) graphics card would then read and display the contents of that memory area on your bulky CRT. This is known as software rendering or software rasterization.


	I did dabble in some graphics programming back then. I even managed to create a Wolfenstein style first person shooter in QBasic with some assembly before the end of the century.



Actually not a ray casting engine, but a polygonal 3D engine with terrible affine texture mapping.


	But I never really dove into the depths of contemporary graphics technology. And while my subsequent professional career featured plenty of graphics programming, it was mostly the GPU accelerated kind, not the ""worry about each cycle in your inner loops"" software rasterizer kind of type.

(Non-)Goals

	I want to explore the ins and outs of software rasterization, starting from first principles, i.e. getting a pixel on screen. From there, I want to delve into topics like simple demo effects, primitive rasterization, ray casting, voxel terrain, maybe even Quake-style 3D rendering, and whatever else comes to mind.


	Each blog post on a topic will lay out the theory the way I understand it in hopefully simple terms, discuss a naive practical implementation, and finally investigate ways to optimize the implementation until it is reasonably fast.


	The end product(s) should work on Windows, Linux, macOS, and common browsers. Ideally, a little software rasterizer library and demos will fall out at the end, that can serve both as an example implementation of common techniques, or as the basis for other demos or games with DOS game aesthetics.


	You'll be able to follow along both here, and by playing with the code on GitHub. For each blog post, there will be one tagged commit in the main branch you can check out. In addition to the render-y bits, I'll also demonstrate how I set up a cross-platform C project and show you how I structure, build, and debug C code in such a project. I love seeing and learning from other people's workflows. Maybe that's true for you too.


	What I do not want to do is dabble in things like assembly or SIMD optimizations. While that can be fun too, it is unlikely to be necessary on today's hardware, given that I'll target common DOS resolutions like 320x240, or 640x480. I might however inspect and discuss the compiler's assembly output to identify areas that can be improved performance wise in the higher level code.

Tools of the trade

	The weapon of choice will be C99 for aesthetic and practical reasons. I want all the code produced throughout this series to compile anywhere. It should also be easy to re-use the code in other languages through an FFI. C99 is a good choice for both objectives.


	In terms of ompilers, I'll be using Clang with MinGW headers and standard libraries on Windows, Clang through Xcode on macOS, and GCC on Linux. Why Clang on Windows? Because Visual Studio is a multi-gigabyte download, and setting up builds for it is a terrible experience. Clang also generates better code.


	I'll use CMake as the meta build tool, not because I love it, but because my favorite C/C++ IDE CLion has first class support for it. Other development environments understand CMake as well these days, including Visual Studio if that's your kink. For actually executing the builds, I'll use Ninja, which is wicked fast, especially compared to MSBuild and consorts.


	The pixels we'll generate need to be thrown up on the display somehow. On Windows, Linux, and macOS we'll use MiniFB. In a few lines of code, we can open a window, process keyboard and mouse input, and give it a bunch of pixels to draw to the window. It can even upscale our low resolution output if needed. Since MiniFB does not have browser support, I've written a web backend myself and submitted it as a pull request to the upstream repo. In the meantime, we'll use my MiniFB fork, which has web support baked in.


	To get the code running in the browser, we'll use Emscripten to compile the C code to WASM and a small .js file, which loads the .wasm file and exposes our C functions to JavaScript.


	In terms of IDE, you are free to use whatever you want. You'll most likely want something that can ingest CMake builds. For this series, I choose VS Code, not because I love it, but because it's free. The project contains a bunch of VS Code specific settings that make working on the project super simple for all supported platforms.

Getting the source code and tools

	That's a lot of tools! I've tried to make it as simple for you to follow along as possible. Here's what you need to install:


Visual Studio Code
Make sure code can be called on the command line! Open VS Code, press CTRL+SHIFT+P (or CMD+SHIFT+P on macOS), type Shell Command: Install 'code' command in PATH and hit enter.
Windows:

Git for Windows. Make sure its available on the command line via the system PATH.


Linux:

Git, GCC, GDB, Python, CMake, Curl, libx11-dev, libxkbcommon-dev, and libgl1-mesa-dev. On Ubuntu sudo apt install build-essential git gdb python3.11 cmake curl libx11-dev libxkbcommon-dev libgl1-mesa-dev


macOS:

Xcode. Make sure to also install the command line tools




	Once you've installed the above, clone the repository (on Windows, use Git Bash, which comes with Git for Windows):


git clone https://github.com/badlogic/r96
cd r96


	Next, checkout the tag for the blog post you want to follow along with, execute the tools/download-tools.sh script:


git checkout 01-babys-first-pixel
./tools/download-tools.sh


	The download-tools.sh script will download all remaining tools that are needed, like CMake, Ninja, Clang for Windows, Python, a small static file server, Emscripten, and Visual Studio Code extensions needed for C/C++ development. See the README.md for details.


Note: we may add new tools in future blog posts. After checking out a tag for a blog post, make sure to run tools/download-tools.sh again.

The r96 project

	These are the goals for the project scaffold:


Make building and debugging for the desktop and the web trivial.
Allow adding new demo apps that work without code modification on both the desktop and in the browser
Make creating re-usable code easy.


	Let's see how I tried to achieve the above. Open your clone of the r96 Git repository in VS Code and have a look what's inside.


Note: The first time you open the project in VS Code, you'll be asked to select a CMake configure preset.


Note: the first time you open a source file in VS Code, you will be asked if you want to install clangd. Click Yes.

File structure




Let's start in the root folder.

	The .gitignore, LICENSE, and README.md files are self-explanatory.


	The CMakeLists.txt and CMakePresets.json define our build. We'll look into these in a later section.


	The .clang-format file stores the formatting settings used to format the code via, you guessed it, clang-format. The VS Code C/C++ extension uses the settings in that file whenever you format a C/C++ source file. The file can also be used to format the entire code base from the command line.


	The src/ folder contains our code. Re-usable code goes into src/r96/. Demo apps go into the root of the src/ folder. There are two demo apps so far called 00_basic_window.c and 01_drawing_a_pixel.c. Any demo apps we write in subsequent blog posts will also go into src/ and start with a sequential number, so we immediately see in which order they were written.


	The src/web/ folder may be weird, even scary to seasoned C veterans. But we need it to run our demo apps on the web. A small price to pay. It contains one .html file per demo app. The purpose of that file is to:


Load the .js and .wasm files generated by Emscripten for the demo app executable target
Provide the demo app with a HTML5 canvas element to draw to
Kick off the demo apps execution by calling its main() function


	For any demo app we write in the future, we'll add a source file to the src/ folder, and a corresponding .html file to the src/web/ folder.


	The src/web/index.html file is just a plain listing linking to all the .html files of our demo apps. The src/web/r96.css file is a CSS style sheet used to make the elements in the demo app .html files a little prettier.


	The .vscode/ folder contains settings and launch configurations so working on the project is a nice experience in VS Code.


	Finally, the tools/ folder contains scripts to download the necessary tools as well as configuration files for a few of those tools. When executing the tools/download-tools.sh script, some of the tools actually get installed in the tools/ folder so they don't clog up your system. The folder also contains scripts and batch files used by the launch configurations to do their work.


	The details of the .vscode and tools folder are all gory and duct tape-y. You can have a look if you must. For the remained of the series, their content doesn't matter much. Just know that they are setup in a way to make our lives easy.

Building

The first time you open the project in VS Code, you're asked to select a configure preset.







	A configure preset defines for what platform the code should be build and with what compiler and build flags that should happen. The presets are defined in CMakePresets.json.


	For each platform the r96 project supports, there is a corresponding debug and release configure preset. To start, we'll select Desktop debug. You can also select the configure preset in the status bar at the bottom of VS Code.






	To build the project for the selected platform and build type (debug or release), click the Build button in the status bar.






	Alternatively, you can open the VS Code command palette (CTRL+SHIFT+P or CMD+SHIFT+P on macOS), type CMake: Build, and hit enter.


	In both cases, the CMake Tools extension, which was installed as part of tools/download-tools.sh, will configure the CMake build if necessary, then incrementally build the libraries and executables defined in CMakeLists.txt.


	The resulting build output consisting of executables and assets can be found in build/<os>-<build-type>. E.g. for Desktop debug, the build output will be located in build/windows-debug, build/linux-debug, or build/macos-debug depending on what operating system you are on. For Web release the output will be in build/web-output, and so on.


Note: To learn more about how to use VS Code CMake integration, check out the documentation.


	You can of course also build the project on the command line:


# Configure a Windows debug build and execute the build
cmake --preset windows-debug
cmake --build build/windows-debug

# Configure a web release build and execute the build
cmake --preset web-release
cmake --build build/web-release

Debugging

	The launch.json file in the .vscode/ folder defines launch configurations for each platform. Click the launch button in the status bar to select the launch configuration and start a debugging session. 






	After clicking this status bar entry, you'll be asked to select a launch configuration:






	When you first start a debugging session, you'll be asked to select a launch target, aka the executable you want to launch:






	You can also change the launch target in the status bar:






	After selecting the launch target, the code is incrementally rebuild, and the debugging session starts. 


	Instead of going through the status bar, you can also start a new debugging sessions by pressing `F5`. This will launch a session for the currently selected launch configuration, configure preset, and launch target.


Important: the launch configuration MUST match the preset you selected:


Desktop debug target: select the Desktop debug or Desktop release preset.
Web debug target: select the Web debug or Web release preset.


	Debugging a desktop build is the standard experience you are used to. Set breakpoints and watches, interrupt the program at any time, and so on.


	Debugging the C code compiled to WASM directly in VS Code is not possible. When you start a web debugging session, the respective launch configuration starts a local static file server (downloaded via tools/download-tools.sh) and opens the .html file corresponding to the selected launch target in a browser tab.


	When you are done ""debugging"" a web build, close the browser tab, and close the debugging session in VS Code by clicking the ""Stop"" button in the debugger controls.


 If you feel adventurous: it is possible to debug the C and JavaScript code in Chrome.. We'll look into that below.

Dissecting the CMakeLists.txt and CMakePresets.json files
To understand how the build is setup, we need to understand the CMakeLists.txt and CMakePresets.json files.

	We've already had a brief look at the CMakePresets.json file above. It defines a configure preset for each operating system and build type combination. Let's have a look at one of the presets, specifically, the one used for Windows debug builds.


{
	""name"": ""windows-debug"",
	""displayName"": ""Desktop debug"",
	""description"": """",
	""generator"": ""Ninja"",
	""binaryDir"": ""${sourceDir}/build/${presetName}"",
	""cacheVariables"": {
		""CMAKE_BUILD_TYPE"": ""Debug"",
		""CMAKE_MAKE_PROGRAM"": ""${sourceDir}/tools/desktop/ninja/ninja""
	},
	""toolchainFile"": ""${sourceDir}/tools/desktop/toolchain-clang-mingw.cmake"",
	""condition"": {
		""type"": ""equals"",
		""lhs"": ""${hostSystemName}"",
		""rhs"": ""Windows""
	}
},


The important bits are:


generator: we tell CMake to generate a Ninja build.
binaryDir: specifies the output directory for the build. In this case it maps to build/windows-debug through variable substitution.
CMAKE_BUILD_TYPE: tells CMake we want the binaries to include debugging information.
CMAKE_MAKE_PROGRAM: tells CMake were to find the Ninja executable. The tools/download-tools.sh script downloaded the executable to tools/desktop/ninja/
toolchainFile: where to find the compiler and linker. On Windows, we use Clang with MinGW headers and standard libraries., which the tools/download-tools.sh script downloads to tools/desktop/clang. The toolchain file references the compiler and linker in that location and sets up a few other CMake cache variables.
condition: tells CMake to only enable this configure preset if we're running on Windows.


	The other configure presets are pretty similar and only differ in what operating system they should be available on, as well as the toolchain being used. On macOS and Linux, the default toolchain is used (GCC or Xcode's Clang). For the web, the Emscripten toolchain is used through a toolchain file that ships with Emscripten.


	We could work without this presets file, but that would mean we'd have to specify all these parameters manually every time we configure a CMake build. With the presets, this becomes cmake --preset <preset-name>. Much nicer!


	The CMakeLists.txt file defines the actual build itself, i.e. which source files make up which libraries and executables, and what compiler flags to use. Definitions of libraries and executables are called targets in CMake. Let's go through it section by section. We start out with this:


cmake_minimum_required(VERSION 3.21.1)
project(r96)

set(CMAKE_C_STANDARD 99)
set(CMAKE_C_STANDARD_REQUIRED TRUE)
set(CMAKE_EXPORT_COMPILE_COMMANDS TRUE)


	We define the minimum CMake version and project name, and enable (and require) C99 support. The final line makes CMake generate a compile_commands.json file in the build folder. This is also known as a compilation database and used by many IDEs to understand a CMake build. In our case, the file is used by the clangd VS Code extension to provide us with code completion and other niceities.


include(FetchContent)
FetchContent_Declare(minifb GIT_REPOSITORY https://github.com/badlogic/minifb GIT_TAG dos-pr-master)
set(MINIFB_BUILD_EXAMPLES CACHE INTERNAL FALSE)
FetchContent_MakeAvailable(minifb)


	Next we pull in MiniFB via CMake's FetchContent mechanism. CMake veterans may sneer at this and rather use a Git submodule. But I like it that way, thank you very much. This magic incantation will clone my MiniFB fork with web support, disable the MiniFB example targets, and finally make the remaining MiniFB library target available to the targets defined in our own CMakeLists.txt. Nice.


add_compile_options(-Wall -Wextra -Wpedantic -Wno-implicit-fallthrough)


	This section sets the ""pedantic warnings are errors"" compiler flags. We want the code to be reasonably clean and fail if a warning is generated.


add_library(r96 ""src/r96/r96.c"")


	Next we add a library target called r96. It's compiled from the r96/r96.c source file. Any re-usable code we write during the course of this blog post series will go in there. Any of our demo app executable targets can then depend on the r96 library target to pull in its code.


add_executable(r96_00_basic_window ""src/00_basic_window.c"")
add_executable(r96_01_drawing_a_pixel ""src/01_drawing_a_pixel.c"")


	We define two executable targets for the demos of this blog post.


add_custom_target(r96_web_assets
    COMMAND ${CMAKE_COMMAND} -E copy_directory
    ${CMAKE_CURRENT_SOURCE_DIR}/src/web
    $<TARGET_FILE_DIR:r96_00_basic_window>
)


	We define a custom target that copies all the .html files from src/web/ to the output folder. This target is needed for web builds.


get_property(targets DIRECTORY ""${_dir}"" PROPERTY BUILDSYSTEM_TARGETS)
list(REMOVE_ITEM targets minifb r96 r96_assets r96_web_assets)
foreach(target IN LISTS targets)
    target_link_libraries(${target} LINK_PUBLIC minifb r96)    
    if(EMSCRIPTEN)
        add_dependencies(${target} r96_web_assets)
        target_link_options(${target} PRIVATE
                ""-sSTRICT=1""
                ""-sENVIRONMENT=web""
                ""-sLLD_REPORT_UNDEFINED""
                ""-sMODULARIZE=1""
                ""-sALLOW_MEMORY_GROWTH=1""
                ""-sALLOW_TABLE_GROWTH""
                ""-sMALLOC=emmalloc""
                ""-sEXPORT_ALL=1""
                ""-sEXPORTED_FUNCTIONS=[\""_malloc\"",\""_free\"",\""_main\""]""
                ""-sASYNCIFY""
                ""--no-entry""
                ""-sEXPORT_NAME=${target}""
        )
    endif()
endforeach()


	And then stuff gets crazy! The first two lines compiles a list of all demo executable targets. We then iterate through those executable targets and link the r96 library target to each of them. If we build for the web, we also add the custom r96_web_assets target to the executable as a dependency, so the .html files get copied over to the output folder.


	Finally, we add a few Emscripten specific linker options. These are settings I arrived at after working with WASM for the last 2 years. They are all Emscripten specific and do things like allowing heap memory to grow. You can check out all the options in Emscripten's settings.js file. There's a lot.

The purpose of this evil incantation is to reduce the amount of CMake spaghetti needed when adding a new demo. All we need to do is add a single add_executable_target() line, specifiyng the demo name and source files its composed of. The evil incantation will then link the new demo up with all the necessary bits automatically. Nice!
The first demo app: 00_basic_window

	Before we can get our hands dirty with programmatically creating the most beautiful pixels in the world, we need to understand how MiniFB works and how a demo app is structured in terms of code. With no further ado, here's src/00_basic_window.c:


#include <MiniFB.h>
#include <stdlib.h>

int main(void) {
	const int res_x = 320, res_y = 240;
	struct mfb_window *window = mfb_open(""00_basic_window"", res_x, res_y);
	uint32_t *pixels = (uint32_t *) malloc(sizeof(uint32_t) * res_x * res_y);
	do {
		mfb_update_ex(window, pixels, res_x, res_y);
	} while (mfb_wait_sync(window));
	return 0;
}


	This is a minimal MiniFB app that opens a window with a drawing area of 320x240 pixels (line 6). It then allocates a buffer of 320x240 unit32_t elements (line 7). Each uint32_t element encodes the color of a pixel. Next, we keep drawing the contents of the buffer to the window via mfb_update_ex() (line 9) until mfb_wait_sync() returns false (line 10), e.g. because the user pressed the ESC key to quit the app. It can't get any simpler.


	MiniFB has a super minimal API. You can learn more about it here.


Note: The mfb_update_ex() function also returns a status code which can be used to decide if the app should be exited. We're not using this above for brevity's sake.

Running the demo app on the desktop

	To compile and run (or debug) our little demo app on the desktop, select the Desktop debug configure preset in the VS Code status bar, select the r96_00_basic_window target as the launch target, and the Desktop debug target launch configuration. Press F5 and you'll get this:



r96_00_basic_window on the desktop.


	Most impressive. You can make changes to the code and just hit F5 again to incrementally rebuild and restart the demo app. You can also set breakpoints, inspect variables and call stacks, and so on.


	Now how do we run the same demo app in the browser?

Running the demo app on the web

	Select the Web debug configure preset, and the Web debug target launch configuraton and press F5. You'll see this:



r96_00_basic_window running in the browser.


	The launch configuration starts a static file server (tools/web/static-server) which serves the files in build/web-debug/ on port 8123. The static server will also automatically open a browser tab with the URL corresponding to the demo's .html file.

When you're done being amazed by this, close the browser tab, and click the Stop button in the debugger controls in VS Code. If you want to be amazed again, just press F5
How the web version works

	It's kind of magic. Here's how the 00_basic_window.html file for the 00_basic_window.c demo app looks like:


<html>
<!DOCTYPE html>
<html lang='en'>
<head>
    <meta charset='utf-8'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1'>
    <link rel='stylesheet' href='r96.css'>
    <script src='r96_00_basic_window.js'></script>
</head>
<body class='r96_content'>
    <h2>Basic window</h2>
    <canvas id='00_basic_window'></canvas>
</body>
<script>
    async function init() {
        await r96_00_basic_window()
    }

    init();
</script>
</html>


	Ignoring the boring HTML boilerplate, we see that the r96_00_basic_window.js file is loaded via a <script> tag. This file was generated as part of the build by Emscripten. It contains JavaScript code that loads the WebAssembly file that stores our compiled C code and exports functions with which we can interact with the WebAssembly code.

	Next we define a <canvas> with the id 00_basic_window. Finally, a little JavaScript kicks of a call to r96_00_basic_window() (defined in r96_00_basic_window.js) in an asynchronous function. This call will load the r96_00_basic_window.wasm file and run its main() method.


	How does MiniFB know to render to the canvas? In our C code we have this line:


struct mfb_window *window = mfb_open(""00_basic_window"", res_x, res_y);


	Instead of opening a window with ""00_basic_window"" as the title, the MiniFB web backend uses the first argument passed to mfb_open() to search a canvas element with that string as its id. Any calls to mfb_update_ex() will then draw the contents of the provided buffer to this canvas.


	Also of note: We didn't have to modify our C code at all, it just ""works"". If you've ever done any front-end development, that may be very weird to you. The app basically has an infinite loop! If you do that in JavaScript, the browser tab (or the whole browser) will freeze, because the browser engine's event loop will never get a chance to run and process events. How does this magic work?


	The MiniFB web backend I wrote uses an Emscripten feature called Asyncify. In the implementation of mfb_wait_sync(), I call emscripten_sleep(0). This gives back control to the browser engine, so it can process any DOM events and not freeze. Our native C code will then resume again, without our C code ever knowing that it was actually put to sleep. The Asyncify feature rewrites our C code (or rather its WASM representation) to use continuations. That allows pausing and resuming the C code transparently. Super cool!

Can I debug the C code in the browser?

	Yes, we can in Chrome. When we build using the Web debug configure preset, Emscripten will emit DWARF information in the resulting .wasm file. Chrome can use that information to provide native code debugging right in the developer tools. To get that working:


Install Chrome
Install the C/C++ DevTools Support (DWARF) extension in Chrome
Open Chrome Developer Tools, click the gear (‚öô) icon in the top right corner of dev tools pane, go to the experiments panel and tick WebAssembly Debugging: Enable DWARF support





Restart Chrome


	 Launch the demo app using the Web debug target launch config in VS code, then open the dev tools in the browser, and click on the Sources tab. You can find all the .c files that make up our little demo app under the file:// node, including the MiniFB sources. Open up 00_basic_window.c and set a breakpoint inside the loop:



C/C++ debugging in Chrome


	And there you have it: C/C++ debugging in Chrome! Since the C code runs the same on both the desktop and in the browser, we'll likely never need this functionality, unless we implement web specific features.


	Speaking of features, let's add a second demo app and draw our first pixel! But first, some very practical ""theory"".

Of colors, pixels, and rasters

	What's a pixel? Rumor has it that pixel is a stylized abbreviation of ""(pic)ture (el)ement"". A precise answer is actually quite involved and may even depend on the decade you are living in.


	Here, we lazily and imprecisely define a pixel as the smallest ""atomic"" area within a raster for which we can define a color. A raster is a rectangular area made up  of pixels. Each pixel in the raster is assumed to have the same size. The width of a raster equals the number of pixels in a row, the height equals the number of pixels in a column.


	The below raster has a width of 23 pixels and a height of 20 pixels. To locate a pixel inside the raster, we use an integer coordinate system, with the x-axis pointing to the right, and the y-axis pointing down. The top left pixel in the raster is at coordinate (0, 0), the top right pixel is at coordinate (22, 0) (or (width - 1, 0)), the bottom right pixel is at coordinate (22, 19) (or (width - 1, height -1)), and so on.



A fishy raster. Source: Wikipedia


	A raster can be a display device's output area, a piece of grid paper, etc. The rasters we'll work with are two-dimensional arrays in memory. Each array element stores the color of the pixel in some encoding.

Color encodings

	We encode the color of a pixel using the RGBA color model, where a color is represented as an additive mix of its red, green, and blue components, and an additional alpha component specifying the pixel's opacity. The opacity comes into play when we blend pixels of one raster with pixels from another raster. That's a topic for another blog post.


	More specifically, we use an ARGB8888 encoding that fits in a 32-bit unsigned integer (or uint32_t in C). Each color component is encoded as an 8-bit integer in the range 0 (no contribution) to 255 (highest contribution). For the alpha component, 0 means ""fully transparent"" and 255 means ""fully opaque"".


	Here's how the components are stored in a 32-bit unsigned integer. The most significant byte stores the alpha component, then come the red, green, and blue bytes.



Storage layout of an ARGB8888 color in a 32-bit unsigned integer. Source: Wikipedia



Here are a few colors in C:



uint32_t red = 0xffff0000;
uint32_t green = 0xff00ff00;
uint32_t blue = 0xff0000ff;
uint32_t pink = 0xffff00ff;
uint32_t fifty_percent_transparent_white = 0x80ffffff;


	More generally, we can compose a color by bit shifting and or'ing its individual components:


uint8_t alpha = 255; // fully opaque
uint8_t red = 20;    // a little red
uint8_t green = 200; // a lot of green
uint8_t blue = 0;    // no blue
uint32_t color = (alpha << 24) | (red << 16) | (green << 8) | blue;


	That looks like a great candidate for a re-usable macro! Why a macro? Because C99 support in Microsoft's C++ compiler is still meh and who knows how it does with inlined functions defined in a header. The macro guarantees that the code is inlined at the use site. Let's put the following in src/r96/r96.h


#include <stdint.h>

#define R96_ARGB(alpha, red, green, blue) (uint32_t)(((uint8_t) (alpha) << 24) | ((uint8_t) (red) << 16) | ((uint8_t) (green) << 8) | (uint8_t) (blue))


	Defining a color then becomes:


uint32_t color = R96_ARGB(255, 20, 200, 0);

Adressing a pixel in a raster

	We now can define colors easily. But how do we work with rasters in code and manipulate the colors of its pixels? We already did! Remember this line from our 00_basic_window demo app?


const int res_x = 320, res_y = 240;
...
uint32_t *pixels = (uint32_t *)malloc(res_x * res_y * sizeof(uint32_t))


	This allocates memory to store a 320x240 raster where each pixel is stored in a uint32_t. Each row of pixels is stored after the other. We can think of it as a one-dimensional array storing a two-dimensional raster.


This raster is passed to mfb_update_ex() to be drawn to the window. The reason the window content remains black is that the pixels all have the color 0x00000000 aka black (at least when building the debug variant or for Emscripten).


	We can set the pixel in the top left corner at coordinate (0, 0) to the color red like this:


pixels[0] = R96_ARGB(255, 255, 0, 0);


	OK, that was obvious. But how about a pixel at an arbitrary coordinate? Let's look at a smaller 4x3 pixel raster:




Our raster is a one dimensional block of memory. The pixel rows are stored one behind the other. The 4 pixels of the first pixel row with y=0 are stored in pixels[0] to pixels[3]. The index of a pixel in the first row is simply its x-coordinate. E.g. the pixel at coordinate (2, 0) is stored in pixels[2].

The pixels of the second row with y=1 are stored in pixels[4] to pixels[7]. The pixels of the third row with y=2 are stored in pixels[8] to pixels[11]. In general, the first pixel of a row at y-coordinate y is located at pixels[y * width]. And to address any pixel inside a row, we just add its x-coordinate! The general formula to go from a pixel's (x, y) coordinate to an index in the one dimensional array representing the raster is thus x + y * width!


Note: this is how C implements two-dimensional arrays under the hood as well. The principle also applies to higher dimensional arrays.


	If we want to set the color of the pixel at (160, 120) to red in our 320x240 pixel raster, we can do it like this:


const int res_x = 320, res_y = 240;
...
pixels[160 + 120 * res_x] = R96_ARGB(255, 255, 0, 0);

Alright, time to draw some pixels!
Demo app: drawing a pixel

	Drawing a single pixel is a bit boring, so how about we flood the screen with a gazillion pixels instead?


#include <MiniFB.h>
#include <stdlib.h>
#include <string.h>
#include ""r96/r96.h""

int main(void) {
	const int res_x = 320, res_y = 240;
	struct mfb_window *window = mfb_open(""01_drawing_a_pixel"", res_x, res_y);
	uint32_t *pixels = (uint32_t *) malloc(sizeof(uint32_t) * res_x * res_y);
	do {
		for (int i = 0; i < 200; i++) {
			int32_t x = rand() % res_x;
			int32_t y = rand() % res_y;
			uint32_t color = R96_ARGB(255, rand() % 255, rand() % 255, rand() % 255);
			pixels[x + y * res_x] = color;
		}

		if (mfb_get_mouse_button_buffer(window)[MOUSE_BTN_1]) {
			memset(pixels, 0, sizeof(uint32_t) * res_x * res_y);
		}

		mfb_update_ex(window, pixels, res_x, res_y);
	} while (mfb_wait_sync(window));
	return 0;
}


	The interesting bit happens in lines 11 to 15. Each frame, we generate 200 pixels at random coordinates with random colors. We ensure that the coordinates are within the raster bounds by % res_x and % res_y. We also clamp the color components to the range 0-255 via modulo.


	We also introduce some light input handling by checking if the left mouse button is pressed. If so, we set all pixels to the color black, giving the ""user"" a way to restart the glorious demo.


	Finally, we pass the pixels to mfb_update_ex(), which will draw them to the window.


	And here it is live in your browser, because why would we spend so much time getting the WASM build to work so nicely. Click/touch to start!







	I sure feel all this build up paid off, don't you?

Mario, WTF

	Yeah, I'm sorry. I sometimes just drift off. But we learned a lot! Next time I likely won't be so wordy. We'll have a looksy at how to draw rectangles. Exciting!


	Read the the next article in the series.


	Discuss this post on Twitter or Mastodon.





"
https://news.ycombinator.com/rss,Tesla Price Drop Angers Current Owners,https://www.bloomberg.com/news/articles/2023-01-13/tesla-price-drop-angers-current-owners-as-much-as-it-hits-profit-margins,Comments,"


Bloomberg - Are you a robot?









Bloomberg
Need help? Contact us


We've detected unusual activity from your computer network
To continue, please click the box below to let us know you're not a robot.




Why did this happen?
Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our Terms of
                Service and Cookie Policy.


Need Help?
For inquiries related to this message please contact
            our support team and provide the reference ID below.
Block reference ID:








"
https://news.ycombinator.com/rss,The art and science of spending money,https://collabfund.com/blog/the-art-and-science-of-spending-money/,Comments,"


























The Art and Science of Spending Money ¬∑ Collab Fund



















Blog


About


Shared Future


SOS


Currency


Public


Blog












About


Shared Future


SOS


Currency


Public


Blog


Follow @collabfund








            
              The Art and Science of Spending Money
            
          







      Jan 12, 2023
    

SHARE ‚Üì




        by
        Morgan Housel
@morganhousel

























          Copy Link
        












Former General Electric CEO Jack Welch once nearly died of a heart attack. Years later he was asked what went through his mind while he was being rushed to the hospital in what could have been his last moments alive.
‚ÄúDamn it, I didn‚Äôt spend enough money,‚Äù was Welch‚Äôs response.
The interviewer, Stuart Varney, was puzzled, and asked why in the world that would go through his mind.
‚ÄúWe all are products of our background,‚Äù Welch said. ‚ÄúI didn‚Äôt have two nickels to rub together [when I was young], so I‚Äôm relatively cheap. I always bought cheap wine.‚Äù
After the heart attack Welch said he ‚Äúswore to God I‚Äôd never buy a bottle of wine for less than a hundred dollars. That was absolutely one of the takeaways from that experience.‚Äù
‚ÄúIs that it?‚Äù Varney asks, stunned.
‚ÄúThat‚Äôs about it,‚Äù says Welch.
Money is so complicated. There‚Äôs a human element that can defy logic ‚Äì it‚Äôs personal, it‚Äôs messy, it‚Äôs emotional.
Behavioral finance is now well documented. But most of the attention goes to how people invest. Welch‚Äôs story shows how much deeper the psychology of money can go. How you spend money can reveal an existential struggle of what you find valuable in life, who you want to spend time with, why you chose your career, and the kind of attention you want from other people.
There is a science to spending money ‚Äì how to find a bargain, how to make a budget, things like that.
But there‚Äôs also an art to spending. A part that can‚Äôt be quantified and varies person to person.
In my book I called money ‚Äúthe greatest show on earth‚Äù because of its ability to reveal things about people‚Äôs character and values. How people invest their money tends to be hidden from view. But how they spend is far more visible, so what it shows about who you are can be even more insightful.
Everyone‚Äôs different, which is part of what makes this topic fascinating. There are no black-and-white rules.
But here are a few things I‚Äôve noticed about the art of spending money.
1. Your family background and past experiences heavily influences your spending preferences.
I love this Washington Post headline from June, 1927 ‚Äì the Roaring ‚Äò20s, the last hurrah before the Great Depression:

This is timeless, and explains so much.
After Covid lockdowns there was the concept of ‚Äúrevenge spending‚Äù ‚Äì a furious blast of conspicuous consumption, letting out everything that had been pent up and held back in 2020.
Revenge spending happens at a broad level, too. The most stunning examples I‚Äôve seen of this are wealthy adults who grew up poor ‚Äì and were heckled, bullied, and teased for being poor as kids. Their revenge spending mentality can become permanent.
If you dig into it, I think you‚Äôll see that a disproportionate share of those with the biggest homes, the fastest cars, and the shiniest jewelry, grew up ‚Äúsnubbed‚Äù in some way. Part of their current spending isn‚Äôt about getting value out of flashy material goods; it‚Äôs about healing a social wound inflicted when they were younger.
Even when ‚Äúwound‚Äù is the wrong word, the desire to show the world that you‚Äôve made it increases if you grew up snubbed out of what you wanted. To someone who grew up in an old-money affluent family, a Lamborghini might be a symbol of gaudy egotism; to those who grew up with nothing, the car might serve as the ultimate symbol that you‚Äôve made it.
A lot of spending is done to fulfill a deep-seated psychological need.
2. Entrapped by spending: Rather than using money to build a life, your life is built around money.
George Vanderbilt spent six years building the 135,000-square-foot Biltmore house ‚Äì with 40 master bedrooms and a full-time staff of nearly 400 ‚Äì but allegedly spent little time there because it was ‚Äúutterly unaddressed to any possible arrangement of life.‚Äù The house nevertheless cost so much to maintain it nearly ruined Vanderbilt. Ninety percent of the land was sold off to pay tax debts, and the house was turned into a tourist attraction.
In 1875 an op-ed said socialites ‚Äúdevote themselves to pleasure regardless of expense.‚Äù A Vanderbilt heir responded that actually they ‚Äúdevote themselves to expense regardless of pleasure.‚Äù
The Vanderbilt‚Äôs are obviously extreme, but that is a common trait among more ordinary people.
The devotion to expense regardless of pleasure.
Part of this is the belief that spending money will make you happier. When it doesn‚Äôt ‚Äì either because it never will or because you haven‚Äôt discovered purchases that bring joy ‚Äì your reaction is that you must not be spending enough, so you double down, again and again.
I‚Äôve often wondered how many personal bankruptcies and financial troubles were caused by spending that brought no joy to begin with. It must be enormous. And it‚Äôs a double loss: not only are you in trouble, but you didn‚Äôt even have fun getting there.
I have an old friend who buried himself in credit card debt to go skiing in Europe and loved every second of it. I can wrap my head around that decision, even if I wouldn‚Äôt recommend it. He‚Äôs in control of his finances.
But what about those whose spending is driven by the belief that money is to be spent, regardless of what pleasure it brings? Money has them by the neck; they are held in captivity by its influence.
3. Frugality inertia: a lifetime of good savings habits can‚Äôt be transitioned to a spending phase.
I think what many people really want from money is the ability to stop thinking about money. To have enough money that they can stop thinking about it and focus on other stuff.
But that ultimate goal can break down when your relationship with money becomes an ingrained part of your personality. You struggle to break away from focusing on money because the focus itself is a big part of who you are.
If you develop an early system of savings and living well below your means ‚Äì congratulations, you‚Äôve won. But if you can never break away from that system, and insist on a heavy savings regimen well into your retirement years ‚Ä¶ what is that? Is it still winning?
A lot of financial planners I‚Äôve talked to say one of their biggest challenges is getting clients to spend money in retirement. Even an appropriate, conservative amount of money. Frugality and savings become such a big part of some people‚Äôs identity that they can‚Äôt ever switch gears.
I think for some people that‚Äôs actually fine. Watching money compound gives them more pleasure than they would get spending it.
But those whose ultimate goal is to stop thinking about money are stuck. Refusing to recognize that you‚Äôve met your goal can be as bad as never meeting the goal to begin with.
4. An emotional attachment to large purchases, particularly a house.
My wife and I pride ourselves on making unemotional financial decisions. But a few years ago we were in the market for our first house. We found one online that we liked, and as we headed out for a tour we promised ourselves we wouldn‚Äôt do anything rash ‚Äì this was just gathering information.
Then we pulled into the driveway and my wife gasped, ‚ÄúI love it!‚Äù I did too. We had an infant son ‚Äì our first ‚Äì and there was a kids‚Äô tree swing in the front yard. Perfect.
And that was it. Emotion was involved and there was nothing we could do about it.
We have zero regrets ‚Äì the house really was great. But no one should pretend that you can make life-changing decisions that will massively impact you and your family and treat it like a math problem.
Jason Zweig of The Wall Street Journal once wrote about his mom selling her longtime home:

‚ÄúI have no emotional attachment to the house; I never liked it physically,‚Äù Mom told us. ‚ÄúBut everything important that ever happened in our life as a family is here, and I can‚Äôt just leave all that behind.‚Äù

If I said, ‚ÄúHow much are the memories with your kids worth?‚Äù you‚Äôd say it‚Äôs impossible to attach a dollar figure. But if I said, ‚ÄúHow much is the home where you formed memories with your kids worth?‚Äù or ‚ÄúHow much does staying in your local town impact your salary?‚Äù you could probably spit out a dollar figure with ease.
Understanding the difference between those two helps explain a lot of spending decisions.
5. The joy of spending can diminish as income rises because there‚Äôs less struggle, sacrifice, and sweat represented in purchases.
In his 1903 book The Quest for the Simple Life, William Dawson writes:

The thing that is least perceived about wealth is that all pleasure in money ends at the point where economy becomes unnecessary. The man who can buy anything he covets, without any consultation with his banker, values nothing that he buys.

Consider how you felt when you got your first paycheck from your first job. If you celebrated with as little as a milkshake from Denny‚Äôs you probably had a joyous feeling of, ‚ÄúI did this. I bought this. With my own money.‚Äù Going from not being able to buy anything to able to buy something is an amazing feeling. The gap between struggle and reward is a big part of what makes people happy.
Contrast that with later in your career, when (hopefully) savings have been built and paychecks have grown. It‚Äôs not that spending won‚Äôt make you happy ‚Äì but it won‚Äôt be as thrilling and adrenaline-inducing as it was when there was more struggle behind each dollar.
I know a guy with a private chef. He‚Äôs served 5-star meals three times a day, an arrangement he‚Äôs enjoyed for years. It‚Äôs amazing; I‚Äôd lie if I said I wasn‚Äôt jealous. But I also wonder if the joy diminishes over time. He doesn‚Äôt have to struggle to get these meals ‚Äì there‚Äôs no anticipation, no looking forward to a restaurant reservation, no contrasting gap between a ‚Äúnormal‚Äù meal and his daily delicacy.
There‚Äôs a saying that the best meal you‚Äôll ever taste is a glass of water when you‚Äôre thirsty. All forms of spending have that equivalent.
Let me end with a wise quote from, of all people, Richard Nixon:

The unhappiest people of the world are those in the international watering places like the South Coast of France, and Newport, and Palm Springs, and Palm Beach. Going to parties every night. Playing golf every afternoon. Drinking too much. Talking too much. Thinking too little. Retired. No purpose.
So while there are those that would disagree with this and say ‚ÄúGee, if I could just be a millionaire! That would be the most wonderful thing.‚Äù If I could just not have to work every day, if I could just be out fishing or hunting or playing golf or traveling, that would be the most wonderful life in the world ‚Äì they don‚Äôt know life. Because what makes life mean something is purpose. A goal. The battle. The struggle ‚Äì even if you don‚Äôt win it.

6. Asking $3 questions when $30,000 questions are all that matter.
There‚Äôs a saying: Save a little bit of money each month, and at the end of the year you‚Äôll be surprised at how little you still have.
Author Ramit Sethi says too many people ask $3 questions (can I afford this latte?) when all that matters to financial success are $30,000 questions (what college should I go to?)
Historian Cyril Parkinson coined a thing called Parkinson‚Äôs Law of Triviality. It states: ‚ÄúThe amount of attention a problem gets is the inverse of its importance.‚Äù
Parkinson described a fictional finance committee with three tasks: approval of a $10 million nuclear reactor, $400 for an employee bike shed, and $20 for employee refreshments in the break room.
The committee approves the $10 million nuclear reactor immediately, because the number is too big to contextualize, alternatives are too daunting to consider, and no one on the committee is an expert in nuclear power.
The bike shed gets considerably more debate. Committee members argue whether a bike rack would suffice and whether a shed should be wood or aluminum, because they have some experience working with those materials at home.
Employee refreshments take up two-thirds of the debate, because everyone has a strong opinion on what‚Äôs the best coffee, the best cookies, the best chips, etc.
Many households operate the same.
7. Social aspiration spending: Trickle-down consumption patterns from one socioeconomic group to the next.
Economist Joseph Stiglitz once wrote: ‚ÄúTrickle-down economics may be a chimera but trickle-down behaviorism is very real.‚Äù
There is no such thing as an objective level of wealth. Everything is relative to something else. People look around and say, ‚ÄúWhat‚Äôs that person driving, where are they living, what kind of clothes are they wearing?‚Äù Aspirations are calibrated accordingly.
I spoke with Wired magazine founding executive editor Kevin Kelly last week. He brought up an interesting point: If you want to know what lower-income groups will aspire to spend their money on in the future, look at what higher-income groups exclusively do today.
European vacations were once the exclusive playground of the rich. Then they trickled down.
Same with college. It was once reserved for the highest income groups. Then it spread.
Same with investing. In 1929 ‚Äì the peak of the Roaring ‚Äò20s bubble ‚Äì five percent of Americans owned stocks, virtually all of them the very wealthy. Today, 58% of households own stocks in some form.
Same with two-car households, lawns, walk-in closets, granite countertops, six-burner stoves, jet travel, and even the entire concept of retirement.
Part of the reason these products spread to the masses is that they got cheaper. But the reason they got cheaper is because there was so much demand from the masses ‚Äì hungered by their aspirations ‚Äì that pushed companies to innovate new ways of mass production.
People like to mimic others, especially those who appear to be living better lives. Always been like that, always will be.
8. An underappreciation of the long-term cost of purchases, with too much emphasis on the initial price.
It‚Äôs common to find someone who bought their home in, say, 1974, for something like $60,000. Today it‚Äôs worth perhaps $350,000. The owners no doubt feel they have made the investment of their lives.
But those numbers above equate to an average annual return of 3.75%. Property taxes tend to average roughly 1%, so that brings our real return to 2.75% per year. Maintenance and repairs vary greatly, but spending 1% - 3% of your home‚Äôs value per year on upkeep should be expected.
Where does that leave our long-term returns? Ah, quite dim.
Price is easy to calculate. It‚Äôs just whatever you paid initially and sold for eventually.
Cost is harder to figure out. They tend to be a slow drip over time, which are easy to ignore but add up quickly.
Same for cars, boats, and hobbies. You can even say the cost of smoking cigarettes is the price of a pack plus the long-term cost of medical care associated with the habit. One is easy to calculate, the other is very difficult.
9. No one is impressed with your possessions as much as you are.
When you see someone driving a nice car, you rarely think, ‚ÄúWow, the guy driving that car is cool.‚Äù Instead, you think, ‚ÄúWow, if I had that car people would think I‚Äôm cool.‚Äù Subconsciously or not, this is how people think.
There is a paradox here: people tend to want wealth to signal to others that they should be liked and admired. But in reality those other people often bypass admiring you, not because they don‚Äôt think wealth is admirable, but because they use your wealth as a benchmark for their own desire to be liked and admired.
I wrote a letter to my son the day he was born. It says, in part:

You might think you want an expensive car, a fancy watch, and a huge house. But I‚Äôm telling you, you don‚Äôt. What you want is respect and admiration from other people, and you think having expensive stuff will bring it. It almost never does ‚Äì especially from the people you want to respect and admire you.

Now, I like nice homes and nice cars as much as anyone. The point here is not to shoo you away from nice things.
It‚Äôs just a recognition that no one is as impressed with your stuff as much as you are. Or even that no one is thinking about you as much as you are. They‚Äôre busy thinking about themselves!
People generally aspire to be respected and admired by others, and using money to buy fancy things may bring less of it than you imagine. If respect and admiration are your goal, be careful how you seek it. Humility, kindness, and empathy will bring you more respect than horsepower ever will.
10. Not knowing what kind of spending will make you happy because you haven‚Äôt tried enough new and strange forms of spending.
Evolution is the most powerful force in the world, capable of transforming single-cell organisms into modern humans.
But evolution has no idea what it‚Äôs doing. There‚Äôs no guide, no manual, no rulebook. It‚Äôs not even necessarily good at selecting traits that work.
Its power is that it ‚Äútries‚Äù trillions upon trillions of different mutations and is ruthless about killing off the ones that don‚Äôt work. What‚Äôs left ‚Äì the winners ‚Äì stick around.
There‚Äôs a theory in evolutionary biology called Fisher‚Äôs Fundamental Theorem of Natural Selection. It‚Äôs the idea that variance equals strength, because the more diverse a population is the more chances it has to come up with new traits that can be selected for. No one can know what traits will be useful; that‚Äôs not how evolution works. But if you create a lot of traits, the useful one ‚Äì whatever it is ‚Äì will be in there somewhere.
There‚Äôs an important analogy here about spending money.
A lot of people have no idea what kind of spending will make them happy. What should you buy? Where should you travel? How much should you save? There is no single answer to these questions because everyone‚Äôs different. People default to what society tells them ‚Äì whatever is most expensive will bring the most joy.
But that‚Äôs not how it works. You have to try spending money on tons of different oddball things before you find what works for you. For some people it‚Äôs travel; others can‚Äôt stand being away from home. For others it‚Äôs nice restaurants; others don‚Äôt get the hype and prefer cheap pizza. I know people who think spending money on first-class plane tickets is a borderline scam. Others would not dare sit behind row four. To each their own.
The more different kinds of spending you test out, the closer you‚Äôll likely get to a system that works for you. The trials don‚Äôt have to be big: a $10 new food here, a $75 treat there, slightly nice shoes, etc.
Here‚Äôs Ramit Sethi again: ‚ÄúFrugality, quite simply, is about choosing the things you love enough to spend extravagantly on‚Äîand then cutting costs mercilessly on the things you don‚Äôt love.‚Äù
There is no guide on what will make you happy ‚Äì you have to try a million different things and figure out what fits your personality.
11. The social signaling aspect of money, on both things you buy for yourself and charity given to others.
There‚Äôs a saying that if you get public recognition for donating money, it‚Äôs not charity ‚Äì it‚Äôs philanthropy. And if you demand recognition, it‚Äôs not even charity ‚Äì it‚Äôs a business deal. There‚Äôs a clear social benefit to you, the giver, in addition to the recipient. I don‚Äôt mean that in a negative way: Good donations to worthy causes would plunge if donors didn‚Äôt get recognition.
Most forms of spending have two purposes: To bring some sort of utility to the owner, and to signal something to other people.
Homes, cars, clothes, jewelry, obviously fit into that category. But even travel does as well ‚Äì how many vacation destinations are picked at least in part by what you think will make a good Instagram picture, or just that it sounds cool. (My guess is most Bali vacations fall into that category).
Psychologist Jonathan Haidt says people don‚Äôt communicate on social media; they perform for one another. Spending money is like that, too.
It‚Äôs not always a bad thing. If you‚Äôve merely thought about what clothes you‚Äôll look best in before you leave in the morning, you‚Äôve engaged in signaling. And it‚Äôs not always about looking the best: intentionally dressing casually to a formal meeting sends a powerful message about who holds the power. Before being caught as a sham, Sam Bankman-Fried said he intentionally didn‚Äôt wear pants to create a mystique.
The thing to recognize is that spending money ‚Äúon yourself‚Äù is often done with the intent of influencing what other people think.
That should spark three questions: Whose opinion are you trying to influence, why, and are those people even paying attention?
12. The social hierarchy of spending, positioning you against your peers.
An old joke is about two hikers who come across a grizzly bear in the woods. One starts to run, and the other yells, ‚ÄúAre you crazy, you can‚Äôt outrun a bear!‚Äù The runner replies: ‚ÄúI don‚Äôt have to be faster than the bear. I only have to be faster than you.‚Äù
All success is simply relative to someone else ‚Äì usually those around you.
That‚Äôs important for spending money, because for so many people the question of whether you‚Äôre buying nice things is actually, ‚Äúare your things nicer than other peoples‚Äô things?‚Äù The question of whether your home is big enough is actually, ‚Äúis your home bigger than your neighbor‚Äôs?‚Äù
Not only is the urge to one-up your peers, but you may feel the need to continually surpass your own spending. Is this year‚Äôs vacation more expensive than last year‚Äôs? Is the next car fancier than the old one?
Money to some people is less of an asset and more of a social liability, indebting them to a status-chasing life that can leave them miserable.
It‚Äôs a dangerous trap if you don‚Äôt recognize the game and how it‚Äôs played. Montesquieu wrote 275 years ago, ‚ÄúIf you only wished to be happy, this could be easily accomplished; but we wish to be happier than other people, and this is always difficult, for we believe others to be happier than they are.‚Äù
13. Spending can be a representation of how hard you‚Äôve worked and how much stress went into earning your paycheck.
Someone who works 100 hours a week and hates their job may have an urge to spend frivolously in an attempt to compensate for the misery of how their paycheck was earned.
Never have I seen money burn a hole in someone‚Äôs pocket faster than an investment banker receiving their annual bonus. After 12 months of Excel modeling until 3am, you have an urge to prove to yourself that it was worth it, offsetting what you sacrificed. It‚Äôs like someone held underwater for a minute ‚Äì they do not take a calm breath when they surface; they gasp.
The opposite can hold true. I can only back this up with anecdotal experiences, but those most capable of delayed gratification are often those who enjoy their work. The pay might be good, but the urge to compensate for your hard work with heavy spending isn‚Äôt there.
Spending money to make you happy is hard if you‚Äôre already happy.
More on this topic:


My book, The Psychology of Money


Lifestyles


Getting Wealthy vs. Staying Wealthy




SHARE Copy Link 















Sign up for more Collab Fund content

Email address












More from the blog‚Ä¶





  by
  
    
  
  ‚Äî 
  














  by
  
    
  
  ‚Äî 
  














  by
  
    
  
  ‚Äî 
  

















Collab Fund

      Collaborative is a leading source of capital for big ideas pushing the world forward.
    



Newsletter
Sign up for updates¬†‚Üó








Twitter
Follow @collabfund¬†‚Üó








RSS
Subscribe to the blog¬†‚Üó











About


Shared Future


SOS


Currency


Public


Blog


Site Credits







Collaborative Fund Management LLC, Collaborative Holdings Management LP and Collab+Currency Management, LLC are distinct investment advisory entities, are not a unitary enterprise and operate independently of one another.  From time to time Collaborative Fund Management LLC may draw on its relationship with Collaborative Holdings Management LP and/or Collab+Currency Management, LLC, but only to the extent consistent with its status as a separate investment adviser.






"
https://news.ycombinator.com/rss,TensorFlow for Python is dying?,https://thenextweb.com/news/why-tensorflow-for-python-is-dying-a-slow-death,Comments,"









                                    Story by
                                


                                        Ari Joury
                                    




Religious wars have been a cornerstone in tech. Whether it‚Äôs debating about the pros and cons of different operating systems, cloud providers, or deep learning frameworks ‚Äî a few beers in, the facts slide aside and people start fighting for their technology like it‚Äôs the holy grail.
Just think about the endless talk about IDEs. Some people prefer VisualStudio, others use IntelliJ, again others use plain old editors like Vim. There‚Äôs a never-ending debate, half-ironic of course, about what your favorite text editor might say about your personality.
Similar wars seem to be flaring up around PyTorch and TensorFlow. Both camps have troves of supporters. And both camps have good arguments to suggest why their favorite deep learning framework might be the best.
Get your tickets for TNW Valencia in March!The heart of tech is coming to the heart of the Mediterranean
Join now
That being said, the data speaks a fairly simple truth. TensorFlow is, as of now, the most widespread deep learning framework. It gets almost twice as many questions on StackOverflow every month as PyTorch does.
On the other hand, TensorFlow hasn‚Äôt been growing since around 2018. PyTorch has been steadily gaining traction until the day this post got published.
For the sake of completeness, I‚Äôve also included Keras in the figure below. It was released at around the same time as TensorFlow. But, as one can see, it‚Äôs tanked in recent years. The short explanation for this is that Keras is a bit simplistic and too slow for the demands that most deep learning practitioners have.
PyTorch is still growing, while TensorFlow‚Äôs growth has stalled. Graph from StackOverflow trends.
StackOverflow traffic for TensorFlow might not be declining at a rapid speed, but it‚Äôs declining nevertheless. And there are reasons to believe that this decline will become more pronounced in the next few years, particularly in the world of Python.
PyTorch feels more pythonic
Developed by Google, TensorFlow might have been one of the first frameworks to show up to the deep learning party in late 2015. However, the first version was rather cumbersome to use ‚Äî as many first versions of any software tend to be.
That is why Meta started developing PyTorch as a means to offer pretty much the same functionalities as TensorFlow, but making it easier to use.
The people behind TensorFlow soon took note of this, and adopted many of PyTorch‚Äôs most popular features in TensorFlow 2.0.
A good rule of thumb is that you can do anything that PyTorch does in TensorFlow. It will just take you twice as much effort to write the code. It‚Äôs not so intuitive and feels quite un-pythonic, even today.
PyTorch, on the other hand, feels very natural to use if you enjoy using Python.
PyTorch has more available models
Many companies and academic institutions don‚Äôt have the massive computational power needed to build large models. Size is king, however, when it comes to machine learning; the larger the model the more impressive its performance is.
With HuggingFace, engineers can use large, trained and tuned models and incorporate them in their pipelines with just a few lines of code. However, a staggering 85% of these models can only be used with PyTorch. Only about 8% of HuggingFace models are exclusive to TensorFlow. The remainder is available for both frameworks.
This means that if you‚Äôre planning to use large models, you‚Äôd better stay away from TensorFlow or invest heavily in compute resources to train your own model.
PyTorch is better for students and research
PyTorch has a reputation for being appreciated more by academia. This is not unjustified; three out of four research papers use PyTorch. Even among those researchers who started out using TensorFlow ‚Äî remember that it arrived earlier to the deep learning party ‚Äî the majority have migrated to PyTorch now.
These trends are staggering and persist despite the fact that Google has quite a large footprint in AI research and mainly uses TensorFlow.
What‚Äôs perhaps more striking about this is that research influences teaching, and therefore defines what students might learn. A professor who has published the majority of their papers using PyTorch will be more inclined to use it in lectures. Not only are they more comfortable teaching and answering questions regarding PyTorch; they might also have stronger beliefs regarding its success.
College students therefore might get much more insights about PyTorch than TensorFlow. And, given that the college students of today are the workers of tomorrow, you can probably guess where this trend is going‚Ä¶
PyTorch‚Äôs ecosystem has grown faster
At the end of the day, software frameworks only matter insofar as they‚Äôre players in an ecosystem. Both PyTorch and TensorFlow have quite developed ecosystems, including repositories for trained models other than HuggingFace, data management systems, failure prevention mechanisms, and more.
It‚Äôs worth stating that, as of now, TensorFlow has a slightly more developed ecosystem than PyTorch. However, keep in mind that PyTorch has shown up later to the party and has had quite some user growth over the past few years. Therefore one can expect that PyTorch‚Äôs ecosystem might outgrow TensorFlow‚Äôs in due time.
TensorFlow has the better deployment infrastructure
As cumbersome as TensorFlow might be to code, once it‚Äôs written is a lot easier to deploy than PyTorch. Tools like TensorFlow Serving and TensorFlow Lite make deployment to cloud, servers, mobile, and IoT devices happen in a jiffy.
PyTorch, on the other hand, has been notoriously slow in releasing deployment tools. That being said, it has been closing the gap with TensorFlow quite rapidly as of late.
It‚Äôs hard to predict at this point in time, but it‚Äôs quite possible that PyTorch might match or even outgrow TensorFlow‚Äôs deployment infrastructure in the years to come.
TensorFlow code will probably stick around for a while because it‚Äôs costly to switch frameworks after deployment. However, it‚Äôs quite conceivable that newer deep learning applications will increasingly be written and deployed with PyTorch.
TensorFlow is not all about Python
TensorFlow isn‚Äôt dead. It‚Äôs just not as popular as it once was.
The core reason for this is that many people who use Python for machine learning are switching to PyTorch.
But Python is not the only language out there for machine learning. It‚Äôs the O.G. of machine learning, and that‚Äôs the only reason why the developers of TensorFlow centered its support around Python.
These days, one can use TensorFlow with JavaScript, Java, and C++. The community is also starting to develop support for other languages like Julia, Rust, Scala, and Haskell, among others.
PyTorch, on the other hand, is very centered around Python ‚Äî that‚Äôs why it feels so pythonic after all. There is a C++ API, but there isn‚Äôt half the support for other languages that TensorFlow offers.
It‚Äôs quite conceivable that PyTorch will overtake TensorFlow within Python. On the other hand, TensorFlow, with its impressive ecosystem, deployment features, and support for other languages, will remain an important player in deep learning.
Whether you choose TensorFlow or PyTorch for your next project depends mostly on how much you love Python.
This article was written by Ari Joury and was originally published on Medium. You can read it here. 


Get the TNW newsletter
Get the most important tech news in your inbox each week.


                                    Follow @thenextweb
                                


Also tagged with



Python




                                Published January 13, 2023 - 2:47 pm UTC

Back to top





















"
https://news.ycombinator.com/rss,Need for speed: static analysis version,https://semgrep.dev/blog/2022/static-analysis-speed,Comments,"Need for speed: static analysis versionLog inSign up freeRegistryPlaygroundProductsSemgrep AppManage and enforce code standards across your organization. Get started for free.Semgrep Supply ChainFind dependency vulnerabilities in your code.Featured docsGetting started with Semgrep Supply ChainStart finding high-priority security issues in your dependenciesPricingResourcesDocsWant to read all the docs? Start hereTutorialLearn to write Semgrep rules in under 10 minutesBlogGet the latest news about SemgrepContact UsWant to talk to a human? Get in touch with us!Latest blog postsIntroducing Semgrep Supply Chain.Find reachable vulnerable dependencies in your codeGeneral availability support of PHPSemgrep adds PHP support including 40+ new rulesDemystifying taint modeA user-friendly guide to writing rules with Semgrep's taint modeAll blog postsLog inSign up freeBlogdevelopmentNeed for speed: static analysis versiondevelopmentNeed for speed: static analysis versionWhy speed is important in static analysis and how Semgrep achieves ludicrous speedBrandon WuNovember 29, 2022In this articleLudicrous graphsStatic analysis at scaleKnowing is half the battleA unique nicheFindings, fasterSemantics, speedilyConclusionSubscribe to our blogShareShareTL;DR: Semgrep has achieved remarkably fast scan times by prioritizing speed using methods like taint summaries and tree matching in OCaml. In addition, Semgrep‚Äôs design as a tool that searches for syntax makes it fast due to designs like purely textual single-file analysis, partial parsing, and optimizations like skipping files that cannot produce matches.Program analysis is an extremely interesting discipline that aims to combine an impossible task (finding undesirable parts of programs) with practical usage (being useful to developers to fix their code). Practical usage takes many forms ranging from convenience of information and quality of findings to the speed at which the analysis is carried out.At r2c, we have one motto which we stick to ‚Äî ‚Äúcode analysis at ludicrous speed‚Äù. After almost 3 years of development, a question remains‚Äîwhat goes into making a code analysis product that can run at ‚Äúludicrous speed‚Äù, and have we achieved that goal with Semgrep?Ludicrous graphsHow do we qualify ‚Äúludicrous speed‚Äù? Some results for Semgrep‚Äôs speed can be seen here, in graphic form:Here is a graph of Semgrep‚Äôs scan time (in seconds) for the Django Python repository, over time. This data serves as a direct reflection of Semgrep‚Äôs growth over the past year, as various optimizations and engine upgrades have been carried out:Figure 1: Semgrep scan time (in seconds) for Django Python repository -¬†sourceAnd for the lodash JavaScript repository:Figure 2: Semgrep scan time (in seconds) for lodash JavaScript repository -¬†sourceHere‚Äôs the performance of Semgrep on all of its benchmarking repositories over time:Figure 3: Semgrep scan time for different repositoriesOver time, Semgrep has been making a consistent effort towards increased performance. In all benchmarked cases, that scan time using the latest Semgrep version takes place in less than 20 seconds, which is a significantly short enough period to run within a developer‚Äôs normal commit workflow.Here‚Äôs some data validating Semgrep‚Äôs run-time (in Python, on the Django repository) against some other open-source Python analysis tools. All data are averaged and sourced from tests run on an M1 Mac machine.Figure 4: Semgrep scan time as compared to other Python analysis tools on Django repositoryIn this graph, we see that Semgrep performs quite fast, beating out the other tools. It‚Äôs worth noting that¬†pylint¬†and¬†flake8¬†are linting tools, which primarily work in the realm of style enforcement, which notably is not concerned with the behavior of the program, like Semgrep. With features like taint analysis, constant propagation, and dataflow analysis, it‚Äôs a fair description that Semgrep performs more computationally intensive analysis than the other options. More than just curiosity, Semgrep‚Äôs speed has made it feasible to be¬†run by existing organizations in production to shift left.Static analysis at scaleWhat makes a static analysis (SAST) tool fast? Well, it‚Äôs useful to look at what may make a static analysis tool¬†slow. SAST applications have to be able to process large amounts of source code, break it down into a format suitable for analysis, and then run detailed semantic scans on it.This analysis may also be done in a¬†dynamic¬†fashion, where programs are instrumented to detect certain faults during their runtime, but this has the disadvantage of adding extra overhead to the analyzed program, as well as operating closer to the hardware level, as opposed to the language level. In this article, we will focus on static analysis, and stay closer to the language level, which will yield dividends later on with Semgrep.Static analysis is inherently hard because it tries to find answers to questions about program behavior ‚Äî about programs that may run for a very long time, if not forever. Given that it is¬†static, this analysis must be done without running the program, so any actual evaluation is a non-starter. How can we make such a problem tractable?The way that this generally takes place is in¬†approximation. While we cannot run the program itself to find out what is actually happening, standard techniques allow us to gain (possibly imprecise) knowledge of the state of the program. In particular,¬†dataflow analysis, a classic technique, involves an iterative scan over all possible program points to find out properties that may be true at those points.In order to facilitate this dataflow analysis, static analysis tools need to know something about what paths the program may take during execution. This is achieved by computing a¬†control-flow graph, which is a graph that connects the various parts of the code which may execute after each other. Given a project with many functions, conditionals, and program text in general, however, looping over the entire control-flow graph of a program is not a trivial task. How does this be done in a more optimal way?Knowing is half the battleThe general mantra that Semgrep follows to facilitate its success is that it only¬†picks battles that it can win.Program analysis is a never-ending uphill slope because analyses can always be done more deeply, and more compute time can always be thrown into figuring out more things about the program's behavior. In practice, however, for the majority of applications, program analysis need not be particularly deep or theoretically based to be effective¬†in general.From the beginning of Semgrep, speed has been a major focus. To make sure we stay in line with that, from the beginning, we make sure that we only support features when we know that¬†Semgrep can win, or in other words, that it can be done in a fast way.A unique nicheIn a way, philosophically, Semgrep‚Äôs original purpose was in line with this way of thinking. Semgrep occupies a unique niche as a tool that straddles the line between¬†syntactic¬†and¬†semantic, however, it used to be more towards the former. It started as sgrep at Facebook by r2c‚Äôs own Yoann Padioleau, an open source tool that was to match program text in a semantically-aware way, but which lacked some of the modern-day features Semgrep possesses, such as constant propagation and taint analysis.This original focus granted Semgrep a unique perspective on program analysis, as sgrep didn‚Äôt need to solve many of the problems that other SAST applications aimed to do. Since it was a matching tool, there was no need to be aware of code flow at all, which is the main bottleneck in terms of program analysis. Since it only focused on text, there was no need to have any kind of understanding of programs beyond single files‚Äînecessarily, there was no need even to require that analyzed code compiled. This also granted other advantages, such as¬†partial parsing, where programs that are not syntactically correct can be parsed to trees that look ‚Äúclose enough‚Äù. This overall had the advantage of making Semgrep an extremely versatile and robust tool, from the get-go.In addition, the unique capabilities of Semgrep as a tool for¬†code review automation,¬†beyond just vulnerability-finding, necessitated that it be able to run quickly. In general, code analysis can occur on a nightly basis, with the goal of reporting any possible errors by the beginning of the next morning, so that engineers can triage those findings. This gives a sizeable 12-hour period for static analysis, which permits a large range of complex inquiries. Semgrep‚Äôs role as a customizable tool that catches vulnerabilities¬†on each pull request¬†means that it isn‚Äôt working in nearly the same time frame‚Äîdevelopers need to be able to interface with it as a regular part of their workflow of merging commits and writing code. This gives an upper limit of minutes, as opposed to hours, for Semgrep. So not only does Semgrep¬†only¬†pick battles it can win‚Äîit¬†must.Findings, fasterSpeed is an admirable goal for any static analysis tool. A more interesting question, however, is¬†how¬†this is achieved.In a similar sense, the fact that Semgrep lives so close to the¬†syntax¬†of a program helps again. One of the most helpful improvements made for Semgrep‚Äôs speed was in recognizing this. Whereas an arbitrary static analysis may not know specifically where a bug may occur and thus have to check¬†all¬†of a given program, Semgrep rules are typically written with some amount of the desired text to find‚Äîfor instance, they may contain the name of a sensitive function or some particular primitive in a language.This characteristic made it possible to speed up Semgrep scans by only searching files that are known to contain literal text which matches that in the patterns. For instance, consider the following Semgrep rule which looks for a hardcoded¬†tmp¬†directory within an¬†open:source:¬†Semgrep ruleThe pattern which this rule looks for involves a call to¬†open, which can only occur if the literal string¬†open¬†occurs anywhere in the given file. This can easily be tested in linear time, resulting in Semgrep being able to skip files that are known to be impossible to produce a match in, due to this property, which significantly improves scan times. In this case, it‚Äôs interesting how purely syntactic searches can supplement more semantic searches!Another significant speed benefit occurs from the inherent nature of the problem. Semgrep‚Äôs core engine is written in OCaml, a functional programming language because functional languages are ideal for the kind of structural decomposition on recursive data (the target program) that Semgrep‚Äôs main matching engine needs to do. This engine is used to provide raw matching data to the Python wrapper, which would then do the work of combining and analyzing the matches using the rule‚Äôs pattern combinators. This work is merely more structural decomposition on recursive data (the pattern), however, and another performance boost was gained upon porting that section of the logic to OCaml.Semantics, speedilyTree matching has a nearly negligible cost when compared to most deep program analysis techniques, such as pointer analysis or symbolic execution, so this was clearly a winning battle. As Semgrep grew more advanced, more features were added which caused it to err closer to the side of¬†semantics, such as¬†taint analysis¬†and constant propagation.These analyses are not necessarily ones that can be done quickly. Taint analysis, in particular, requires running dataflow analysis over the entire control flow of a program, which can potentially be huge, when considering how large an entire codebase may be, with all of its function calls and tricky control flow logic. To do taint analysis in this way would be to pick a losing battle.Semgrep succeeds in that it only carries out single-file analysis, so the control flow graph never exceeds the size of a file. In addition, taint can be done¬†incrementally. Functions have well-defined points where they begin and end, as well as generally well-defined entrances in terms of the data they accept (the function arguments). Thus, Semgrep collects taint summaries, which essentially (per function) encode the information about what taint may be possible, depending on the taint of the inputs that flow in.So for instance, given a function in Python:1def foo(a, b):
2
3    sink(a)
4
5    return NoneA taint summary for this function¬†foo¬†will note that, if the input¬†a¬†is tainted, then it will reach the tainted¬†sink¬†sink. Regardless of how the function¬†foo¬†is used, this is a fact about the function‚Äôs¬†potential¬†use. Then, at the call site to the function, if the input¬†a¬†is tainted, then we know to report a finding.This seems simple, but the end result is that we only ever need to run a dataflow analysis on the code of each function¬†once. Never does a taint summary need to be collected for a given function more than once, meaning that we can simply stitch all these facts together at the end, making for speedy results. The core lesson is that, by collecting summaries and doing taint in an intelligent way, we pick the battle that we can win. It turns out that for our upcoming inter-file extension to Semgrep, by applying this approach in an inter-file manner, we can still reap the speed benefits. This lets us avoid running dataflow analysis on an entire control-flow graph, and instead do small, localized analyses.ConclusionAt the end of the day, solving an undecidable problem at a pace that is useful to security engineers is a hard task. Harder still is solving an undecidable problem at a pace that is useful to the¬†developer, such that it can fit into the normal cycle of writing code and pushing commits. Semgrep‚Äôs unique philosophy as a tool has made it capable of bridging this gap, and over time, has proven it to have a speed that is nothing short of¬†ludicrous.AboutSemgrep is a fast, open-source, static analysis tool for finding bugs, detecting vulnerabilities in third-party dependencies, and enforcing code standards.Learn more with Semgrep‚Äôs blogStart ScanningBrowse PostsAnnouncementJune 22, 20222 min readAnnouncing Semgrep's general availability support of PHPPablo EstradaAnnouncementMay 11, 20225 min readSemgrep's May 2022 updates: Introducing DeepSemgrep, plus new Playground, and self managed GitHub + GitLab support!Chinmay GaikwadBest practicesOctober 01, 20215 min readProtect Your GitHub Actions with SemgrepGrayson HardawayCode scanning at ludicrous speedFind Bugs and Enforce Code StandardsStart ScanningBook a DemoCode analysis at ludicrous speedStay up to dateTwitterSlackGitHubYouTubeResourcesDocsTutorialBlogAbout usContact usProductsSemgrep AppSemgrep Supply ChainPricingTwitterSlackGitHubYouTube¬© 2023 r2c. Semgrep is a registered trademark of r2c.Semgrep jobsTermsPrivacy"
