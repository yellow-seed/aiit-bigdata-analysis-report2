{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カラムではlink, contentが重要\n",
    "# 第3回の内容がとても重要\n",
    "# 第５回の6も参考に\n",
    "# 英語モデルから類似表現を探るなら11回も参考になる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://news.ycombinator.com/rss</td>\n",
       "      <td>I'm Shadow Banned by DuckDuckGo (and Bing)</td>\n",
       "      <td>https://daverupert.com/2023/01/shadow-banned-b...</td>\n",
       "      <td>Comments</td>\n",
       "      <td>\\n\\n\\n\\n\\nI'm Shadow Banned by DuckDuckGo (and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://news.ycombinator.com/rss</td>\n",
       "      <td>SLT – A Common Lisp Language Plugin for Jetbra...</td>\n",
       "      <td>https://github.com/Enerccio/SLT</td>\n",
       "      <td>Comments</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\nEnerccio\\n\\n/\\n\\nSLT\\n\\nPubl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://news.ycombinator.com/rss</td>\n",
       "      <td>Ask HN: How do you trust that your personal ma...</td>\n",
       "      <td>https://news.ycombinator.com/item?id=34388866</td>\n",
       "      <td>Comments</td>\n",
       "      <td>\\n\\nAsk HN: How do you trust that your persona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://news.ycombinator.com/rss</td>\n",
       "      <td>Ubuntu 22.04 LTS servers and phased apt updates</td>\n",
       "      <td>https://utcc.utoronto.ca/~cks/space/blog/linux...</td>\n",
       "      <td>Comments</td>\n",
       "      <td>\\n \\n Chris's Wiki :: blog/linux/Ubuntu2204Ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://news.ycombinator.com/rss</td>\n",
       "      <td>Single-file scripts that download their depend...</td>\n",
       "      <td>https://dbohdan.com/scripts-with-dependencies</td>\n",
       "      <td>Comments</td>\n",
       "      <td>\\n\\n\\n\\nSingle-file scripts that download thei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                url  \\\n",
       "0  https://news.ycombinator.com/rss   \n",
       "1  https://news.ycombinator.com/rss   \n",
       "2  https://news.ycombinator.com/rss   \n",
       "3  https://news.ycombinator.com/rss   \n",
       "4  https://news.ycombinator.com/rss   \n",
       "\n",
       "                                               title  \\\n",
       "0         I'm Shadow Banned by DuckDuckGo (and Bing)   \n",
       "1  SLT – A Common Lisp Language Plugin for Jetbra...   \n",
       "2  Ask HN: How do you trust that your personal ma...   \n",
       "3    Ubuntu 22.04 LTS servers and phased apt updates   \n",
       "4  Single-file scripts that download their depend...   \n",
       "\n",
       "                                                link   summary  \\\n",
       "0  https://daverupert.com/2023/01/shadow-banned-b...  Comments   \n",
       "1                    https://github.com/Enerccio/SLT  Comments   \n",
       "2      https://news.ycombinator.com/item?id=34388866  Comments   \n",
       "3  https://utcc.utoronto.ca/~cks/space/blog/linux...  Comments   \n",
       "4      https://dbohdan.com/scripts-with-dependencies  Comments   \n",
       "\n",
       "                                             content  \n",
       "0  \\n\\n\\n\\n\\nI'm Shadow Banned by DuckDuckGo (and...  \n",
       "1  \\n\\n\\n\\n\\n\\n\\n\\n\\nEnerccio\\n\\n/\\n\\nSLT\\n\\nPubl...  \n",
       "2  \\n\\nAsk HN: How do you trust that your persona...  \n",
       "3  \\n \\n Chris's Wiki :: blog/linux/Ubuntu2204Ser...  \n",
       "4  \\n\\n\\n\\nSingle-file scripts that download thei...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "\n",
    "# フィードデータの読み込み\n",
    "# - 1_feeeds で取得した output_en.csv\n",
    "feeds = pd.read_csv('data/output_en.csv')\n",
    "\n",
    "# 確認\n",
    "feeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://daverupert.com/2023/01/shadow-banned-b...</td>\n",
       "      <td>\\n\\n\\n\\n\\nI'm Shadow Banned by DuckDuckGo (and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/Enerccio/SLT</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\nEnerccio\\n\\n/\\n\\nSLT\\n\\nPubl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://news.ycombinator.com/item?id=34388866</td>\n",
       "      <td>\\n\\nAsk HN: How do you trust that your persona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://utcc.utoronto.ca/~cks/space/blog/linux...</td>\n",
       "      <td>\\n \\n Chris's Wiki :: blog/linux/Ubuntu2204Ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://dbohdan.com/scripts-with-dependencies</td>\n",
       "      <td>\\n\\n\\n\\nSingle-file scripts that download thei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://daverupert.com/2023/01/shadow-banned-b...   \n",
       "1                    https://github.com/Enerccio/SLT   \n",
       "2      https://news.ycombinator.com/item?id=34388866   \n",
       "3  https://utcc.utoronto.ca/~cks/space/blog/linux...   \n",
       "4      https://dbohdan.com/scripts-with-dependencies   \n",
       "\n",
       "                                             content  \n",
       "0  \\n\\n\\n\\n\\nI'm Shadow Banned by DuckDuckGo (and...  \n",
       "1  \\n\\n\\n\\n\\n\\n\\n\\n\\nEnerccio\\n\\n/\\n\\nSLT\\n\\nPubl...  \n",
       "2  \\n\\nAsk HN: How do you trust that your persona...  \n",
       "3  \\n \\n Chris's Wiki :: blog/linux/Ubuntu2204Ser...  \n",
       "4  \\n\\n\\n\\nSingle-file scripts that download thei...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url title summaryを削除してdataframeを作成\n",
    "df = feeds.drop(['title', 'url', 'summary'], axis=1)\n",
    "\n",
    "# sampleとして初めの5行だけのdfを用意\n",
    "sample_df = df.head(5)\n",
    "\n",
    "sample_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 英語テキストに対する前処理\n",
    "\n",
    "- トークン化（単語に分割）\n",
    "- 小文字化\n",
    "- ストップワードの除去\n",
    "- 見出し語化\n",
    "- ステミング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/08p75_s57m71xgdcr10y9kwm0000gn/T/ipykernel_76545/1894906837.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df['tokens'] = sample_df.apply(lambda row: nltk.tokenize.word_tokenize(row['content']), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://daverupert.com/2023/01/shadow-banned-b...</td>\n",
       "      <td>\\n\\n\\n\\n\\nI'm Shadow Banned by DuckDuckGo (and...</td>\n",
       "      <td>[I, 'm, Shadow, Banned, by, DuckDuckGo, (, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/Enerccio/SLT</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\nEnerccio\\n\\n/\\n\\nSLT\\n\\nPubl...</td>\n",
       "      <td>[Enerccio, /, SLT, Public, Notifications, Fork...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://news.ycombinator.com/item?id=34388866</td>\n",
       "      <td>\\n\\nAsk HN: How do you trust that your persona...</td>\n",
       "      <td>[Ask, HN, :, How, do, you, trust, that, your, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://utcc.utoronto.ca/~cks/space/blog/linux...</td>\n",
       "      <td>\\n \\n Chris's Wiki :: blog/linux/Ubuntu2204Ser...</td>\n",
       "      <td>[Chris, 's, Wiki, :, :, blog/linux/Ubuntu2204S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://dbohdan.com/scripts-with-dependencies</td>\n",
       "      <td>\\n\\n\\n\\nSingle-file scripts that download thei...</td>\n",
       "      <td>[Single-file, scripts, that, download, their, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://daverupert.com/2023/01/shadow-banned-b...   \n",
       "1                    https://github.com/Enerccio/SLT   \n",
       "2      https://news.ycombinator.com/item?id=34388866   \n",
       "3  https://utcc.utoronto.ca/~cks/space/blog/linux...   \n",
       "4      https://dbohdan.com/scripts-with-dependencies   \n",
       "\n",
       "                                             content  \\\n",
       "0  \\n\\n\\n\\n\\nI'm Shadow Banned by DuckDuckGo (and...   \n",
       "1  \\n\\n\\n\\n\\n\\n\\n\\n\\nEnerccio\\n\\n/\\n\\nSLT\\n\\nPubl...   \n",
       "2  \\n\\nAsk HN: How do you trust that your persona...   \n",
       "3  \\n \\n Chris's Wiki :: blog/linux/Ubuntu2204Ser...   \n",
       "4  \\n\\n\\n\\nSingle-file scripts that download thei...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [I, 'm, Shadow, Banned, by, DuckDuckGo, (, and...  \n",
       "1  [Enerccio, /, SLT, Public, Notifications, Fork...  \n",
       "2  [Ask, HN, :, How, do, you, trust, that, your, ...  \n",
       "3  [Chris, 's, Wiki, :, :, blog/linux/Ubuntu2204S...  \n",
       "4  [Single-file, scripts, that, download, their, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# # 各行のトークン化\n",
    "# sample_df['tokens'] = sample_df.apply(lambda row: nltk.tokenize.word_tokenize(row['content']), axis=1)\n",
    "\n",
    "# sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/08p75_s57m71xgdcr10y9kwm0000gn/T/ipykernel_76545/1843076984.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df['tokens_tag'] = sample_df.apply(lambda row: nltk.pos_tag(row['tokens']), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://daverupert.com/2023/01/shadow-banned-b...</td>\n",
       "      <td>\\n\\n\\n\\n\\nI'm Shadow Banned by DuckDuckGo (and...</td>\n",
       "      <td>[I, 'm, Shadow, Banned, by, DuckDuckGo, (, and...</td>\n",
       "      <td>[(I, PRP), ('m, VBP), (Shadow, JJ), (Banned, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/Enerccio/SLT</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\nEnerccio\\n\\n/\\n\\nSLT\\n\\nPubl...</td>\n",
       "      <td>[Enerccio, /, SLT, Public, Notifications, Fork...</td>\n",
       "      <td>[(Enerccio, NNP), (/, NNP), (SLT, NNP), (Publi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://news.ycombinator.com/item?id=34388866</td>\n",
       "      <td>\\n\\nAsk HN: How do you trust that your persona...</td>\n",
       "      <td>[Ask, HN, :, How, do, you, trust, that, your, ...</td>\n",
       "      <td>[(Ask, NNP), (HN, NNP), (:, :), (How, WRB), (d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://utcc.utoronto.ca/~cks/space/blog/linux...</td>\n",
       "      <td>\\n \\n Chris's Wiki :: blog/linux/Ubuntu2204Ser...</td>\n",
       "      <td>[Chris, 's, Wiki, :, :, blog/linux/Ubuntu2204S...</td>\n",
       "      <td>[(Chris, NNP), ('s, POS), (Wiki, NN), (:, :), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://dbohdan.com/scripts-with-dependencies</td>\n",
       "      <td>\\n\\n\\n\\nSingle-file scripts that download thei...</td>\n",
       "      <td>[Single-file, scripts, that, download, their, ...</td>\n",
       "      <td>[(Single-file, JJ), (scripts, NNS), (that, WDT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://daverupert.com/2023/01/shadow-banned-b...   \n",
       "1                    https://github.com/Enerccio/SLT   \n",
       "2      https://news.ycombinator.com/item?id=34388866   \n",
       "3  https://utcc.utoronto.ca/~cks/space/blog/linux...   \n",
       "4      https://dbohdan.com/scripts-with-dependencies   \n",
       "\n",
       "                                             content  \\\n",
       "0  \\n\\n\\n\\n\\nI'm Shadow Banned by DuckDuckGo (and...   \n",
       "1  \\n\\n\\n\\n\\n\\n\\n\\n\\nEnerccio\\n\\n/\\n\\nSLT\\n\\nPubl...   \n",
       "2  \\n\\nAsk HN: How do you trust that your persona...   \n",
       "3  \\n \\n Chris's Wiki :: blog/linux/Ubuntu2204Ser...   \n",
       "4  \\n\\n\\n\\nSingle-file scripts that download thei...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [I, 'm, Shadow, Banned, by, DuckDuckGo, (, and...   \n",
       "1  [Enerccio, /, SLT, Public, Notifications, Fork...   \n",
       "2  [Ask, HN, :, How, do, you, trust, that, your, ...   \n",
       "3  [Chris, 's, Wiki, :, :, blog/linux/Ubuntu2204S...   \n",
       "4  [Single-file, scripts, that, download, their, ...   \n",
       "\n",
       "                                          tokens_tag  \n",
       "0  [(I, PRP), ('m, VBP), (Shadow, JJ), (Banned, V...  \n",
       "1  [(Enerccio, NNP), (/, NNP), (SLT, NNP), (Publi...  \n",
       "2  [(Ask, NNP), (HN, NNP), (:, :), (How, WRB), (d...  \n",
       "3  [(Chris, NNP), ('s, POS), (Wiki, NN), (:, :), ...  \n",
       "4  [(Single-file, JJ), (scripts, NNS), (that, WDT...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 品詞のタグ\n",
    "# sample_df['tokens_tag'] = sample_df.apply(lambda row: nltk.pos_tag(row['tokens']), axis=1)\n",
    "\n",
    "# sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 小文字\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "symbols_to_remove = r'[\"`,.' + r\"'\" + r']'\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words += [\"'\", '\"', ':', ';', '.', ',', '-', '!', '?', \"'s\", '`', '•', '%']\n",
    "stop_words += ['–', '—', '‘', '’', '“', '”', '…', '|', '#', '$', '&', \"''\", '(', ')']\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "# 品詞の名称を変換\n",
    "def wordnet_tag(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    return None\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = []\n",
    "    # 品詞のタグ付けをした各トークンについて\n",
    "    for t in nltk.pos_tag(nltk.tokenize.word_tokenize(text.replace('-', ' '))):\n",
    "        # 小文字化\n",
    "        t0 = t[0].lower()\n",
    "        # 不要な文字の削除\n",
    "        t0 = re.sub(symbols_to_remove, '', t0)\n",
    "        # 空文字列になったら次へ\n",
    "        if t0 == '':\n",
    "            continue\n",
    "        # stop_words に含まれていないトークンのみを残す\n",
    "        if t0 in stop_words:\n",
    "            continue\n",
    "        # カンマ区切りが入った数値からカンマを削除\n",
    "        if t[1] == 'CD':\n",
    "            t0 = t0.replace(',', '')\n",
    "        # 見出し語化\n",
    "        tag = wordnet_tag(t[1])\n",
    "        if tag is None:\n",
    "            t0 = lemmatizer.lemmatize(t0)\n",
    "        else:\n",
    "            t0 = lemmatizer.lemmatize(t0, tag)\n",
    "        # ステミング\n",
    "        t0 = stemmer.stem(t0)\n",
    "        # リストに追加\n",
    "        tokens.append(t0)\n",
    "    # トークンのリストを返す\n",
    "    return tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoWによるベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 例として最初の2行のテキストを処理\n",
    "# text_list = [df['text'].iloc[0], df['text'].iloc[1]]\n",
    "text_list = [sample_df['content']]\n",
    "\n",
    "# CountVectorizer\n",
    "# - tokenizer=preprocess: トークン化処理に上で定義した preprocess を使用することを指定\n",
    "bow_vectorizer = CountVectorizer(tokenizer=preprocess)\n",
    "\n",
    "# ベクトル化\n",
    "bow_vector = bow_vectorizer.fit_transform(sample_df.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shadow ban duckduckgo bing januari 14 2023 come attent site appear search result even daverupertcom directli dig use get index yandex sure enough… either first all… rude one person know actual start mac… audac —nay cowardic contribut web —a southern gentleman— take high offens slight misconstru charact declar seo top object initi dismiss nerdsnip shot signal flare brain spin mysteri need solv mean… money blog build clout years… right almost weekli decade… co host somewhat success develop podcast… back link popular like cs tricks… hacker news hand times… probabl important… show googl earth would step sign webmast tool tri enough zero click impress page aw clue go error accord crawler 100 miss meta descript seem dealbreak 91 lighthous super care 0 418 sitemapxml though reason think amazon affili bookshelf /use trigger could see spammi question ethic sometim without dollar make year keep around carrot incent motiv updat perhap time retir monet avenu anyway afoot… let investig begin post follow ever "
     ]
    }
   ],
   "source": [
    "# ベクトルの単語との対応\n",
    "for i in bow_vector[0].indices:\n",
    "    # print()\n",
    "    # - end=' ': 改行の代わりに空白を出力\n",
    "    print(bow_vectorizer.get_feature_names_out()[i], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['shadow', 3],\n",
       " ['ban', 3],\n",
       " ['duckduckgo', 4],\n",
       " ['bing', 9],\n",
       " ['januari', 1],\n",
       " ['14', 1],\n",
       " ['2023', 1],\n",
       " ['come', 1],\n",
       " ['attent', 1],\n",
       " ['site', 7],\n",
       " ['appear', 3],\n",
       " ['search', 2],\n",
       " ['result', 1],\n",
       " ['even', 1],\n",
       " ['daverupertcom', 1],\n",
       " ['directli', 1],\n",
       " ['dig', 1],\n",
       " ['use', 4],\n",
       " ['get', 3],\n",
       " ['index', 4],\n",
       " ['yandex', 1],\n",
       " ['sure', 3],\n",
       " ['enough…', 1],\n",
       " ['either', 1],\n",
       " ['first', 2],\n",
       " ['all…', 1],\n",
       " ['rude', 1],\n",
       " ['one', 5],\n",
       " ['person', 1],\n",
       " ['know', 3],\n",
       " ['actual', 1],\n",
       " ['start', 1],\n",
       " ['mac…', 1],\n",
       " ['audac', 1],\n",
       " ['—nay', 1],\n",
       " ['cowardic', 1],\n",
       " ['contribut', 1],\n",
       " ['web', 2],\n",
       " ['—a', 1],\n",
       " ['southern', 1],\n",
       " ['gentleman—', 1],\n",
       " ['take', 2],\n",
       " ['high', 1],\n",
       " ['offens', 1],\n",
       " ['slight', 1],\n",
       " ['misconstru', 1],\n",
       " ['charact', 1],\n",
       " ['declar', 1],\n",
       " ['seo', 3],\n",
       " ['top', 1],\n",
       " ['object', 1],\n",
       " ['initi', 1],\n",
       " ['dismiss', 1],\n",
       " ['nerdsnip', 1],\n",
       " ['shot', 1],\n",
       " ['signal', 1],\n",
       " ['flare', 1],\n",
       " ['brain', 1],\n",
       " ['spin', 1],\n",
       " ['mysteri', 2],\n",
       " ['need', 1],\n",
       " ['solv', 3],\n",
       " ['mean…', 1],\n",
       " ['money', 2],\n",
       " ['blog', 4],\n",
       " ['build', 1],\n",
       " ['clout', 1],\n",
       " ['years…', 1],\n",
       " ['right', 1],\n",
       " ['almost', 1],\n",
       " ['weekli', 1],\n",
       " ['decade…', 1],\n",
       " ['co', 1],\n",
       " ['host', 1],\n",
       " ['somewhat', 1],\n",
       " ['success', 1],\n",
       " ['develop', 1],\n",
       " ['podcast…', 1],\n",
       " ['back', 1],\n",
       " ['link', 3],\n",
       " ['popular', 1],\n",
       " ['like', 3],\n",
       " ['cs', 1],\n",
       " ['tricks…', 1],\n",
       " ['hacker', 1],\n",
       " ['news', 1],\n",
       " ['hand', 1],\n",
       " ['times…', 1],\n",
       " ['probabl', 1],\n",
       " ['important…', 1],\n",
       " ['show', 1],\n",
       " ['googl', 1],\n",
       " ['earth', 1],\n",
       " ['would', 2],\n",
       " ['step', 1],\n",
       " ['sign', 1],\n",
       " ['webmast', 1],\n",
       " ['tool', 1],\n",
       " ['tri', 1],\n",
       " ['enough', 1],\n",
       " ['zero', 3],\n",
       " ['click', 1],\n",
       " ['impress', 1],\n",
       " ['page', 3],\n",
       " ['aw', 1],\n",
       " ['clue', 1],\n",
       " ['go', 1],\n",
       " ['error', 2],\n",
       " ['accord', 1],\n",
       " ['crawler', 1],\n",
       " ['100', 1],\n",
       " ['miss', 1],\n",
       " ['meta', 2],\n",
       " ['descript', 2],\n",
       " ['seem', 2],\n",
       " ['dealbreak', 1],\n",
       " ['91', 1],\n",
       " ['lighthous', 1],\n",
       " ['super', 1],\n",
       " ['care', 1],\n",
       " ['0', 1],\n",
       " ['418', 1],\n",
       " ['sitemapxml', 1],\n",
       " ['though', 1],\n",
       " ['reason', 1],\n",
       " ['think', 1],\n",
       " ['amazon', 2],\n",
       " ['affili', 1],\n",
       " ['bookshelf', 2],\n",
       " ['/use', 1],\n",
       " ['trigger', 1],\n",
       " ['could', 1],\n",
       " ['see', 1],\n",
       " ['spammi', 1],\n",
       " ['question', 1],\n",
       " ['ethic', 1],\n",
       " ['sometim', 1],\n",
       " ['without', 1],\n",
       " ['dollar', 1],\n",
       " ['make', 1],\n",
       " ['year', 1],\n",
       " ['keep', 1],\n",
       " ['around', 1],\n",
       " ['carrot', 1],\n",
       " ['incent', 1],\n",
       " ['motiv', 1],\n",
       " ['updat', 1],\n",
       " ['perhap', 1],\n",
       " ['time', 1],\n",
       " ['retir', 1],\n",
       " ['monet', 1],\n",
       " ['avenu', 1],\n",
       " ['anyway', 1],\n",
       " ['afoot…', 1],\n",
       " ['let', 1],\n",
       " ['investig', 1],\n",
       " ['begin', 1],\n",
       " ['post', 1],\n",
       " ['follow', 1],\n",
       " ['ever', 1]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 単語と頻度\n",
    "[[bow_vectorizer.get_feature_names_out()[i], bow_vector[0, i]] for i in bow_vector[0].indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 2023 come search use get sure start web top build develop back sign tri enough 0 without time enerccio / slt public notif fork star 26 ide plugin itellij/jetbrain lineup implement support common lisp via sbcl slime/swank licens apach 20 code issu 4 pull request action project secur insight enerccio/slt commit belong branch repositori may outsid master switch branches/tag tag view name alreadi exist provid mani git command accept creat caus unexpect behavior want cancel 3 1 local codespac clone http github cli checkout svn url work fast offici learn open desktop download zip requir pleas launch noth happen xcode visual studio readi problem prepar late peter vanusanik fix wrong import stringutil test distribut 4681185 jan 15 stat 19 file permalink fail load inform type messag run gradle/wrapp init 6 src gitignor codeofconductmd renam licensetxt readm readmemd distributionssh buildgradlekt gradleproperti gradlew gradlewbat settingsgradlekt languag jetbrain compil sourc plan featur goal experiment crash report bug modifi protocol commmun capabl intellij base idea community/ultim workd major steel bank instal quicklisp releas find appli check tabl variant pattern clion version clzip goland gozip commun iczip ultim iuzip pycharm pyzip pczip rider rdzip phpstorm read correctli sinc swap chang gradl also upload marketplac repl interact debug walkabl debugg breakpoint document macro expand function symbol refer refactor list packag asdf level form yet evalu v2 topic integr environ resourc watcher watch publish java 914 44 lex 33 09 "
     ]
    }
   ],
   "source": [
    "# ベクトルの単語との対応\n",
    "for i in bow_vector[1].indices:\n",
    "    print(bow_vectorizer.get_feature_names_out()[i], end=' ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDFによるベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 例として最初の2行のテキストを処理\n",
    "# text_list = [df['text'].iloc[0], df['text'].iloc[1]]\n",
    "\n",
    "\n",
    "# TfidfVectorizer\n",
    "# - tokenizer=preprocess: トークン化処理に上で定義した preprocess を使用することを指定\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=preprocess)\n",
    "\n",
    "# ベクトル化\n",
    "tfidf_vector = tfidf_vectorizer.fit_transform(sample_df.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I'm Shadow Banned by DuckDuckGo (and Bing)\n",
      "\n",
      "\n",
      "January 14, 2023\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "It came to my attention that my site does not appear on DuckDuckGo search results. Even when searching for “daverupert.com” directly. After some digging, DuckDuckGo used to get their site index from Yandex, but now gets their site index from Bing and sure enough… I didn’t appear on Bing either.\n",
      "First of all… rude. I’m the one person I know who actually uses Bing and I started using DuckDuckGo on my Mac… and they have the audacity —nay, the cowardice!— to shadow ban me and my contributions to the Web!? I —a southern gentleman— take the highest offense at this slighting and misconstruing of my character. I do declare.\n",
      "SEO isn’t one of my top objectives with this site, so initially I dismissed it. But that nerdsnipe shot a signal flare up in my brain that spun into mystery I needed to solve. I mean… there can be money from blogging. Surely I’ve built some clout for my blog over the years… right?\n",
      "\n",
      "I have been blogging, almost weekly, for over a decade…\n",
      "I co-host a somewhat successful web development podcast…\n",
      "I’ve been back linked from popular blogs like CSS-Tricks…\n",
      "I’ve been on hacker news a handful of times…\n",
      "And probably most important… I show up on Google!\n",
      "\n",
      "Why on earth would Bing not index my site at all? To solve this, I took the first step and signed up for Bing Webmaster Tools to try to know what Bing knows about my site and sure enough: zero clicks, zero impressions, and zero indexed pages for my site. Awful.\n",
      "\n",
      "The one clue I have to go off are some “Errors” according to Bing’s Crawler. 100% of those errors are “missing meta description”. That doesn’t seem like an SEO dealbreaker to me (I get a 91 on Lighthouse SEO), but does Bing super care about meta descriptions? Doesn’t seem like I should have 0 out of 418 pages in my sitemap.xml though.\n",
      "One “out there” reason I can think is that I use Amazon Affiliate links on my Bookshelf and my /Uses page and that triggers a shadow ban? I could see how that appears spammy and I question the ethics of Amazon links sometimes myself, but what would I do without those $ones of dollars that I make each year!? I keep it around as a money carrot incentive to motivate me to update the bookshelf, but perhaps it’s time I retire that monetization avenue.\n",
      "Anyways, a mystery is afoot… let the investigation begin! I will post a follow up if I ever solve this.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  (0, 372)\t0.05053140560629549\n",
      "  (0, 409)\t0.04076841987155678\n",
      "  (0, 736)\t0.04076841987155678\n",
      "  (0, 168)\t0.05053140560629549\n",
      "  (0, 523)\t0.04076841987155678\n",
      "  (0, 566)\t0.04076841987155678\n",
      "  (0, 93)\t0.05053140560629549\n",
      "  (0, 126)\t0.05053140560629549\n",
      "  (0, 153)\t0.05053140560629549\n",
      "  (0, 628)\t0.05053140560629549\n",
      "  (0, 830)\t0.05053140560629549\n",
      "  (0, 965)\t0.02846851248609574\n",
      "  (0, 710)\t0.05053140560629549\n",
      "  (0, 1004)\t0.03384147125545648\n",
      "  (0, 633)\t0.05053140560629549\n",
      "  (0, 500)\t0.05053140560629549\n",
      "  (0, 206)\t0.05053140560629549\n",
      "  (0, 140)\t0.03384147125545648\n",
      "  (0, 543)\t0.04076841987155678\n",
      "  (0, 1068)\t0.04076841987155678\n",
      "  (0, 601)\t0.04076841987155678\n",
      "  (0, 334)\t0.05053140560629549\n",
      "  (0, 1053)\t0.03384147125545648\n",
      "  (0, 893)\t0.05053140560629549\n",
      "  (0, 368)\t0.05053140560629549\n",
      "  :\t:\n",
      "  (0, 403)\t0.08153683974311356\n",
      "  (0, 348)\t0.04076841987155678\n",
      "  (0, 357)\t0.05053140560629549\n",
      "  (0, 938)\t0.08540553745828722\n",
      "  (0, 1065)\t0.05053140560629549\n",
      "  (0, 505)\t0.1630736794862271\n",
      "  (0, 429)\t0.07223545656215334\n",
      "  (0, 1009)\t0.09631394208287111\n",
      "  (0, 320)\t0.05053140560629549\n",
      "  (0, 324)\t0.03384147125545648\n",
      "  (0, 294)\t0.05053140560629549\n",
      "  (0, 370)\t0.03384147125545648\n",
      "  (0, 829)\t0.05053140560629549\n",
      "  (0, 850)\t0.05693702497219148\n",
      "  (0, 131)\t0.12230525961467033\n",
      "  (0, 878)\t0.35371983924406836\n",
      "  (0, 148)\t0.05053140560629549\n",
      "  (0, 243)\t0.02846851248609574\n",
      "  (0, 31)\t0.03384147125545648\n",
      "  (0, 22)\t0.03384147125545648\n",
      "  (0, 533)\t0.04076841987155678\n",
      "  (0, 174)\t0.4547826504566594\n",
      "  (0, 342)\t0.20212562242518195\n",
      "  (0, 162)\t0.15159421681888646\n",
      "  (0, 865)\t0.15159421681888646\n"
     ]
    }
   ],
   "source": [
    "# 1行目\n",
    "print(sample_df['content'][0])\n",
    "print(vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ever follow post begin investig let afoot… anyway avenu monet retir time perhap updat motiv incent carrot around keep year make dollar without sometim ethic question spammi see could trigger /use bookshelf affili amazon think reason though sitemapxml 418 0 care super lighthous 91 dealbreak seem descript meta miss 100 crawler accord error go clue aw page impress click zero enough tri tool webmast sign step would earth googl show important… probabl times… hand news hacker tricks… cs like popular link back podcast… develop success somewhat host co decade… weekli almost right years… clout build blog money mean… solv need mysteri spin brain flare signal shot nerdsnip dismiss initi object top seo declar charact misconstru slight offens high take gentleman— southern —a web contribut cowardic —nay audac mac… start actual know person one rude all… first either enough… sure yandex index get use dig directli daverupertcom even result search appear site attent come 2023 14 januari bing duckduckgo ban shadow "
     ]
    }
   ],
   "source": [
    "# ベクトルの単語との対応\n",
    "for i in tfidf_vector[0].indices:\n",
    "    print(tfidf_vectorizer.get_feature_names_out()[i], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ever', 0.05053140560629549],\n",
       " ['follow', 0.04076841987155678],\n",
       " ['post', 0.04076841987155678],\n",
       " ['begin', 0.05053140560629549],\n",
       " ['investig', 0.04076841987155678],\n",
       " ['let', 0.04076841987155678],\n",
       " ['afoot…', 0.05053140560629549],\n",
       " ['anyway', 0.05053140560629549],\n",
       " ['avenu', 0.05053140560629549],\n",
       " ['monet', 0.05053140560629549],\n",
       " ['retir', 0.05053140560629549],\n",
       " ['time', 0.02846851248609574],\n",
       " ['perhap', 0.05053140560629549],\n",
       " ['updat', 0.03384147125545648],\n",
       " ['motiv', 0.05053140560629549],\n",
       " ['incent', 0.05053140560629549],\n",
       " ['carrot', 0.05053140560629549],\n",
       " ['around', 0.03384147125545648],\n",
       " ['keep', 0.04076841987155678],\n",
       " ['year', 0.04076841987155678],\n",
       " ['make', 0.04076841987155678],\n",
       " ['dollar', 0.05053140560629549],\n",
       " ['without', 0.03384147125545648],\n",
       " ['sometim', 0.05053140560629549],\n",
       " ['ethic', 0.05053140560629549],\n",
       " ['question', 0.04076841987155678],\n",
       " ['spammi', 0.05053140560629549],\n",
       " ['see', 0.04076841987155678],\n",
       " ['could', 0.03384147125545648],\n",
       " ['trigger', 0.05053140560629549],\n",
       " ['/use', 0.05053140560629549],\n",
       " ['bookshelf', 0.10106281121259097],\n",
       " ['affili', 0.05053140560629549],\n",
       " ['amazon', 0.10106281121259097],\n",
       " ['think', 0.03384147125545648],\n",
       " ['reason', 0.03384147125545648],\n",
       " ['though', 0.04076841987155678],\n",
       " ['sitemapxml', 0.05053140560629549],\n",
       " ['418', 0.05053140560629549],\n",
       " ['0', 0.024078485520717778],\n",
       " ['care', 0.04076841987155678],\n",
       " ['super', 0.05053140560629549],\n",
       " ['lighthous', 0.05053140560629549],\n",
       " ['91', 0.05053140560629549],\n",
       " ['dealbreak', 0.05053140560629549],\n",
       " ['seem', 0.10106281121259097],\n",
       " ['descript', 0.10106281121259097],\n",
       " ['meta', 0.10106281121259097],\n",
       " ['miss', 0.04076841987155678],\n",
       " ['100', 0.03384147125545648],\n",
       " ['crawler', 0.05053140560629549],\n",
       " ['accord', 0.05053140560629549],\n",
       " ['error', 0.10106281121259097],\n",
       " ['go', 0.04076841987155678],\n",
       " ['clue', 0.05053140560629549],\n",
       " ['aw', 0.05053140560629549],\n",
       " ['page', 0.10152441376636945],\n",
       " ['impress', 0.05053140560629549],\n",
       " ['click', 0.04076841987155678],\n",
       " ['zero', 0.12230525961467033],\n",
       " ['enough', 0.03384147125545648],\n",
       " ['tri', 0.03384147125545648],\n",
       " ['tool', 0.03384147125545648],\n",
       " ['webmast', 0.05053140560629549],\n",
       " ['sign', 0.04076841987155678],\n",
       " ['step', 0.05053140560629549],\n",
       " ['would', 0.06768294251091296],\n",
       " ['earth', 0.05053140560629549],\n",
       " ['googl', 0.04076841987155678],\n",
       " ['show', 0.04076841987155678],\n",
       " ['important…', 0.05053140560629549],\n",
       " ['probabl', 0.04076841987155678],\n",
       " ['times…', 0.05053140560629549],\n",
       " ['hand', 0.04076841987155678],\n",
       " ['news', 0.04076841987155678],\n",
       " ['hacker', 0.03384147125545648],\n",
       " ['tricks…', 0.05053140560629549],\n",
       " ['cs', 0.05053140560629549],\n",
       " ['like', 0.08540553745828722],\n",
       " ['popular', 0.05053140560629549],\n",
       " ['link', 0.12230525961467033],\n",
       " ['back', 0.03384147125545648],\n",
       " ['podcast…', 0.05053140560629549],\n",
       " ['develop', 0.04076841987155678],\n",
       " ['success', 0.05053140560629549],\n",
       " ['somewhat', 0.04076841987155678],\n",
       " ['host', 0.05053140560629549],\n",
       " ['co', 0.05053140560629549],\n",
       " ['decade…', 0.05053140560629549],\n",
       " ['weekli', 0.05053140560629549],\n",
       " ['almost', 0.05053140560629549],\n",
       " ['right', 0.04076841987155678],\n",
       " ['years…', 0.05053140560629549],\n",
       " ['clout', 0.05053140560629549],\n",
       " ['build', 0.03384147125545648],\n",
       " ['blog', 0.1630736794862271],\n",
       " ['money', 0.10106281121259097],\n",
       " ['mean…', 0.05053140560629549],\n",
       " ['solv', 0.15159421681888646],\n",
       " ['need', 0.03384147125545648],\n",
       " ['mysteri', 0.08153683974311356],\n",
       " ['spin', 0.04076841987155678],\n",
       " ['brain', 0.05053140560629549],\n",
       " ['flare', 0.05053140560629549],\n",
       " ['signal', 0.05053140560629549],\n",
       " ['shot', 0.05053140560629549],\n",
       " ['nerdsnip', 0.05053140560629549],\n",
       " ['dismiss', 0.05053140560629549],\n",
       " ['initi', 0.04076841987155678],\n",
       " ['object', 0.05053140560629549],\n",
       " ['top', 0.04076841987155678],\n",
       " ['seo', 0.15159421681888646],\n",
       " ['declar', 0.04076841987155678],\n",
       " ['charact', 0.05053140560629549],\n",
       " ['misconstru', 0.05053140560629549],\n",
       " ['slight', 0.05053140560629549],\n",
       " ['offens', 0.05053140560629549],\n",
       " ['high', 0.04076841987155678],\n",
       " ['take', 0.08153683974311356],\n",
       " ['gentleman—', 0.05053140560629549],\n",
       " ['southern', 0.05053140560629549],\n",
       " ['—a', 0.05053140560629549],\n",
       " ['web', 0.06768294251091296],\n",
       " ['contribut', 0.05053140560629549],\n",
       " ['cowardic', 0.05053140560629549],\n",
       " ['—nay', 0.05053140560629549],\n",
       " ['audac', 0.05053140560629549],\n",
       " ['mac…', 0.05053140560629549],\n",
       " ['start', 0.024078485520717778],\n",
       " ['actual', 0.05053140560629549],\n",
       " ['know', 0.08540553745828722],\n",
       " ['person', 0.04076841987155678],\n",
       " ['one', 0.14234256243047871],\n",
       " ['rude', 0.05053140560629549],\n",
       " ['all…', 0.05053140560629549],\n",
       " ['first', 0.08153683974311356],\n",
       " ['either', 0.04076841987155678],\n",
       " ['enough…', 0.05053140560629549],\n",
       " ['sure', 0.08540553745828722],\n",
       " ['yandex', 0.05053140560629549],\n",
       " ['index', 0.1630736794862271],\n",
       " ['get', 0.07223545656215334],\n",
       " ['use', 0.09631394208287111],\n",
       " ['dig', 0.05053140560629549],\n",
       " ['directli', 0.03384147125545648],\n",
       " ['daverupertcom', 0.05053140560629549],\n",
       " ['even', 0.03384147125545648],\n",
       " ['result', 0.05053140560629549],\n",
       " ['search', 0.05693702497219148],\n",
       " ['appear', 0.12230525961467033],\n",
       " ['site', 0.35371983924406836],\n",
       " ['attent', 0.05053140560629549],\n",
       " ['come', 0.02846851248609574],\n",
       " ['2023', 0.03384147125545648],\n",
       " ['14', 0.03384147125545648],\n",
       " ['januari', 0.04076841987155678],\n",
       " ['bing', 0.4547826504566594],\n",
       " ['duckduckgo', 0.20212562242518195],\n",
       " ['ban', 0.15159421681888646],\n",
       " ['shadow', 0.15159421681888646]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 単語とTF-IDF\n",
    "[[tfidf_vectorizer.get_feature_names_out()[i], tfidf_vector[0, i]] for i in tfidf_vector[0].indices]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 階層的クラスタリング (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bow_vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kz/08p75_s57m71xgdcr10y9kwm0000gn/T/ipykernel_76545/2937237510.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# - metric='cosine' コサイン距離\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# - method='average' 平均非類似度（コサイン距離ではward法は使えないため）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinkage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'average'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cosine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 樹形図を作成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bow_vector' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# 階層的凝集クラスタリング\n",
    "# - metric='cosine' コサイン距離\n",
    "# - method='average' 平均非類似度（コサイン距離ではward法は使えないため）\n",
    "bow_clusters = linkage(bow_vector.todense(), method='average', metric='cosine')\n",
    "\n",
    "# 樹形図を作成\n",
    "plt.figure(figsize=(50, 20))\n",
    "dendr = dendrogram(bow_clusters, labels=sample_df.index, leaf_font_size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import cut_tree\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "n_clusters = 10\n",
    "\n",
    "# cut_tree: 指定したクラスタ数でのラベル（クラスタ番号）を取得\n",
    "# - np.ndarray.flatten: cut_tree は多次元配列で返すので、1次元配列に変換\n",
    "labels = np.ndarray.flatten(cut_tree(bow_clusters, n_clusters))\n",
    "\n",
    "# 結果を DataFrame にまとめる\n",
    "bow_df_cluster = pd.DataFrame(labels, columns=['cluster'])\n",
    "bow_df_cluster['content'] = sample_df.content\n",
    "\n",
    "# 確認\n",
    "bow_df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれのクラスタの内容を出力\n",
    "for i in range(0, n_clusters):\n",
    "    print(bow_df_cluster[bow_df_cluster.cluster == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 階層的凝集クラスタリング\n",
    "# - metric='cosine' コサイン距離\n",
    "# - method='average' 平均非類似度（コサイン距離ではward法は使えないため）\n",
    "tfidf_clusters = linkage(bow_vector.todense(), method='average', metric='cosine')\n",
    "\n",
    "# 樹形図を作成\n",
    "plt.figure(figsize=(50, 20))\n",
    "dendr = dendrogram(tfidf_clusters, labels=sample_df.index, leaf_font_size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut_tree: 指定したクラスタ数でのラベル（クラスタ番号）を取得\n",
    "# - np.ndarray.flatten: cut_tree は多次元配列で返すので、1次元配列に変換\n",
    "labels = np.ndarray.flatten(cut_tree(tfidf_clusters, n_clusters))\n",
    "\n",
    "# 結果を DataFrame にまとめる\n",
    "tfidf_df_cluster = pd.DataFrame(labels, columns=['cluster'])\n",
    "tfidf_df_cluster['content'] = df.content\n",
    "\n",
    "# 確認\n",
    "tfidf_df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれのクラスタの内容を出力\n",
    "for i in range(0, n_clusters):\n",
    "    print(tfidf_df_cluster[tfidf_df_cluster.cluster == i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:52:10) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d451e6fd3e3a90eb92742bb146e8e20c8a00180dad068226f141e79828259f8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
